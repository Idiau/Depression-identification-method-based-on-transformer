
{'eval_loss': 0.47841086983680725, 'eval_accuracy': 0.895852534562212, 'eval_runtime': 66.2986, 'eval_samples_per_second': 16.365, 'eval_steps_per_second': 8.19, 'epoch': 3.0}
[{'label': 'POSITIVE', 'score': 0.9430760741233826}]
depressive score: 0.0020876704 neutral score: 0.99791235
<xml><var name="_dummy_ipython_val"  />
<var name="_dummy_special_var"  />
<var name="acc_metric" type="Accuracy" qualifier="evaluate_modules.metrics.accuracy.f887c0aab52c2d38e1f8a215681126379eca617f96c447638f751434e8e65b14.accuracy" value="EvaluationModule%28name%3A %22accuracy%22%2C module_type%3A %22metric%22%2C features%3A %7B%27predictions%27%3A Value%28dtype=%27int32%27%2C id=None%29%2C %27references...weight=%5B0.5%2C 2%2C 0.7%2C 0.5%2C 9%2C 0.4%5D%29%0A        &gt;&gt;&gt; print%28results%29%0A        %7B%27accuracy%27%3A 0.8778625954198473%7D%0A%22%22%22%2C stored examples%3A 0%29" isContainer="True" shape="0" />
<var name="base_model" type="BertForSequenceClassification" qualifier="transformers.models.bert.modeling_bert" value="BertForSequenceClassification%28%0A  %28bert%29%3A BertModel%28%0A    %28embeddings%29%3A BertEmbeddings%28%0A      %28word_embeddings%29%3A Embedding%2828996...anh%28%29%0A    %29%0A  %29%0A  %28dropout%29%3A Dropout%28p=0.1%2C inplace=False%29%0A  %28classifier%29%3A Linear%28in_features=768%2C out_features=2%2C bias=True%29%0A%29" isContainer="True" />
<var name="classifier" type="TextClassificationPipeline" qualifier="transformers.pipelines.text_classification" value="%3Ctransformers.pipelines.text_classification.TextClassificationPipeline object at 0x0000027E5A48DCD0&gt;" isContainer="True" />
<var name="dataset" type="DatasetDict" qualifier="datasets.dataset_dict" value="DatasetDict%28%7B%0A    train%3A Dataset%28%7B%0A        features%3A %5B%27id%27%2C %27text%27%2C %27label%27%2C %27source_data%27%5D%2C%0A        num_rows%3A 10843%0A    %7D%29%0A%7D%29" isContainer="True" shape="('train',)" />
<var name="dataset_eval" type="Dataset" qualifier="datasets.arrow_dataset" value="Dataset%28%7B%0A    features%3A %5B%27id%27%2C %27text%27%2C %27label%27%2C %27source_data%27%2C %27input_ids%27%2C %27token_type_ids%27%2C %27attention_mask%27%5D%2C%0A    num_rows%3A 1085%0A%7D%29" isContainer="True" shape="(1085, 7)" />
<var name="dataset_tokens" type="DatasetDict" qualifier="datasets.dataset_dict" value="DatasetDict%28%7B%0A    train%3A Dataset%28%7B%0A        features%3A %5B%27id%27%2C %27text%27%2C %27label%27%2C %27source_data%27%2C %27input_ids%27%2C %27token_type_ids%27%2C %27attention_mask%27%5D%2C%0A        num_rows%3A 10843%0A    %7D%29%0A%7D%29" isContainer="True" shape="('train',)" />
<var name="dataset_train" type="Dataset" qualifier="datasets.arrow_dataset" value="Dataset%28%7B%0A    features%3A %5B%27id%27%2C %27text%27%2C %27label%27%2C %27source_data%27%2C %27input_ids%27%2C %27token_type_ids%27%2C %27attention_mask%27%5D%2C%0A    num_rows%3A 9758%0A%7D%29" isContainer="True" shape="(9758, 7)" />
<var name="ft_model" type="BertForSequenceClassification" qualifier="transformers.models.bert.modeling_bert" value="BertForSequenceClassification%28%0A  %28bert%29%3A BertModel%28%0A    %28embeddings%29%3A BertEmbeddings%28%0A      %28word_embeddings%29%3A Embedding%2828996...anh%28%29%0A    %29%0A  %29%0A  %28dropout%29%3A Dropout%28p=0.1%2C inplace=False%29%0A  %28classifier%29%3A Linear%28in_features=768%2C out_features=2%2C bias=True%29%0A%29" isContainer="True" />
<var name="ft_model_checkpoint" type="str" qualifier="builtins" value="test_trainer/checkpoint-2439" />
<var name="label_count" type="int" qualifier="builtins" value="2" />
<var name="model_name" type="str" qualifier="builtins" value="./bert-base-cased" />
<var name="result" type="list" qualifier="builtins" value="%5B%7B%27label%27%3A %27POSITIVE%27%2C %27score%27%3A 0.9430760741233826%7D%5D" isContainer="True" shape="1" />
<var name="sample_out" type="SequenceClassifierOutput" qualifier="transformers.modeling_outputs" value="SequenceClassifierOutput%28loss=None%2C logits=tensor%28%5B%5B 2.8993%2C -3.2703%5D%5D%2C grad_fn=%3CAddmmBackward0&gt;%29%2C hidden_states=None%2C attentions=None%29" isContainer="True" shape="1" />
<var name="sample_text" type="str" qualifier="builtins" value="RT %40humansofny%3A %E2%80%9CI don%E2%80%99t think I%E2%80%99m going to miss eighth grade. It%E2%80%99s been a tough year. A lot of my friends are struggling with depr%E2%80%A6 " />
<var name="sample_tokens" type="BatchEncoding" qualifier="transformers.tokenization_utils_base" value="%7B%27input_ids%27%3A tensor%28%5B%5B  101%2C   155%2C  1942%2C   137%2C  3612%2C 10008%2C  3382%2C   131%2C   789%2C   146%2C%0A          1274%2C   787%2C   189%2C  13...%2C 0%2C 0%2C 0%2C%0A         0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C%0A         0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%5D%5D%29%7D" isContainer="True" shape="3" />
<var name="scores" type="ndarray" qualifier="numpy" value="%5B0.99791235 0.00208767%5D" isContainer="True" shape="(2,)" />
<var name="shuffle" type="Dataset" qualifier="datasets.arrow_dataset" value="Dataset%28%7B%0A    features%3A %5B%27id%27%2C %27text%27%2C %27label%27%2C %27source_data%27%2C %27input_ids%27%2C %27token_type_ids%27%2C %27attention_mask%27%5D%2C%0A    num_rows%3A 10843%0A%7D%29" isContainer="True" shape="(10843, 7)" />
<var name="tokenizer" type="BertTokenizerFast" qualifier="transformers.models.bert.tokenization_bert_fast" value="BertTokenizerFast%28name_or_path=%27./bert-base-cased%27%2C vocab_size=28996%2C model_max_length=1000000000000000019884624838656%2C is_fas...se%2C special=True%29%2C%0A%09103%3A AddedToken%28%22%5BMASK%5D%22%2C rstrip=False%2C lstrip=False%2C single_word=False%2C normalized=False%2C special=True%29%2C%0A%7D" isContainer="True" shape="28996" />
<var name="train_count" type="int" qualifier="builtins" value="9758" />
<var name="trainer" type="Trainer" qualifier="transformers.trainer" value="%3Ctransformers.trainer.Trainer object at 0x0000027DAAA33190&gt;" isContainer="True" />
<var name="training_args" type="TrainingArguments" qualifier="transformers.training_args" value="TrainingArguments%28%0A_n_gpu=1%2C%0Aadafactor=False%2C%0Aadam_beta1=0.9%2C%0Aadam_beta2=0.999%2C%0Aadam_epsilon=1e-08%2C%0Aauto_find_batch_size=False...use_ipex=False%2C%0Ause_legacy_prediction_loop=False%2C%0Ause_mps_device=False%2C%0Awarmup_ratio=0.0%2C%0Awarmup_steps=100%2C%0Aweight_decay=0.0%2C%0A%29" isContainer="True" />
</xml>
<xml><var name="_dummy_ipython_val"  />
<var name="_dummy_special_var"  />
<var name="acc_metric" type="Accuracy" qualifier="evaluate_modules.metrics.accuracy.f887c0aab52c2d38e1f8a215681126379eca617f96c447638f751434e8e65b14.accuracy" value="EvaluationModule%28name%3A %22accuracy%22%2C module_type%3A %22metric%22%2C features%3A %7B%27predictions%27%3A Value%28dtype=%27int32%27%2C id=None%29%2C %27references...weight=%5B0.5%2C 2%2C 0.7%2C 0.5%2C 9%2C 0.4%5D%29%0A        &gt;&gt;&gt; print%28results%29%0A        %7B%27accuracy%27%3A 0.8778625954198473%7D%0A%22%22%22%2C stored examples%3A 0%29" isContainer="True" shape="0" />
<var name="base_model" type="BertForSequenceClassification" qualifier="transformers.models.bert.modeling_bert" value="BertForSequenceClassification%28%0A  %28bert%29%3A BertModel%28%0A    %28embeddings%29%3A BertEmbeddings%28%0A      %28word_embeddings%29%3A Embedding%2828996...anh%28%29%0A    %29%0A  %29%0A  %28dropout%29%3A Dropout%28p=0.1%2C inplace=False%29%0A  %28classifier%29%3A Linear%28in_features=768%2C out_features=2%2C bias=True%29%0A%29" isContainer="True" />
<var name="classifier" type="TextClassificationPipeline" qualifier="transformers.pipelines.text_classification" value="%3Ctransformers.pipelines.text_classification.TextClassificationPipeline object at 0x0000027E5A48DCD0&gt;" isContainer="True" />
<var name="dataset" type="DatasetDict" qualifier="datasets.dataset_dict" value="DatasetDict%28%7B%0A    train%3A Dataset%28%7B%0A        features%3A %5B%27id%27%2C %27text%27%2C %27label%27%2C %27source_data%27%5D%2C%0A        num_rows%3A 10843%0A    %7D%29%0A%7D%29" isContainer="True" shape="('train',)" />
<var name="dataset_eval" type="Dataset" qualifier="datasets.arrow_dataset" value="Dataset%28%7B%0A    features%3A %5B%27id%27%2C %27text%27%2C %27label%27%2C %27source_data%27%2C %27input_ids%27%2C %27token_type_ids%27%2C %27attention_mask%27%5D%2C%0A    num_rows%3A 1085%0A%7D%29" isContainer="True" shape="(1085, 7)" />
<var name="dataset_tokens" type="DatasetDict" qualifier="datasets.dataset_dict" value="DatasetDict%28%7B%0A    train%3A Dataset%28%7B%0A        features%3A %5B%27id%27%2C %27text%27%2C %27label%27%2C %27source_data%27%2C %27input_ids%27%2C %27token_type_ids%27%2C %27attention_mask%27%5D%2C%0A        num_rows%3A 10843%0A    %7D%29%0A%7D%29" isContainer="True" shape="('train',)" />
<var name="dataset_train" type="Dataset" qualifier="datasets.arrow_dataset" value="Dataset%28%7B%0A    features%3A %5B%27id%27%2C %27text%27%2C %27label%27%2C %27source_data%27%2C %27input_ids%27%2C %27token_type_ids%27%2C %27attention_mask%27%5D%2C%0A    num_rows%3A 9758%0A%7D%29" isContainer="True" shape="(9758, 7)" />
<var name="ft_model" type="BertForSequenceClassification" qualifier="transformers.models.bert.modeling_bert" value="BertForSequenceClassification%28%0A  %28bert%29%3A BertModel%28%0A    %28embeddings%29%3A BertEmbeddings%28%0A      %28word_embeddings%29%3A Embedding%2828996...anh%28%29%0A    %29%0A  %29%0A  %28dropout%29%3A Dropout%28p=0.1%2C inplace=False%29%0A  %28classifier%29%3A Linear%28in_features=768%2C out_features=2%2C bias=True%29%0A%29" isContainer="True" />
<var name="ft_model_checkpoint" type="str" qualifier="builtins" value="test_trainer/checkpoint-7317" />
<var name="label_count" type="int" qualifier="builtins" value="2" />
<var name="model_name" type="str" qualifier="builtins" value="./bert-base-cased" />
<var name="result" type="list" qualifier="builtins" value="%5B%7B%27label%27%3A %27POSITIVE%27%2C %27score%27%3A 0.9430760741233826%7D%5D" isContainer="True" shape="1" />
<var name="sample_out" type="SequenceClassifierOutput" qualifier="transformers.modeling_outputs" value="SequenceClassifierOutput%28loss=None%2C logits=tensor%28%5B%5B 2.8993%2C -3.2703%5D%5D%2C grad_fn=%3CAddmmBackward0&gt;%29%2C hidden_states=None%2C attentions=None%29" isContainer="True" shape="1" />
<var name="sample_text" type="str" qualifier="builtins" value="RT %40humansofny%3A %E2%80%9CI don%E2%80%99t think I%E2%80%99m going to miss eighth grade. It%E2%80%99s been a tough year. A lot of my friends are struggling with depr%E2%80%A6 " />
<var name="sample_tokens" type="BatchEncoding" qualifier="transformers.tokenization_utils_base" value="%7B%27input_ids%27%3A tensor%28%5B%5B  101%2C   155%2C  1942%2C   137%2C  3612%2C 10008%2C  3382%2C   131%2C   789%2C   146%2C%0A          1274%2C   787%2C   189%2C  13...%2C 0%2C 0%2C 0%2C%0A         0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C%0A         0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%5D%5D%29%7D" isContainer="True" shape="3" />
<var name="scores" type="ndarray" qualifier="numpy" value="%5B0.99791235 0.00208767%5D" isContainer="True" shape="(2,)" />
<var name="shuffle" type="Dataset" qualifier="datasets.arrow_dataset" value="Dataset%28%7B%0A    features%3A %5B%27id%27%2C %27text%27%2C %27label%27%2C %27source_data%27%2C %27input_ids%27%2C %27token_type_ids%27%2C %27attention_mask%27%5D%2C%0A    num_rows%3A 10843%0A%7D%29" isContainer="True" shape="(10843, 7)" />
<var name="tokenizer" type="BertTokenizerFast" qualifier="transformers.models.bert.tokenization_bert_fast" value="BertTokenizerFast%28name_or_path=%27./bert-base-cased%27%2C vocab_size=28996%2C model_max_length=1000000000000000019884624838656%2C is_fas...se%2C special=True%29%2C%0A%09103%3A AddedToken%28%22%5BMASK%5D%22%2C rstrip=False%2C lstrip=False%2C single_word=False%2C normalized=False%2C special=True%29%2C%0A%7D" isContainer="True" shape="28996" />
<var name="train_count" type="int" qualifier="builtins" value="9758" />
<var name="trainer" type="Trainer" qualifier="transformers.trainer" value="%3Ctransformers.trainer.Trainer object at 0x0000027DAAA33190&gt;" isContainer="True" />
<var name="training_args" type="TrainingArguments" qualifier="transformers.training_args" value="TrainingArguments%28%0A_n_gpu=1%2C%0Aadafactor=False%2C%0Aadam_beta1=0.9%2C%0Aadam_beta2=0.999%2C%0Aadam_epsilon=1e-08%2C%0Aauto_find_batch_size=False...use_ipex=False%2C%0Ause_legacy_prediction_loop=False%2C%0Ause_mps_device=False%2C%0Awarmup_ratio=0.0%2C%0Awarmup_steps=100%2C%0Aweight_decay=0.0%2C%0A%29" isContainer="True" />
</xml>
[{'label': 'POSITIVE', 'score': 0.9430760741233826}]
depressive score: 0.00012680366 neutral score: 0.99987316
<xml><var name="_dummy_ipython_val"  />
<var name="_dummy_special_var"  />
<var name="acc_metric" type="Accuracy" qualifier="evaluate_modules.metrics.accuracy.f887c0aab52c2d38e1f8a215681126379eca617f96c447638f751434e8e65b14.accuracy" value="EvaluationModule%28name%3A %22accuracy%22%2C module_type%3A %22metric%22%2C features%3A %7B%27predictions%27%3A Value%28dtype=%27int32%27%2C id=None%29%2C %27references...weight=%5B0.5%2C 2%2C 0.7%2C 0.5%2C 9%2C 0.4%5D%29%0A        &gt;&gt;&gt; print%28results%29%0A        %7B%27accuracy%27%3A 0.8778625954198473%7D%0A%22%22%22%2C stored examples%3A 0%29" isContainer="True" shape="0" />
<var name="base_model" type="BertForSequenceClassification" qualifier="transformers.models.bert.modeling_bert" value="BertForSequenceClassification%28%0A  %28bert%29%3A BertModel%28%0A    %28embeddings%29%3A BertEmbeddings%28%0A      %28word_embeddings%29%3A Embedding%2828996...anh%28%29%0A    %29%0A  %29%0A  %28dropout%29%3A Dropout%28p=0.1%2C inplace=False%29%0A  %28classifier%29%3A Linear%28in_features=768%2C out_features=2%2C bias=True%29%0A%29" isContainer="True" />
<var name="classifier" type="TextClassificationPipeline" qualifier="transformers.pipelines.text_classification" value="%3Ctransformers.pipelines.text_classification.TextClassificationPipeline object at 0x0000027DAAE5AA10&gt;" isContainer="True" />
<var name="dataset" type="DatasetDict" qualifier="datasets.dataset_dict" value="DatasetDict%28%7B%0A    train%3A Dataset%28%7B%0A        features%3A %5B%27id%27%2C %27text%27%2C %27label%27%2C %27source_data%27%5D%2C%0A        num_rows%3A 10843%0A    %7D%29%0A%7D%29" isContainer="True" shape="('train',)" />
<var name="dataset_eval" type="Dataset" qualifier="datasets.arrow_dataset" value="Dataset%28%7B%0A    features%3A %5B%27id%27%2C %27text%27%2C %27label%27%2C %27source_data%27%2C %27input_ids%27%2C %27token_type_ids%27%2C %27attention_mask%27%5D%2C%0A    num_rows%3A 1085%0A%7D%29" isContainer="True" shape="(1085, 7)" />
<var name="dataset_tokens" type="DatasetDict" qualifier="datasets.dataset_dict" value="DatasetDict%28%7B%0A    train%3A Dataset%28%7B%0A        features%3A %5B%27id%27%2C %27text%27%2C %27label%27%2C %27source_data%27%2C %27input_ids%27%2C %27token_type_ids%27%2C %27attention_mask%27%5D%2C%0A        num_rows%3A 10843%0A    %7D%29%0A%7D%29" isContainer="True" shape="('train',)" />
<var name="dataset_train" type="Dataset" qualifier="datasets.arrow_dataset" value="Dataset%28%7B%0A    features%3A %5B%27id%27%2C %27text%27%2C %27label%27%2C %27source_data%27%2C %27input_ids%27%2C %27token_type_ids%27%2C %27attention_mask%27%5D%2C%0A    num_rows%3A 9758%0A%7D%29" isContainer="True" shape="(9758, 7)" />
<var name="ft_model" type="BertForSequenceClassification" qualifier="transformers.models.bert.modeling_bert" value="BertForSequenceClassification%28%0A  %28bert%29%3A BertModel%28%0A    %28embeddings%29%3A BertEmbeddings%28%0A      %28word_embeddings%29%3A Embedding%2828996...anh%28%29%0A    %29%0A  %29%0A  %28dropout%29%3A Dropout%28p=0.1%2C inplace=False%29%0A  %28classifier%29%3A Linear%28in_features=768%2C out_features=2%2C bias=True%29%0A%29" isContainer="True" />
<var name="ft_model_checkpoint" type="str" qualifier="builtins" value="test_trainer/checkpoint-7317" />
<var name="label_count" type="int" qualifier="builtins" value="2" />
<var name="model_name" type="str" qualifier="builtins" value="./bert-base-cased" />
<var name="result" type="list" qualifier="builtins" value="%5B%7B%27label%27%3A %27POSITIVE%27%2C %27score%27%3A 0.9430760741233826%7D%5D" isContainer="True" shape="1" />
<var name="sample_out" type="SequenceClassifierOutput" qualifier="transformers.modeling_outputs" value="SequenceClassifierOutput%28loss=None%2C logits=tensor%28%5B%5B 4.6304%2C -4.3424%5D%5D%2C grad_fn=%3CAddmmBackward0&gt;%29%2C hidden_states=None%2C attentions=None%29" isContainer="True" shape="1" />
<var name="sample_text" type="str" qualifier="builtins" value="RT %40humansofny%3A %E2%80%9CI don%E2%80%99t think I%E2%80%99m going to miss eighth grade. It%E2%80%99s been a tough year. A lot of my friends are struggling with depr%E2%80%A6 " />
<var name="sample_tokens" type="BatchEncoding" qualifier="transformers.tokenization_utils_base" value="%7B%27input_ids%27%3A tensor%28%5B%5B  101%2C   155%2C  1942%2C   137%2C  3612%2C 10008%2C  3382%2C   131%2C   789%2C   146%2C%0A          1274%2C   787%2C   189%2C  13...%2C 0%2C 0%2C 0%2C%0A         0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C%0A         0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%5D%5D%29%7D" isContainer="True" shape="3" />
<var name="scores" type="ndarray" qualifier="numpy" value="%5B9.9987316e-01 1.2680366e-04%5D" isContainer="True" shape="(2,)" />
<var name="shuffle" type="Dataset" qualifier="datasets.arrow_dataset" value="Dataset%28%7B%0A    features%3A %5B%27id%27%2C %27text%27%2C %27label%27%2C %27source_data%27%2C %27input_ids%27%2C %27token_type_ids%27%2C %27attention_mask%27%5D%2C%0A    num_rows%3A 10843%0A%7D%29" isContainer="True" shape="(10843, 7)" />
<var name="tokenizer" type="BertTokenizerFast" qualifier="transformers.models.bert.tokenization_bert_fast" value="BertTokenizerFast%28name_or_path=%27./bert-base-cased%27%2C vocab_size=28996%2C model_max_length=1000000000000000019884624838656%2C is_fas...se%2C special=True%29%2C%0A%09103%3A AddedToken%28%22%5BMASK%5D%22%2C rstrip=False%2C lstrip=False%2C single_word=False%2C normalized=False%2C special=True%29%2C%0A%7D" isContainer="True" shape="28996" />
<var name="train_count" type="int" qualifier="builtins" value="9758" />
<var name="trainer" type="Trainer" qualifier="transformers.trainer" value="%3Ctransformers.trainer.Trainer object at 0x0000027DAAA33190&gt;" isContainer="True" />
<var name="training_args" type="TrainingArguments" qualifier="transformers.training_args" value="TrainingArguments%28%0A_n_gpu=1%2C%0Aadafactor=False%2C%0Aadam_beta1=0.9%2C%0Aadam_beta2=0.999%2C%0Aadam_epsilon=1e-08%2C%0Aauto_find_batch_size=False...use_ipex=False%2C%0Ause_legacy_prediction_loop=False%2C%0Ause_mps_device=False%2C%0Awarmup_ratio=0.0%2C%0Awarmup_steps=100%2C%0Aweight_decay=0.0%2C%0A%29" isContainer="True" />
</xml>
[{'label': 'NEGATIVE', 'score': 0.9808326959609985}]
depressive score: 0.9990225 neutral score: 0.0009775396
<xml><var name="_dummy_ipython_val"  />
<var name="_dummy_special_var"  />
<var name="acc_metric" type="Accuracy" qualifier="evaluate_modules.metrics.accuracy.f887c0aab52c2d38e1f8a215681126379eca617f96c447638f751434e8e65b14.accuracy" value="EvaluationModule%28name%3A %22accuracy%22%2C module_type%3A %22metric%22%2C features%3A %7B%27predictions%27%3A Value%28dtype=%27int32%27%2C id=None%29%2C %27references...weight=%5B0.5%2C 2%2C 0.7%2C 0.5%2C 9%2C 0.4%5D%29%0A        &gt;&gt;&gt; print%28results%29%0A        %7B%27accuracy%27%3A 0.8778625954198473%7D%0A%22%22%22%2C stored examples%3A 0%29" isContainer="True" shape="0" />
<var name="base_model" type="BertForSequenceClassification" qualifier="transformers.models.bert.modeling_bert" value="BertForSequenceClassification%28%0A  %28bert%29%3A BertModel%28%0A    %28embeddings%29%3A BertEmbeddings%28%0A      %28word_embeddings%29%3A Embedding%2828996...anh%28%29%0A    %29%0A  %29%0A  %28dropout%29%3A Dropout%28p=0.1%2C inplace=False%29%0A  %28classifier%29%3A Linear%28in_features=768%2C out_features=2%2C bias=True%29%0A%29" isContainer="True" />
<var name="classifier" type="TextClassificationPipeline" qualifier="transformers.pipelines.text_classification" value="%3Ctransformers.pipelines.text_classification.TextClassificationPipeline object at 0x0000027E5A46BC90&gt;" isContainer="True" />
<var name="dataset" type="DatasetDict" qualifier="datasets.dataset_dict" value="DatasetDict%28%7B%0A    train%3A Dataset%28%7B%0A        features%3A %5B%27id%27%2C %27text%27%2C %27label%27%2C %27source_data%27%5D%2C%0A        num_rows%3A 10843%0A    %7D%29%0A%7D%29" isContainer="True" shape="('train',)" />
<var name="dataset_eval" type="Dataset" qualifier="datasets.arrow_dataset" value="Dataset%28%7B%0A    features%3A %5B%27id%27%2C %27text%27%2C %27label%27%2C %27source_data%27%2C %27input_ids%27%2C %27token_type_ids%27%2C %27attention_mask%27%5D%2C%0A    num_rows%3A 1085%0A%7D%29" isContainer="True" shape="(1085, 7)" />
<var name="dataset_tokens" type="DatasetDict" qualifier="datasets.dataset_dict" value="DatasetDict%28%7B%0A    train%3A Dataset%28%7B%0A        features%3A %5B%27id%27%2C %27text%27%2C %27label%27%2C %27source_data%27%2C %27input_ids%27%2C %27token_type_ids%27%2C %27attention_mask%27%5D%2C%0A        num_rows%3A 10843%0A    %7D%29%0A%7D%29" isContainer="True" shape="('train',)" />
<var name="dataset_train" type="Dataset" qualifier="datasets.arrow_dataset" value="Dataset%28%7B%0A    features%3A %5B%27id%27%2C %27text%27%2C %27label%27%2C %27source_data%27%2C %27input_ids%27%2C %27token_type_ids%27%2C %27attention_mask%27%5D%2C%0A    num_rows%3A 9758%0A%7D%29" isContainer="True" shape="(9758, 7)" />
<var name="ft_model" type="BertForSequenceClassification" qualifier="transformers.models.bert.modeling_bert" value="BertForSequenceClassification%28%0A  %28bert%29%3A BertModel%28%0A    %28embeddings%29%3A BertEmbeddings%28%0A      %28word_embeddings%29%3A Embedding%2828996...anh%28%29%0A    %29%0A  %29%0A  %28dropout%29%3A Dropout%28p=0.1%2C inplace=False%29%0A  %28classifier%29%3A Linear%28in_features=768%2C out_features=2%2C bias=True%29%0A%29" isContainer="True" />
<var name="ft_model_checkpoint" type="str" qualifier="builtins" value="test_trainer/checkpoint-7317" />
<var name="label_count" type="int" qualifier="builtins" value="2" />
<var name="model_name" type="str" qualifier="builtins" value="./bert-base-cased" />
<var name="result" type="list" qualifier="builtins" value="%5B%7B%27label%27%3A %27NEGATIVE%27%2C %27score%27%3A 0.9808326959609985%7D%5D" isContainer="True" shape="1" />
<var name="sample_out" type="SequenceClassifierOutput" qualifier="transformers.modeling_outputs" value="SequenceClassifierOutput%28loss=None%2C logits=tensor%28%5B%5B-3.6528%2C  3.2767%5D%5D%2C grad_fn=%3CAddmmBackward0&gt;%29%2C hidden_states=None%2C attentions=None%29" isContainer="True" shape="1" />
<var name="sample_text" type="str" qualifier="builtins" value="Hey%2C look - I found my social anxiety again. Was wondering where that went." />
<var name="sample_tokens" type="BatchEncoding" qualifier="transformers.tokenization_utils_base" value="%7B%27input_ids%27%3A tensor%28%5B%5B  101%2C  4403%2C   117%2C  1440%2C   118%2C   146%2C  1276%2C  1139%2C  1934%2C 10507%2C%0A          1254%2C   119%2C  3982%2C  61...%2C 0%2C 0%2C 0%2C%0A         0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C%0A         0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%5D%5D%29%7D" isContainer="True" shape="3" />
<var name="scores" type="ndarray" qualifier="numpy" value="%5B9.775396e-04 9.990225e-01%5D" isContainer="True" shape="(2,)" />
<var name="shuffle" type="Dataset" qualifier="datasets.arrow_dataset" value="Dataset%28%7B%0A    features%3A %5B%27id%27%2C %27text%27%2C %27label%27%2C %27source_data%27%2C %27input_ids%27%2C %27token_type_ids%27%2C %27attention_mask%27%5D%2C%0A    num_rows%3A 10843%0A%7D%29" isContainer="True" shape="(10843, 7)" />
<var name="tokenizer" type="BertTokenizerFast" qualifier="transformers.models.bert.tokenization_bert_fast" value="BertTokenizerFast%28name_or_path=%27./bert-base-cased%27%2C vocab_size=28996%2C model_max_length=1000000000000000019884624838656%2C is_fas...se%2C special=True%29%2C%0A%09103%3A AddedToken%28%22%5BMASK%5D%22%2C rstrip=False%2C lstrip=False%2C single_word=False%2C normalized=False%2C special=True%29%2C%0A%7D" isContainer="True" shape="28996" />
<var name="train_count" type="int" qualifier="builtins" value="9758" />
<var name="trainer" type="Trainer" qualifier="transformers.trainer" value="%3Ctransformers.trainer.Trainer object at 0x0000027DAAA33190&gt;" isContainer="True" />
<var name="training_args" type="TrainingArguments" qualifier="transformers.training_args" value="TrainingArguments%28%0A_n_gpu=1%2C%0Aadafactor=False%2C%0Aadam_beta1=0.9%2C%0Aadam_beta2=0.999%2C%0Aadam_epsilon=1e-08%2C%0Aauto_find_batch_size=False...use_ipex=False%2C%0Ause_legacy_prediction_loop=False%2C%0Ause_mps_device=False%2C%0Awarmup_ratio=0.0%2C%0Awarmup_steps=100%2C%0Aweight_decay=0.0%2C%0A%29" isContainer="True" />
</xml>
[{'label': 'NEGATIVE', 'score': 0.8664417862892151}]
depressive score: 0.99946266 neutral score: 0.00053736556
<xml><var name="_dummy_ipython_val"  />
<var name="_dummy_special_var"  />
<var name="acc_metric" type="Accuracy" qualifier="evaluate_modules.metrics.accuracy.f887c0aab52c2d38e1f8a215681126379eca617f96c447638f751434e8e65b14.accuracy" value="EvaluationModule%28name%3A %22accuracy%22%2C module_type%3A %22metric%22%2C features%3A %7B%27predictions%27%3A Value%28dtype=%27int32%27%2C id=None%29%2C %27references...weight=%5B0.5%2C 2%2C 0.7%2C 0.5%2C 9%2C 0.4%5D%29%0A        &gt;&gt;&gt; print%28results%29%0A        %7B%27accuracy%27%3A 0.8778625954198473%7D%0A%22%22%22%2C stored examples%3A 0%29" isContainer="True" shape="0" />
<var name="base_model" type="BertForSequenceClassification" qualifier="transformers.models.bert.modeling_bert" value="BertForSequenceClassification%28%0A  %28bert%29%3A BertModel%28%0A    %28embeddings%29%3A BertEmbeddings%28%0A      %28word_embeddings%29%3A Embedding%2828996...anh%28%29%0A    %29%0A  %29%0A  %28dropout%29%3A Dropout%28p=0.1%2C inplace=False%29%0A  %28classifier%29%3A Linear%28in_features=768%2C out_features=2%2C bias=True%29%0A%29" isContainer="True" />
<var name="classifier" type="TextClassificationPipeline" qualifier="transformers.pipelines.text_classification" value="%3Ctransformers.pipelines.text_classification.TextClassificationPipeline object at 0x0000027E5A447790&gt;" isContainer="True" />
<var name="dataset" type="DatasetDict" qualifier="datasets.dataset_dict" value="DatasetDict%28%7B%0A    train%3A Dataset%28%7B%0A        features%3A %5B%27id%27%2C %27text%27%2C %27label%27%2C %27source_data%27%5D%2C%0A        num_rows%3A 10843%0A    %7D%29%0A%7D%29" isContainer="True" shape="('train',)" />
<var name="dataset_eval" type="Dataset" qualifier="datasets.arrow_dataset" value="Dataset%28%7B%0A    features%3A %5B%27id%27%2C %27text%27%2C %27label%27%2C %27source_data%27%2C %27input_ids%27%2C %27token_type_ids%27%2C %27attention_mask%27%5D%2C%0A    num_rows%3A 1085%0A%7D%29" isContainer="True" shape="(1085, 7)" />
<var name="dataset_tokens" type="DatasetDict" qualifier="datasets.dataset_dict" value="DatasetDict%28%7B%0A    train%3A Dataset%28%7B%0A        features%3A %5B%27id%27%2C %27text%27%2C %27label%27%2C %27source_data%27%2C %27input_ids%27%2C %27token_type_ids%27%2C %27attention_mask%27%5D%2C%0A        num_rows%3A 10843%0A    %7D%29%0A%7D%29" isContainer="True" shape="('train',)" />
<var name="dataset_train" type="Dataset" qualifier="datasets.arrow_dataset" value="Dataset%28%7B%0A    features%3A %5B%27id%27%2C %27text%27%2C %27label%27%2C %27source_data%27%2C %27input_ids%27%2C %27token_type_ids%27%2C %27attention_mask%27%5D%2C%0A    num_rows%3A 9758%0A%7D%29" isContainer="True" shape="(9758, 7)" />
<var name="ft_model" type="BertForSequenceClassification" qualifier="transformers.models.bert.modeling_bert" value="BertForSequenceClassification%28%0A  %28bert%29%3A BertModel%28%0A    %28embeddings%29%3A BertEmbeddings%28%0A      %28word_embeddings%29%3A Embedding%2828996...anh%28%29%0A    %29%0A  %29%0A  %28dropout%29%3A Dropout%28p=0.1%2C inplace=False%29%0A  %28classifier%29%3A Linear%28in_features=768%2C out_features=2%2C bias=True%29%0A%29" isContainer="True" />
<var name="ft_model_checkpoint" type="str" qualifier="builtins" value="test_trainer/checkpoint-7317" />
<var name="label_count" type="int" qualifier="builtins" value="2" />
<var name="model_name" type="str" qualifier="builtins" value="./bert-base-cased" />
<var name="result" type="list" qualifier="builtins" value="%5B%7B%27label%27%3A %27NEGATIVE%27%2C %27score%27%3A 0.8664417862892151%7D%5D" isContainer="True" shape="1" />
<var name="sample_out" type="SequenceClassifierOutput" qualifier="transformers.modeling_outputs" value="SequenceClassifierOutput%28loss=None%2C logits=tensor%28%5B%5B-4.0085%2C  3.5198%5D%5D%2C grad_fn=%3CAddmmBackward0&gt;%29%2C hidden_states=None%2C attentions=None%29" isContainer="True" shape="1" />
<var name="sample_text" type="str" qualifier="builtins" value="RT %40shannonpurser%3A Depression sucks. I%27m in the middle of it rn. I know some of you are too. We%27re going to make it." />
<var name="sample_tokens" type="BatchEncoding" qualifier="transformers.tokenization_utils_base" value="%7B%27input_ids%27%3A tensor%28%5B%5B  101%2C   155%2C  1942%2C   137%2C   188%2C  3822%2C  9158%2C  4093%2C  6906%2C   131%2C%0A         11442%2C 22797%2C   119%2C   1...%2C 0%2C 0%2C 0%2C%0A         0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C%0A         0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%5D%5D%29%7D" isContainer="True" shape="3" />
<var name="scores" type="ndarray" qualifier="numpy" value="%5B5.3736556e-04 9.9946266e-01%5D" isContainer="True" shape="(2,)" />
<var name="shuffle" type="Dataset" qualifier="datasets.arrow_dataset" value="Dataset%28%7B%0A    features%3A %5B%27id%27%2C %27text%27%2C %27label%27%2C %27source_data%27%2C %27input_ids%27%2C %27token_type_ids%27%2C %27attention_mask%27%5D%2C%0A    num_rows%3A 10843%0A%7D%29" isContainer="True" shape="(10843, 7)" />
<var name="tokenizer" type="BertTokenizerFast" qualifier="transformers.models.bert.tokenization_bert_fast" value="BertTokenizerFast%28name_or_path=%27./bert-base-cased%27%2C vocab_size=28996%2C model_max_length=1000000000000000019884624838656%2C is_fas...se%2C special=True%29%2C%0A%09103%3A AddedToken%28%22%5BMASK%5D%22%2C rstrip=False%2C lstrip=False%2C single_word=False%2C normalized=False%2C special=True%29%2C%0A%7D" isContainer="True" shape="28996" />
<var name="train_count" type="int" qualifier="builtins" value="9758" />
<var name="trainer" type="Trainer" qualifier="transformers.trainer" value="%3Ctransformers.trainer.Trainer object at 0x0000027DAAA33190&gt;" isContainer="True" />
<var name="training_args" type="TrainingArguments" qualifier="transformers.training_args" value="TrainingArguments%28%0A_n_gpu=1%2C%0Aadafactor=False%2C%0Aadam_beta1=0.9%2C%0Aadam_beta2=0.999%2C%0Aadam_epsilon=1e-08%2C%0Aauto_find_batch_size=False...use_ipex=False%2C%0Ause_legacy_prediction_loop=False%2C%0Ause_mps_device=False%2C%0Awarmup_ratio=0.0%2C%0Awarmup_steps=100%2C%0Aweight_decay=0.0%2C%0A%29" isContainer="True" />
</xml>
[{'label': 'NEGATIVE', 'score': 0.9960929751396179}]
depressive score: 0.9993393 neutral score: 0.000660682
<xml><var name="_dummy_ipython_val"  />
<var name="_dummy_special_var"  />
<var name="acc_metric" type="Accuracy" qualifier="evaluate_modules.metrics.accuracy.f887c0aab52c2d38e1f8a215681126379eca617f96c447638f751434e8e65b14.accuracy" value="EvaluationModule%28name%3A %22accuracy%22%2C module_type%3A %22metric%22%2C features%3A %7B%27predictions%27%3A Value%28dtype=%27int32%27%2C id=None%29%2C %27references...weight=%5B0.5%2C 2%2C 0.7%2C 0.5%2C 9%2C 0.4%5D%29%0A        &gt;&gt;&gt; print%28results%29%0A        %7B%27accuracy%27%3A 0.8778625954198473%7D%0A%22%22%22%2C stored examples%3A 0%29" isContainer="True" shape="0" />
<var name="base_model" type="BertForSequenceClassification" qualifier="transformers.models.bert.modeling_bert" value="BertForSequenceClassification%28%0A  %28bert%29%3A BertModel%28%0A    %28embeddings%29%3A BertEmbeddings%28%0A      %28word_embeddings%29%3A Embedding%2828996...anh%28%29%0A    %29%0A  %29%0A  %28dropout%29%3A Dropout%28p=0.1%2C inplace=False%29%0A  %28classifier%29%3A Linear%28in_features=768%2C out_features=2%2C bias=True%29%0A%29" isContainer="True" />
<var name="classifier" type="TextClassificationPipeline" qualifier="transformers.pipelines.text_classification" value="%3Ctransformers.pipelines.text_classification.TextClassificationPipeline object at 0x0000027E5BE7AFD0&gt;" isContainer="True" />
<var name="dataset" type="DatasetDict" qualifier="datasets.dataset_dict" value="DatasetDict%28%7B%0A    train%3A Dataset%28%7B%0A        features%3A %5B%27id%27%2C %27text%27%2C %27label%27%2C %27source_data%27%5D%2C%0A        num_rows%3A 10843%0A    %7D%29%0A%7D%29" isContainer="True" shape="('train',)" />
<var name="dataset_eval" type="Dataset" qualifier="datasets.arrow_dataset" value="Dataset%28%7B%0A    features%3A %5B%27id%27%2C %27text%27%2C %27label%27%2C %27source_data%27%2C %27input_ids%27%2C %27token_type_ids%27%2C %27attention_mask%27%5D%2C%0A    num_rows%3A 1085%0A%7D%29" isContainer="True" shape="(1085, 7)" />
<var name="dataset_tokens" type="DatasetDict" qualifier="datasets.dataset_dict" value="DatasetDict%28%7B%0A    train%3A Dataset%28%7B%0A        features%3A %5B%27id%27%2C %27text%27%2C %27label%27%2C %27source_data%27%2C %27input_ids%27%2C %27token_type_ids%27%2C %27attention_mask%27%5D%2C%0A        num_rows%3A 10843%0A    %7D%29%0A%7D%29" isContainer="True" shape="('train',)" />
<var name="dataset_train" type="Dataset" qualifier="datasets.arrow_dataset" value="Dataset%28%7B%0A    features%3A %5B%27id%27%2C %27text%27%2C %27label%27%2C %27source_data%27%2C %27input_ids%27%2C %27token_type_ids%27%2C %27attention_mask%27%5D%2C%0A    num_rows%3A 9758%0A%7D%29" isContainer="True" shape="(9758, 7)" />
<var name="ft_model" type="BertForSequenceClassification" qualifier="transformers.models.bert.modeling_bert" value="BertForSequenceClassification%28%0A  %28bert%29%3A BertModel%28%0A    %28embeddings%29%3A BertEmbeddings%28%0A      %28word_embeddings%29%3A Embedding%2828996...anh%28%29%0A    %29%0A  %29%0A  %28dropout%29%3A Dropout%28p=0.1%2C inplace=False%29%0A  %28classifier%29%3A Linear%28in_features=768%2C out_features=2%2C bias=True%29%0A%29" isContainer="True" />
<var name="ft_model_checkpoint" type="str" qualifier="builtins" value="test_trainer/checkpoint-7317" />
<var name="label_count" type="int" qualifier="builtins" value="2" />
<var name="model_name" type="str" qualifier="builtins" value="./bert-base-cased" />
<var name="result" type="list" qualifier="builtins" value="%5B%7B%27label%27%3A %27NEGATIVE%27%2C %27score%27%3A 0.9960929751396179%7D%5D" isContainer="True" shape="1" />
<var name="sample_out" type="SequenceClassifierOutput" qualifier="transformers.modeling_outputs" value="SequenceClassifierOutput%28loss=None%2C logits=tensor%28%5B%5B-3.8794%2C  3.4422%5D%5D%2C grad_fn=%3CAddmmBackward0&gt;%29%2C hidden_states=None%2C attentions=None%29" isContainer="True" shape="1" />
<var name="sample_text" type="str" qualifier="builtins" value="RT %40HRoyalThighness%3A Lol my social anxiety goes through the roof. Dunno bout this one mate lol https%3A//t.co/9vTMgnRK7X" />
<var name="sample_tokens" type="BatchEncoding" qualifier="transformers.tokenization_utils_base" value="%7B%27input_ids%27%3A tensor%28%5B%5B  101%2C   155%2C  1942%2C   137%2C   145%2C  2069%2C 22044%2C  1233%2C  1942%2C  3031%2C%0A          5084%2C  1757%2C   131%2C 106...%2C 0%2C 0%2C 0%2C%0A         0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C%0A         0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%5D%5D%29%7D" isContainer="True" shape="3" />
<var name="scores" type="ndarray" qualifier="numpy" value="%5B6.606820e-04 9.993393e-01%5D" isContainer="True" shape="(2,)" />
<var name="shuffle" type="Dataset" qualifier="datasets.arrow_dataset" value="Dataset%28%7B%0A    features%3A %5B%27id%27%2C %27text%27%2C %27label%27%2C %27source_data%27%2C %27input_ids%27%2C %27token_type_ids%27%2C %27attention_mask%27%5D%2C%0A    num_rows%3A 10843%0A%7D%29" isContainer="True" shape="(10843, 7)" />
<var name="tokenizer" type="BertTokenizerFast" qualifier="transformers.models.bert.tokenization_bert_fast" value="BertTokenizerFast%28name_or_path=%27./bert-base-cased%27%2C vocab_size=28996%2C model_max_length=1000000000000000019884624838656%2C is_fas...se%2C special=True%29%2C%0A%09103%3A AddedToken%28%22%5BMASK%5D%22%2C rstrip=False%2C lstrip=False%2C single_word=False%2C normalized=False%2C special=True%29%2C%0A%7D" isContainer="True" shape="28996" />
<var name="train_count" type="int" qualifier="builtins" value="9758" />
<var name="trainer" type="Trainer" qualifier="transformers.trainer" value="%3Ctransformers.trainer.Trainer object at 0x0000027DAAA33190&gt;" isContainer="True" />
<var name="training_args" type="TrainingArguments" qualifier="transformers.training_args" value="TrainingArguments%28%0A_n_gpu=1%2C%0Aadafactor=False%2C%0Aadam_beta1=0.9%2C%0Aadam_beta2=0.999%2C%0Aadam_epsilon=1e-08%2C%0Aauto_find_batch_size=False...use_ipex=False%2C%0Ause_legacy_prediction_loop=False%2C%0Ause_mps_device=False%2C%0Awarmup_ratio=0.0%2C%0Awarmup_steps=100%2C%0Aweight_decay=0.0%2C%0A%29" isContainer="True" />
</xml>
[{'label': 'NEGATIVE', 'score': 0.998799204826355}]
depressive score: 0.9987594 neutral score: 0.0012405666
<xml><var name="_dummy_ipython_val"  />
<var name="_dummy_special_var"  />
<var name="acc_metric" type="Accuracy" qualifier="evaluate_modules.metrics.accuracy.f887c0aab52c2d38e1f8a215681126379eca617f96c447638f751434e8e65b14.accuracy" value="EvaluationModule%28name%3A %22accuracy%22%2C module_type%3A %22metric%22%2C features%3A %7B%27predictions%27%3A Value%28dtype=%27int32%27%2C id=None%29%2C %27references...weight=%5B0.5%2C 2%2C 0.7%2C 0.5%2C 9%2C 0.4%5D%29%0A        &gt;&gt;&gt; print%28results%29%0A        %7B%27accuracy%27%3A 0.8778625954198473%7D%0A%22%22%22%2C stored examples%3A 0%29" isContainer="True" shape="0" />
<var name="base_model" type="BertForSequenceClassification" qualifier="transformers.models.bert.modeling_bert" value="BertForSequenceClassification%28%0A  %28bert%29%3A BertModel%28%0A    %28embeddings%29%3A BertEmbeddings%28%0A      %28word_embeddings%29%3A Embedding%2828996...anh%28%29%0A    %29%0A  %29%0A  %28dropout%29%3A Dropout%28p=0.1%2C inplace=False%29%0A  %28classifier%29%3A Linear%28in_features=768%2C out_features=2%2C bias=True%29%0A%29" isContainer="True" />
<var name="classifier" type="TextClassificationPipeline" qualifier="transformers.pipelines.text_classification" value="%3Ctransformers.pipelines.text_classification.TextClassificationPipeline object at 0x0000027DD5199010&gt;" isContainer="True" />
<var name="dataset" type="DatasetDict" qualifier="datasets.dataset_dict" value="DatasetDict%28%7B%0A    train%3A Dataset%28%7B%0A        features%3A %5B%27id%27%2C %27text%27%2C %27label%27%2C %27source_data%27%5D%2C%0A        num_rows%3A 10843%0A    %7D%29%0A%7D%29" isContainer="True" shape="('train',)" />
<var name="dataset_eval" type="Dataset" qualifier="datasets.arrow_dataset" value="Dataset%28%7B%0A    features%3A %5B%27id%27%2C %27text%27%2C %27label%27%2C %27source_data%27%2C %27input_ids%27%2C %27token_type_ids%27%2C %27attention_mask%27%5D%2C%0A    num_rows%3A 1085%0A%7D%29" isContainer="True" shape="(1085, 7)" />
<var name="dataset_tokens" type="DatasetDict" qualifier="datasets.dataset_dict" value="DatasetDict%28%7B%0A    train%3A Dataset%28%7B%0A        features%3A %5B%27id%27%2C %27text%27%2C %27label%27%2C %27source_data%27%2C %27input_ids%27%2C %27token_type_ids%27%2C %27attention_mask%27%5D%2C%0A        num_rows%3A 10843%0A    %7D%29%0A%7D%29" isContainer="True" shape="('train',)" />
<var name="dataset_train" type="Dataset" qualifier="datasets.arrow_dataset" value="Dataset%28%7B%0A    features%3A %5B%27id%27%2C %27text%27%2C %27label%27%2C %27source_data%27%2C %27input_ids%27%2C %27token_type_ids%27%2C %27attention_mask%27%5D%2C%0A    num_rows%3A 9758%0A%7D%29" isContainer="True" shape="(9758, 7)" />
<var name="ft_model" type="BertForSequenceClassification" qualifier="transformers.models.bert.modeling_bert" value="BertForSequenceClassification%28%0A  %28bert%29%3A BertModel%28%0A    %28embeddings%29%3A BertEmbeddings%28%0A      %28word_embeddings%29%3A Embedding%2828996...anh%28%29%0A    %29%0A  %29%0A  %28dropout%29%3A Dropout%28p=0.1%2C inplace=False%29%0A  %28classifier%29%3A Linear%28in_features=768%2C out_features=2%2C bias=True%29%0A%29" isContainer="True" />
<var name="ft_model_checkpoint" type="str" qualifier="builtins" value="test_trainer/checkpoint-7317" />
<var name="label_count" type="int" qualifier="builtins" value="2" />
<var name="model_name" type="str" qualifier="builtins" value="./bert-base-cased" />
<var name="result" type="list" qualifier="builtins" value="%5B%7B%27label%27%3A %27NEGATIVE%27%2C %27score%27%3A 0.998799204826355%7D%5D" isContainer="True" shape="1" />
<var name="sample_out" type="SequenceClassifierOutput" qualifier="transformers.modeling_outputs" value="SequenceClassifierOutput%28loss=None%2C logits=tensor%28%5B%5B-3.5080%2C  3.1830%5D%5D%2C grad_fn=%3CAddmmBackward0&gt;%29%2C hidden_states=None%2C attentions=None%29" isContainer="True" shape="1" />
<var name="sample_text" type="str" qualifier="builtins" value="How to Deal with Stress%2C Anxiety and Bipolar Disorder - Anxiety is one of many troubling symptoms of bipolar di... https%3A//t.co/34Al3y4eAE" />
<var name="sample_tokens" type="BatchEncoding" qualifier="transformers.tokenization_utils_base" value="%7B%27input_ids%27%3A tensor%28%5B%5B  101%2C  1731%2C  1106%2C 15361%2C  1114%2C  1457%2C  7370%2C   117%2C  1760%2C  8745%2C%0A         20656%2C  1105%2C   139%2C  97...%2C 0%2C 0%2C 0%2C%0A         0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C%0A         0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%5D%5D%29%7D" isContainer="True" shape="3" />
<var name="scores" type="ndarray" qualifier="numpy" value="%5B0.00124057 0.9987594 %5D" isContainer="True" shape="(2,)" />
<var name="shuffle" type="Dataset" qualifier="datasets.arrow_dataset" value="Dataset%28%7B%0A    features%3A %5B%27id%27%2C %27text%27%2C %27label%27%2C %27source_data%27%2C %27input_ids%27%2C %27token_type_ids%27%2C %27attention_mask%27%5D%2C%0A    num_rows%3A 10843%0A%7D%29" isContainer="True" shape="(10843, 7)" />
<var name="tokenizer" type="BertTokenizerFast" qualifier="transformers.models.bert.tokenization_bert_fast" value="BertTokenizerFast%28name_or_path=%27./bert-base-cased%27%2C vocab_size=28996%2C model_max_length=1000000000000000019884624838656%2C is_fas...se%2C special=True%29%2C%0A%09103%3A AddedToken%28%22%5BMASK%5D%22%2C rstrip=False%2C lstrip=False%2C single_word=False%2C normalized=False%2C special=True%29%2C%0A%7D" isContainer="True" shape="28996" />
<var name="train_count" type="int" qualifier="builtins" value="9758" />
<var name="trainer" type="Trainer" qualifier="transformers.trainer" value="%3Ctransformers.trainer.Trainer object at 0x0000027DAAA33190&gt;" isContainer="True" />
<var name="training_args" type="TrainingArguments" qualifier="transformers.training_args" value="TrainingArguments%28%0A_n_gpu=1%2C%0Aadafactor=False%2C%0Aadam_beta1=0.9%2C%0Aadam_beta2=0.999%2C%0Aadam_epsilon=1e-08%2C%0Aauto_find_batch_size=False...use_ipex=False%2C%0Ause_legacy_prediction_loop=False%2C%0Ause_mps_device=False%2C%0Awarmup_ratio=0.0%2C%0Awarmup_steps=100%2C%0Aweight_decay=0.0%2C%0A%29" isContainer="True" />
</xml>
[{'label': 'NEGATIVE', 'score': 0.9971976280212402}]
depressive score: 0.00013547632 neutral score: 0.99986446
<xml><var name="_dummy_ipython_val"  />
<var name="_dummy_special_var"  />
<var name="acc_metric" type="Accuracy" qualifier="evaluate_modules.metrics.accuracy.f887c0aab52c2d38e1f8a215681126379eca617f96c447638f751434e8e65b14.accuracy" value="EvaluationModule%28name%3A %22accuracy%22%2C module_type%3A %22metric%22%2C features%3A %7B%27predictions%27%3A Value%28dtype=%27int32%27%2C id=None%29%2C %27references...weight=%5B0.5%2C 2%2C 0.7%2C 0.5%2C 9%2C 0.4%5D%29%0A        &gt;&gt;&gt; print%28results%29%0A        %7B%27accuracy%27%3A 0.8778625954198473%7D%0A%22%22%22%2C stored examples%3A 0%29" isContainer="True" shape="0" />
<var name="base_model" type="BertForSequenceClassification" qualifier="transformers.models.bert.modeling_bert" value="BertForSequenceClassification%28%0A  %28bert%29%3A BertModel%28%0A    %28embeddings%29%3A BertEmbeddings%28%0A      %28word_embeddings%29%3A Embedding%2828996...anh%28%29%0A    %29%0A  %29%0A  %28dropout%29%3A Dropout%28p=0.1%2C inplace=False%29%0A  %28classifier%29%3A Linear%28in_features=768%2C out_features=2%2C bias=True%29%0A%29" isContainer="True" />
<var name="classifier" type="TextClassificationPipeline" qualifier="transformers.pipelines.text_classification" value="%3Ctransformers.pipelines.text_classification.TextClassificationPipeline object at 0x0000027E5A592910&gt;" isContainer="True" />
<var name="dataset" type="DatasetDict" qualifier="datasets.dataset_dict" value="DatasetDict%28%7B%0A    train%3A Dataset%28%7B%0A        features%3A %5B%27id%27%2C %27text%27%2C %27label%27%2C %27source_data%27%5D%2C%0A        num_rows%3A 10843%0A    %7D%29%0A%7D%29" isContainer="True" shape="('train',)" />
<var name="dataset_eval" type="Dataset" qualifier="datasets.arrow_dataset" value="Dataset%28%7B%0A    features%3A %5B%27id%27%2C %27text%27%2C %27label%27%2C %27source_data%27%2C %27input_ids%27%2C %27token_type_ids%27%2C %27attention_mask%27%5D%2C%0A    num_rows%3A 1085%0A%7D%29" isContainer="True" shape="(1085, 7)" />
<var name="dataset_tokens" type="DatasetDict" qualifier="datasets.dataset_dict" value="DatasetDict%28%7B%0A    train%3A Dataset%28%7B%0A        features%3A %5B%27id%27%2C %27text%27%2C %27label%27%2C %27source_data%27%2C %27input_ids%27%2C %27token_type_ids%27%2C %27attention_mask%27%5D%2C%0A        num_rows%3A 10843%0A    %7D%29%0A%7D%29" isContainer="True" shape="('train',)" />
<var name="dataset_train" type="Dataset" qualifier="datasets.arrow_dataset" value="Dataset%28%7B%0A    features%3A %5B%27id%27%2C %27text%27%2C %27label%27%2C %27source_data%27%2C %27input_ids%27%2C %27token_type_ids%27%2C %27attention_mask%27%5D%2C%0A    num_rows%3A 9758%0A%7D%29" isContainer="True" shape="(9758, 7)" />
<var name="ft_model" type="BertForSequenceClassification" qualifier="transformers.models.bert.modeling_bert" value="BertForSequenceClassification%28%0A  %28bert%29%3A BertModel%28%0A    %28embeddings%29%3A BertEmbeddings%28%0A      %28word_embeddings%29%3A Embedding%2828996...anh%28%29%0A    %29%0A  %29%0A  %28dropout%29%3A Dropout%28p=0.1%2C inplace=False%29%0A  %28classifier%29%3A Linear%28in_features=768%2C out_features=2%2C bias=True%29%0A%29" isContainer="True" />
<var name="ft_model_checkpoint" type="str" qualifier="builtins" value="test_trainer/checkpoint-7317" />
<var name="label_count" type="int" qualifier="builtins" value="2" />
<var name="model_name" type="str" qualifier="builtins" value="./bert-base-cased" />
<var name="result" type="list" qualifier="builtins" value="%5B%7B%27label%27%3A %27NEGATIVE%27%2C %27score%27%3A 0.9971976280212402%7D%5D" isContainer="True" shape="1" />
<var name="sample_out" type="SequenceClassifierOutput" qualifier="transformers.modeling_outputs" value="SequenceClassifierOutput%28loss=None%2C logits=tensor%28%5B%5B 4.5909%2C -4.3157%5D%5D%2C grad_fn=%3CAddmmBackward0&gt;%29%2C hidden_states=None%2C attentions=None%29" isContainer="True" shape="1" />
<var name="sample_text" type="str" qualifier="builtins" value="RT %40COCONUTOILBAE%3A when you want to be friends w ppl but ppl think ur mean and unapproachable cus u have a resting bitch face and soci%E2%80%A6 " />
<var name="sample_tokens" type="BatchEncoding" qualifier="transformers.tokenization_utils_base" value="%7B%27input_ids%27%3A tensor%28%5B%5B  101%2C   155%2C  1942%2C   137%2C 18732%2C 15678%2C 21760%2C 18082%2C 17656%2C  8215%2C%0A          2036%2C   131%2C  1165%2C  11...%2C 0%2C 0%2C 0%2C%0A         0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C%0A         0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%5D%5D%29%7D" isContainer="True" shape="3" />
<var name="scores" type="ndarray" qualifier="numpy" value="%5B9.9986446e-01 1.3547632e-04%5D" isContainer="True" shape="(2,)" />
<var name="shuffle" type="Dataset" qualifier="datasets.arrow_dataset" value="Dataset%28%7B%0A    features%3A %5B%27id%27%2C %27text%27%2C %27label%27%2C %27source_data%27%2C %27input_ids%27%2C %27token_type_ids%27%2C %27attention_mask%27%5D%2C%0A    num_rows%3A 10843%0A%7D%29" isContainer="True" shape="(10843, 7)" />
<var name="tokenizer" type="BertTokenizerFast" qualifier="transformers.models.bert.tokenization_bert_fast" value="BertTokenizerFast%28name_or_path=%27./bert-base-cased%27%2C vocab_size=28996%2C model_max_length=1000000000000000019884624838656%2C is_fas...se%2C special=True%29%2C%0A%09103%3A AddedToken%28%22%5BMASK%5D%22%2C rstrip=False%2C lstrip=False%2C single_word=False%2C normalized=False%2C special=True%29%2C%0A%7D" isContainer="True" shape="28996" />
<var name="train_count" type="int" qualifier="builtins" value="9758" />
<var name="trainer" type="Trainer" qualifier="transformers.trainer" value="%3Ctransformers.trainer.Trainer object at 0x0000027DAAA33190&gt;" isContainer="True" />
<var name="training_args" type="TrainingArguments" qualifier="transformers.training_args" value="TrainingArguments%28%0A_n_gpu=1%2C%0Aadafactor=False%2C%0Aadam_beta1=0.9%2C%0Aadam_beta2=0.999%2C%0Aadam_epsilon=1e-08%2C%0Aauto_find_batch_size=False...use_ipex=False%2C%0Ause_legacy_prediction_loop=False%2C%0Ause_mps_device=False%2C%0Awarmup_ratio=0.0%2C%0Awarmup_steps=100%2C%0Aweight_decay=0.0%2C%0A%29" isContainer="True" />
</xml>
[{'label': 'NEGATIVE', 'score': 0.9868893623352051}]
depressive score: 0.99965596 neutral score: 0.00034403554
<xml><var name="_dummy_ipython_val"  />
<var name="_dummy_special_var"  />
<var name="acc_metric" type="Accuracy" qualifier="evaluate_modules.metrics.accuracy.f887c0aab52c2d38e1f8a215681126379eca617f96c447638f751434e8e65b14.accuracy" value="EvaluationModule%28name%3A %22accuracy%22%2C module_type%3A %22metric%22%2C features%3A %7B%27predictions%27%3A Value%28dtype=%27int32%27%2C id=None%29%2C %27references...weight=%5B0.5%2C 2%2C 0.7%2C 0.5%2C 9%2C 0.4%5D%29%0A        &gt;&gt;&gt; print%28results%29%0A        %7B%27accuracy%27%3A 0.8778625954198473%7D%0A%22%22%22%2C stored examples%3A 0%29" isContainer="True" shape="0" />
<var name="base_model" type="BertForSequenceClassification" qualifier="transformers.models.bert.modeling_bert" value="BertForSequenceClassification%28%0A  %28bert%29%3A BertModel%28%0A    %28embeddings%29%3A BertEmbeddings%28%0A      %28word_embeddings%29%3A Embedding%2828996...anh%28%29%0A    %29%0A  %29%0A  %28dropout%29%3A Dropout%28p=0.1%2C inplace=False%29%0A  %28classifier%29%3A Linear%28in_features=768%2C out_features=2%2C bias=True%29%0A%29" isContainer="True" />
<var name="classifier" type="TextClassificationPipeline" qualifier="transformers.pipelines.text_classification" value="%3Ctransformers.pipelines.text_classification.TextClassificationPipeline object at 0x0000027E5A42FF50&gt;" isContainer="True" />
<var name="dataset" type="DatasetDict" qualifier="datasets.dataset_dict" value="DatasetDict%28%7B%0A    train%3A Dataset%28%7B%0A        features%3A %5B%27id%27%2C %27text%27%2C %27label%27%2C %27source_data%27%5D%2C%0A        num_rows%3A 10843%0A    %7D%29%0A%7D%29" isContainer="True" shape="('train',)" />
<var name="dataset_eval" type="Dataset" qualifier="datasets.arrow_dataset" value="Dataset%28%7B%0A    features%3A %5B%27id%27%2C %27text%27%2C %27label%27%2C %27source_data%27%2C %27input_ids%27%2C %27token_type_ids%27%2C %27attention_mask%27%5D%2C%0A    num_rows%3A 1085%0A%7D%29" isContainer="True" shape="(1085, 7)" />
<var name="dataset_tokens" type="DatasetDict" qualifier="datasets.dataset_dict" value="DatasetDict%28%7B%0A    train%3A Dataset%28%7B%0A        features%3A %5B%27id%27%2C %27text%27%2C %27label%27%2C %27source_data%27%2C %27input_ids%27%2C %27token_type_ids%27%2C %27attention_mask%27%5D%2C%0A        num_rows%3A 10843%0A    %7D%29%0A%7D%29" isContainer="True" shape="('train',)" />
<var name="dataset_train" type="Dataset" qualifier="datasets.arrow_dataset" value="Dataset%28%7B%0A    features%3A %5B%27id%27%2C %27text%27%2C %27label%27%2C %27source_data%27%2C %27input_ids%27%2C %27token_type_ids%27%2C %27attention_mask%27%5D%2C%0A    num_rows%3A 9758%0A%7D%29" isContainer="True" shape="(9758, 7)" />
<var name="ft_model" type="BertForSequenceClassification" qualifier="transformers.models.bert.modeling_bert" value="BertForSequenceClassification%28%0A  %28bert%29%3A BertModel%28%0A    %28embeddings%29%3A BertEmbeddings%28%0A      %28word_embeddings%29%3A Embedding%2828996...anh%28%29%0A    %29%0A  %29%0A  %28dropout%29%3A Dropout%28p=0.1%2C inplace=False%29%0A  %28classifier%29%3A Linear%28in_features=768%2C out_features=2%2C bias=True%29%0A%29" isContainer="True" />
<var name="ft_model_checkpoint" type="str" qualifier="builtins" value="test_trainer/checkpoint-7317" />
<var name="label_count" type="int" qualifier="builtins" value="2" />
<var name="model_name" type="str" qualifier="builtins" value="./bert-base-cased" />
<var name="result" type="list" qualifier="builtins" value="%5B%7B%27label%27%3A %27NEGATIVE%27%2C %27score%27%3A 0.9868893623352051%7D%5D" isContainer="True" shape="1" />
<var name="sample_out" type="SequenceClassifierOutput" qualifier="transformers.modeling_outputs" value="SequenceClassifierOutput%28loss=None%2C logits=tensor%28%5B%5B-4.2774%2C  3.6970%5D%5D%2C grad_fn=%3CAddmmBackward0&gt;%29%2C hidden_states=None%2C attentions=None%29" isContainer="True" shape="1" />
<var name="sample_text" type="str" qualifier="builtins" value="RT %40pettyblackboy%3A Me and my homegirls taking a break from our depression to turn up at local functions this summer https%3A//t.co/bhtbieNixW" />
<var name="sample_tokens" type="BatchEncoding" qualifier="transformers.tokenization_utils_base" value="%7B%27input_ids%27%3A tensor%28%5B%5B  101%2C   155%2C  1942%2C   137%2C 19701%2C 18075%2C  2158%2C  9858%2C   131%2C  2508%2C%0A          1105%2C  1139%2C  1313%2C 170...%2C 0%2C 0%2C 0%2C%0A         0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C%0A         0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%5D%5D%29%7D" isContainer="True" shape="3" />
<var name="scores" type="ndarray" qualifier="numpy" value="%5B3.4403554e-04 9.9965596e-01%5D" isContainer="True" shape="(2,)" />
<var name="shuffle" type="Dataset" qualifier="datasets.arrow_dataset" value="Dataset%28%7B%0A    features%3A %5B%27id%27%2C %27text%27%2C %27label%27%2C %27source_data%27%2C %27input_ids%27%2C %27token_type_ids%27%2C %27attention_mask%27%5D%2C%0A    num_rows%3A 10843%0A%7D%29" isContainer="True" shape="(10843, 7)" />
<var name="tokenizer" type="BertTokenizerFast" qualifier="transformers.models.bert.tokenization_bert_fast" value="BertTokenizerFast%28name_or_path=%27./bert-base-cased%27%2C vocab_size=28996%2C model_max_length=1000000000000000019884624838656%2C is_fas...se%2C special=True%29%2C%0A%09103%3A AddedToken%28%22%5BMASK%5D%22%2C rstrip=False%2C lstrip=False%2C single_word=False%2C normalized=False%2C special=True%29%2C%0A%7D" isContainer="True" shape="28996" />
<var name="train_count" type="int" qualifier="builtins" value="9758" />
<var name="trainer" type="Trainer" qualifier="transformers.trainer" value="%3Ctransformers.trainer.Trainer object at 0x0000027DAAA33190&gt;" isContainer="True" />
<var name="training_args" type="TrainingArguments" qualifier="transformers.training_args" value="TrainingArguments%28%0A_n_gpu=1%2C%0Aadafactor=False%2C%0Aadam_beta1=0.9%2C%0Aadam_beta2=0.999%2C%0Aadam_epsilon=1e-08%2C%0Aauto_find_batch_size=False...use_ipex=False%2C%0Ause_legacy_prediction_loop=False%2C%0Ause_mps_device=False%2C%0Awarmup_ratio=0.0%2C%0Awarmup_steps=100%2C%0Aweight_decay=0.0%2C%0A%29" isContainer="True" />
</xml>
[{'label': 'POSITIVE', 'score': 0.8650990724563599}]
depressive score: 0.0008739179 neutral score: 0.99912614
<xml><var name="_dummy_ipython_val"  />
<var name="_dummy_special_var"  />
<var name="acc_metric" type="Accuracy" qualifier="evaluate_modules.metrics.accuracy.f887c0aab52c2d38e1f8a215681126379eca617f96c447638f751434e8e65b14.accuracy" value="EvaluationModule%28name%3A %22accuracy%22%2C module_type%3A %22metric%22%2C features%3A %7B%27predictions%27%3A Value%28dtype=%27int32%27%2C id=None%29%2C %27references...weight=%5B0.5%2C 2%2C 0.7%2C 0.5%2C 9%2C 0.4%5D%29%0A        &gt;&gt;&gt; print%28results%29%0A        %7B%27accuracy%27%3A 0.8778625954198473%7D%0A%22%22%22%2C stored examples%3A 0%29" isContainer="True" shape="0" />
<var name="base_model" type="BertForSequenceClassification" qualifier="transformers.models.bert.modeling_bert" value="BertForSequenceClassification%28%0A  %28bert%29%3A BertModel%28%0A    %28embeddings%29%3A BertEmbeddings%28%0A      %28word_embeddings%29%3A Embedding%2828996...anh%28%29%0A    %29%0A  %29%0A  %28dropout%29%3A Dropout%28p=0.1%2C inplace=False%29%0A  %28classifier%29%3A Linear%28in_features=768%2C out_features=2%2C bias=True%29%0A%29" isContainer="True" />
<var name="classifier" type="TextClassificationPipeline" qualifier="transformers.pipelines.text_classification" value="%3Ctransformers.pipelines.text_classification.TextClassificationPipeline object at 0x0000027DD5199010&gt;" isContainer="True" />
<var name="dataset" type="DatasetDict" qualifier="datasets.dataset_dict" value="DatasetDict%28%7B%0A    train%3A Dataset%28%7B%0A        features%3A %5B%27id%27%2C %27text%27%2C %27label%27%2C %27source_data%27%5D%2C%0A        num_rows%3A 10843%0A    %7D%29%0A%7D%29" isContainer="True" shape="('train',)" />
<var name="dataset_eval" type="Dataset" qualifier="datasets.arrow_dataset" value="Dataset%28%7B%0A    features%3A %5B%27id%27%2C %27text%27%2C %27label%27%2C %27source_data%27%2C %27input_ids%27%2C %27token_type_ids%27%2C %27attention_mask%27%5D%2C%0A    num_rows%3A 1085%0A%7D%29" isContainer="True" shape="(1085, 7)" />
<var name="dataset_tokens" type="DatasetDict" qualifier="datasets.dataset_dict" value="DatasetDict%28%7B%0A    train%3A Dataset%28%7B%0A        features%3A %5B%27id%27%2C %27text%27%2C %27label%27%2C %27source_data%27%2C %27input_ids%27%2C %27token_type_ids%27%2C %27attention_mask%27%5D%2C%0A        num_rows%3A 10843%0A    %7D%29%0A%7D%29" isContainer="True" shape="('train',)" />
<var name="dataset_train" type="Dataset" qualifier="datasets.arrow_dataset" value="Dataset%28%7B%0A    features%3A %5B%27id%27%2C %27text%27%2C %27label%27%2C %27source_data%27%2C %27input_ids%27%2C %27token_type_ids%27%2C %27attention_mask%27%5D%2C%0A    num_rows%3A 9758%0A%7D%29" isContainer="True" shape="(9758, 7)" />
<var name="ft_model" type="BertForSequenceClassification" qualifier="transformers.models.bert.modeling_bert" value="BertForSequenceClassification%28%0A  %28bert%29%3A BertModel%28%0A    %28embeddings%29%3A BertEmbeddings%28%0A      %28word_embeddings%29%3A Embedding%2828996...anh%28%29%0A    %29%0A  %29%0A  %28dropout%29%3A Dropout%28p=0.1%2C inplace=False%29%0A  %28classifier%29%3A Linear%28in_features=768%2C out_features=2%2C bias=True%29%0A%29" isContainer="True" />
<var name="ft_model_checkpoint" type="str" qualifier="builtins" value="test_trainer/checkpoint-7317" />
<var name="label_count" type="int" qualifier="builtins" value="2" />
<var name="model_name" type="str" qualifier="builtins" value="./bert-base-cased" />
<var name="result" type="list" qualifier="builtins" value="%5B%7B%27label%27%3A %27POSITIVE%27%2C %27score%27%3A 0.8650990724563599%7D%5D" isContainer="True" shape="1" />
<var name="sample_out" type="SequenceClassifierOutput" qualifier="transformers.modeling_outputs" value="SequenceClassifierOutput%28loss=None%2C logits=tensor%28%5B%5B 3.3724%2C -3.6693%5D%5D%2C grad_fn=%3CAddmmBackward0&gt;%29%2C hidden_states=None%2C attentions=None%29" isContainer="True" shape="1" />
<var name="sample_text" type="str" qualifier="builtins" value="RT %40lucasbavid%3A Me%3A I am gonna make art today%2C there%27s no reason to be depressed all day My depression%3A https%3A//t.co/uOD0RacMpB" />
<var name="sample_tokens" type="BatchEncoding" qualifier="transformers.tokenization_utils_base" value="%7B%27input_ids%27%3A tensor%28%5B%5B  101%2C   155%2C  1942%2C   137%2C   181%2C 23315%2C  1116%2C  2822%2C 18312%2C   131%2C%0A          2508%2C   131%2C   146%2C  18...%2C 0%2C 0%2C 0%2C%0A         0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C%0A         0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%5D%5D%29%7D" isContainer="True" shape="3" />
<var name="scores" type="ndarray" qualifier="numpy" value="%5B9.9912614e-01 8.7391789e-04%5D" isContainer="True" shape="(2,)" />
<var name="shuffle" type="Dataset" qualifier="datasets.arrow_dataset" value="Dataset%28%7B%0A    features%3A %5B%27id%27%2C %27text%27%2C %27label%27%2C %27source_data%27%2C %27input_ids%27%2C %27token_type_ids%27%2C %27attention_mask%27%5D%2C%0A    num_rows%3A 10843%0A%7D%29" isContainer="True" shape="(10843, 7)" />
<var name="tokenizer" type="BertTokenizerFast" qualifier="transformers.models.bert.tokenization_bert_fast" value="BertTokenizerFast%28name_or_path=%27./bert-base-cased%27%2C vocab_size=28996%2C model_max_length=1000000000000000019884624838656%2C is_fas...se%2C special=True%29%2C%0A%09103%3A AddedToken%28%22%5BMASK%5D%22%2C rstrip=False%2C lstrip=False%2C single_word=False%2C normalized=False%2C special=True%29%2C%0A%7D" isContainer="True" shape="28996" />
<var name="train_count" type="int" qualifier="builtins" value="9758" />
<var name="trainer" type="Trainer" qualifier="transformers.trainer" value="%3Ctransformers.trainer.Trainer object at 0x0000027DAAA33190&gt;" isContainer="True" />
<var name="training_args" type="TrainingArguments" qualifier="transformers.training_args" value="TrainingArguments%28%0A_n_gpu=1%2C%0Aadafactor=False%2C%0Aadam_beta1=0.9%2C%0Aadam_beta2=0.999%2C%0Aadam_epsilon=1e-08%2C%0Aauto_find_batch_size=False...use_ipex=False%2C%0Ause_legacy_prediction_loop=False%2C%0Ause_mps_device=False%2C%0Awarmup_ratio=0.0%2C%0Awarmup_steps=100%2C%0Aweight_decay=0.0%2C%0A%29" isContainer="True" />
</xml>
[{'label': 'POSITIVE', 'score': 0.9739630222320557}]
depressive score: 0.05803999 neutral score: 0.94196004
<xml><var name="_dummy_ipython_val"  />
<var name="_dummy_special_var"  />
<var name="acc_metric" type="Accuracy" qualifier="evaluate_modules.metrics.accuracy.f887c0aab52c2d38e1f8a215681126379eca617f96c447638f751434e8e65b14.accuracy" value="EvaluationModule%28name%3A %22accuracy%22%2C module_type%3A %22metric%22%2C features%3A %7B%27predictions%27%3A Value%28dtype=%27int32%27%2C id=None%29%2C %27references...weight=%5B0.5%2C 2%2C 0.7%2C 0.5%2C 9%2C 0.4%5D%29%0A        &gt;&gt;&gt; print%28results%29%0A        %7B%27accuracy%27%3A 0.8778625954198473%7D%0A%22%22%22%2C stored examples%3A 0%29" isContainer="True" shape="0" />
<var name="base_model" type="BertForSequenceClassification" qualifier="transformers.models.bert.modeling_bert" value="BertForSequenceClassification%28%0A  %28bert%29%3A BertModel%28%0A    %28embeddings%29%3A BertEmbeddings%28%0A      %28word_embeddings%29%3A Embedding%2828996...anh%28%29%0A    %29%0A  %29%0A  %28dropout%29%3A Dropout%28p=0.1%2C inplace=False%29%0A  %28classifier%29%3A Linear%28in_features=768%2C out_features=2%2C bias=True%29%0A%29" isContainer="True" />
<var name="classifier" type="TextClassificationPipeline" qualifier="transformers.pipelines.text_classification" value="%3Ctransformers.pipelines.text_classification.TextClassificationPipeline object at 0x0000027E3D936410&gt;" isContainer="True" />
<var name="dataset" type="DatasetDict" qualifier="datasets.dataset_dict" value="DatasetDict%28%7B%0A    train%3A Dataset%28%7B%0A        features%3A %5B%27id%27%2C %27text%27%2C %27label%27%2C %27source_data%27%5D%2C%0A        num_rows%3A 10843%0A    %7D%29%0A%7D%29" isContainer="True" shape="('train',)" />
<var name="dataset_eval" type="Dataset" qualifier="datasets.arrow_dataset" value="Dataset%28%7B%0A    features%3A %5B%27id%27%2C %27text%27%2C %27label%27%2C %27source_data%27%2C %27input_ids%27%2C %27token_type_ids%27%2C %27attention_mask%27%5D%2C%0A    num_rows%3A 1085%0A%7D%29" isContainer="True" shape="(1085, 7)" />
<var name="dataset_tokens" type="DatasetDict" qualifier="datasets.dataset_dict" value="DatasetDict%28%7B%0A    train%3A Dataset%28%7B%0A        features%3A %5B%27id%27%2C %27text%27%2C %27label%27%2C %27source_data%27%2C %27input_ids%27%2C %27token_type_ids%27%2C %27attention_mask%27%5D%2C%0A        num_rows%3A 10843%0A    %7D%29%0A%7D%29" isContainer="True" shape="('train',)" />
<var name="dataset_train" type="Dataset" qualifier="datasets.arrow_dataset" value="Dataset%28%7B%0A    features%3A %5B%27id%27%2C %27text%27%2C %27label%27%2C %27source_data%27%2C %27input_ids%27%2C %27token_type_ids%27%2C %27attention_mask%27%5D%2C%0A    num_rows%3A 9758%0A%7D%29" isContainer="True" shape="(9758, 7)" />
<var name="ft_model" type="BertForSequenceClassification" qualifier="transformers.models.bert.modeling_bert" value="BertForSequenceClassification%28%0A  %28bert%29%3A BertModel%28%0A    %28embeddings%29%3A BertEmbeddings%28%0A      %28word_embeddings%29%3A Embedding%2828996...anh%28%29%0A    %29%0A  %29%0A  %28dropout%29%3A Dropout%28p=0.1%2C inplace=False%29%0A  %28classifier%29%3A Linear%28in_features=768%2C out_features=2%2C bias=True%29%0A%29" isContainer="True" />
<var name="ft_model_checkpoint" type="str" qualifier="builtins" value="test_trainer/checkpoint-7317" />
<var name="label_count" type="int" qualifier="builtins" value="2" />
<var name="model_name" type="str" qualifier="builtins" value="./bert-base-cased" />
<var name="result" type="list" qualifier="builtins" value="%5B%7B%27label%27%3A %27POSITIVE%27%2C %27score%27%3A 0.9739630222320557%7D%5D" isContainer="True" shape="1" />
<var name="sample_out" type="SequenceClassifierOutput" qualifier="transformers.modeling_outputs" value="SequenceClassifierOutput%28loss=None%2C logits=tensor%28%5B%5B 1.2591%2C -1.5277%5D%5D%2C grad_fn=%3CAddmmBackward0&gt;%29%2C hidden_states=None%2C attentions=None%29" isContainer="True" shape="1" />
<var name="sample_text" type="str" qualifier="builtins" value="UR PRECIOUS AND ADORABLE HBAHDDHADDBAJ https%3A//t.co/MR6GwE7Aex" />
<var name="sample_tokens" type="BatchEncoding" qualifier="transformers.tokenization_utils_base" value="%7B%27input_ids%27%3A tensor%28%5B%5B  101%2C   158%2C  2069%2C 11629%2C  8231%2C 19368%2C 13329%2C 16716%2C  5844%2C  9565%2C%0A         19985%2C 17516%2C   145%2C  82...%2C 0%2C 0%2C 0%2C%0A         0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C%0A         0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%5D%5D%29%7D" isContainer="True" shape="3" />
<var name="scores" type="ndarray" qualifier="numpy" value="%5B0.94196004 0.05803999%5D" isContainer="True" shape="(2,)" />
<var name="shuffle" type="Dataset" qualifier="datasets.arrow_dataset" value="Dataset%28%7B%0A    features%3A %5B%27id%27%2C %27text%27%2C %27label%27%2C %27source_data%27%2C %27input_ids%27%2C %27token_type_ids%27%2C %27attention_mask%27%5D%2C%0A    num_rows%3A 10843%0A%7D%29" isContainer="True" shape="(10843, 7)" />
<var name="tokenizer" type="BertTokenizerFast" qualifier="transformers.models.bert.tokenization_bert_fast" value="BertTokenizerFast%28name_or_path=%27./bert-base-cased%27%2C vocab_size=28996%2C model_max_length=1000000000000000019884624838656%2C is_fas...se%2C special=True%29%2C%0A%09103%3A AddedToken%28%22%5BMASK%5D%22%2C rstrip=False%2C lstrip=False%2C single_word=False%2C normalized=False%2C special=True%29%2C%0A%7D" isContainer="True" shape="28996" />
<var name="train_count" type="int" qualifier="builtins" value="9758" />
<var name="trainer" type="Trainer" qualifier="transformers.trainer" value="%3Ctransformers.trainer.Trainer object at 0x0000027DAAA33190&gt;" isContainer="True" />
<var name="training_args" type="TrainingArguments" qualifier="transformers.training_args" value="TrainingArguments%28%0A_n_gpu=1%2C%0Aadafactor=False%2C%0Aadam_beta1=0.9%2C%0Aadam_beta2=0.999%2C%0Aadam_epsilon=1e-08%2C%0Aauto_find_batch_size=False...use_ipex=False%2C%0Ause_legacy_prediction_loop=False%2C%0Ause_mps_device=False%2C%0Awarmup_ratio=0.0%2C%0Awarmup_steps=100%2C%0Aweight_decay=0.0%2C%0A%29" isContainer="True" />
</xml>
[{'label': 'NEGATIVE', 'score': 0.9987989664077759}]
depressive score: 0.9828876 neutral score: 0.017112372
<xml><var name="_dummy_ipython_val"  />
<var name="_dummy_special_var"  />
<var name="acc_metric" type="Accuracy" qualifier="evaluate_modules.metrics.accuracy.f887c0aab52c2d38e1f8a215681126379eca617f96c447638f751434e8e65b14.accuracy" value="EvaluationModule%28name%3A %22accuracy%22%2C module_type%3A %22metric%22%2C features%3A %7B%27predictions%27%3A Value%28dtype=%27int32%27%2C id=None%29%2C %27references...weight=%5B0.5%2C 2%2C 0.7%2C 0.5%2C 9%2C 0.4%5D%29%0A        &gt;&gt;&gt; print%28results%29%0A        %7B%27accuracy%27%3A 0.8778625954198473%7D%0A%22%22%22%2C stored examples%3A 0%29" isContainer="True" shape="0" />
<var name="base_model" type="BertForSequenceClassification" qualifier="transformers.models.bert.modeling_bert" value="BertForSequenceClassification%28%0A  %28bert%29%3A BertModel%28%0A    %28embeddings%29%3A BertEmbeddings%28%0A      %28word_embeddings%29%3A Embedding%2828996...anh%28%29%0A    %29%0A  %29%0A  %28dropout%29%3A Dropout%28p=0.1%2C inplace=False%29%0A  %28classifier%29%3A Linear%28in_features=768%2C out_features=2%2C bias=True%29%0A%29" isContainer="True" />
<var name="classifier" type="TextClassificationPipeline" qualifier="transformers.pipelines.text_classification" value="%3Ctransformers.pipelines.text_classification.TextClassificationPipeline object at 0x0000027E5A53C550&gt;" isContainer="True" />
<var name="dataset" type="DatasetDict" qualifier="datasets.dataset_dict" value="DatasetDict%28%7B%0A    train%3A Dataset%28%7B%0A        features%3A %5B%27id%27%2C %27text%27%2C %27label%27%2C %27source_data%27%5D%2C%0A        num_rows%3A 10843%0A    %7D%29%0A%7D%29" isContainer="True" shape="('train',)" />
<var name="dataset_eval" type="Dataset" qualifier="datasets.arrow_dataset" value="Dataset%28%7B%0A    features%3A %5B%27id%27%2C %27text%27%2C %27label%27%2C %27source_data%27%2C %27input_ids%27%2C %27token_type_ids%27%2C %27attention_mask%27%5D%2C%0A    num_rows%3A 1085%0A%7D%29" isContainer="True" shape="(1085, 7)" />
<var name="dataset_tokens" type="DatasetDict" qualifier="datasets.dataset_dict" value="DatasetDict%28%7B%0A    train%3A Dataset%28%7B%0A        features%3A %5B%27id%27%2C %27text%27%2C %27label%27%2C %27source_data%27%2C %27input_ids%27%2C %27token_type_ids%27%2C %27attention_mask%27%5D%2C%0A        num_rows%3A 10843%0A    %7D%29%0A%7D%29" isContainer="True" shape="('train',)" />
<var name="dataset_train" type="Dataset" qualifier="datasets.arrow_dataset" value="Dataset%28%7B%0A    features%3A %5B%27id%27%2C %27text%27%2C %27label%27%2C %27source_data%27%2C %27input_ids%27%2C %27token_type_ids%27%2C %27attention_mask%27%5D%2C%0A    num_rows%3A 9758%0A%7D%29" isContainer="True" shape="(9758, 7)" />
<var name="ft_model" type="BertForSequenceClassification" qualifier="transformers.models.bert.modeling_bert" value="BertForSequenceClassification%28%0A  %28bert%29%3A BertModel%28%0A    %28embeddings%29%3A BertEmbeddings%28%0A      %28word_embeddings%29%3A Embedding%2828996...anh%28%29%0A    %29%0A  %29%0A  %28dropout%29%3A Dropout%28p=0.1%2C inplace=False%29%0A  %28classifier%29%3A Linear%28in_features=768%2C out_features=2%2C bias=True%29%0A%29" isContainer="True" />
<var name="ft_model_checkpoint" type="str" qualifier="builtins" value="test_trainer/checkpoint-7317" />
<var name="label_count" type="int" qualifier="builtins" value="2" />
<var name="model_name" type="str" qualifier="builtins" value="./bert-base-cased" />
<var name="result" type="list" qualifier="builtins" value="%5B%7B%27label%27%3A %27NEGATIVE%27%2C %27score%27%3A 0.9987989664077759%7D%5D" isContainer="True" shape="1" />
<var name="sample_out" type="SequenceClassifierOutput" qualifier="transformers.modeling_outputs" value="SequenceClassifierOutput%28loss=None%2C logits=tensor%28%5B%5B-2.2934%2C  1.7573%5D%5D%2C grad_fn=%3CAddmmBackward0&gt;%29%2C hidden_states=None%2C attentions=None%29" isContainer="True" shape="1" />
<var name="sample_text" type="str" qualifier="builtins" value="RT %40_Liviiiiii%3A it%27s fucking me https%3A//t.co/808i3s7hmQ" />
<var name="sample_tokens" type="BatchEncoding" qualifier="transformers.tokenization_utils_base" value="%7B%27input_ids%27%3A tensor%28%5B%5B  101%2C   155%2C  1942%2C   137%2C   168%2C 26997%2C  6904%2C  6904%2C  6904%2C   131%2C%0A          1122%2C   112%2C   188%2C  87...%2C 0%2C 0%2C 0%2C%0A         0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C%0A         0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%5D%5D%29%7D" isContainer="True" shape="3" />
<var name="scores" type="ndarray" qualifier="numpy" value="%5B0.01711237 0.9828876 %5D" isContainer="True" shape="(2,)" />
<var name="shuffle" type="Dataset" qualifier="datasets.arrow_dataset" value="Dataset%28%7B%0A    features%3A %5B%27id%27%2C %27text%27%2C %27label%27%2C %27source_data%27%2C %27input_ids%27%2C %27token_type_ids%27%2C %27attention_mask%27%5D%2C%0A    num_rows%3A 10843%0A%7D%29" isContainer="True" shape="(10843, 7)" />
<var name="tokenizer" type="BertTokenizerFast" qualifier="transformers.models.bert.tokenization_bert_fast" value="BertTokenizerFast%28name_or_path=%27./bert-base-cased%27%2C vocab_size=28996%2C model_max_length=1000000000000000019884624838656%2C is_fas...se%2C special=True%29%2C%0A%09103%3A AddedToken%28%22%5BMASK%5D%22%2C rstrip=False%2C lstrip=False%2C single_word=False%2C normalized=False%2C special=True%29%2C%0A%7D" isContainer="True" shape="28996" />
<var name="train_count" type="int" qualifier="builtins" value="9758" />
<var name="trainer" type="Trainer" qualifier="transformers.trainer" value="%3Ctransformers.trainer.Trainer object at 0x0000027DAAA33190&gt;" isContainer="True" />
<var name="training_args" type="TrainingArguments" qualifier="transformers.training_args" value="TrainingArguments%28%0A_n_gpu=1%2C%0Aadafactor=False%2C%0Aadam_beta1=0.9%2C%0Aadam_beta2=0.999%2C%0Aadam_epsilon=1e-08%2C%0Aauto_find_batch_size=False...use_ipex=False%2C%0Ause_legacy_prediction_loop=False%2C%0Ause_mps_device=False%2C%0Awarmup_ratio=0.0%2C%0Awarmup_steps=100%2C%0Aweight_decay=0.0%2C%0A%29" isContainer="True" />
</xml>
[{'label': 'NEGATIVE', 'score': 0.9808326959609985}]
depressive score: 0.9990225 neutral score: 0.0009775396
<xml><var name="_dummy_ipython_val"  />
<var name="_dummy_special_var"  />
<var name="acc_metric" type="Accuracy" qualifier="evaluate_modules.metrics.accuracy.f887c0aab52c2d38e1f8a215681126379eca617f96c447638f751434e8e65b14.accuracy" value="EvaluationModule%28name%3A %22accuracy%22%2C module_type%3A %22metric%22%2C features%3A %7B%27predictions%27%3A Value%28dtype=%27int32%27%2C id=None%29%2C %27references...weight=%5B0.5%2C 2%2C 0.7%2C 0.5%2C 9%2C 0.4%5D%29%0A        &gt;&gt;&gt; print%28results%29%0A        %7B%27accuracy%27%3A 0.8778625954198473%7D%0A%22%22%22%2C stored examples%3A 0%29" isContainer="True" shape="0" />
<var name="base_model" type="BertForSequenceClassification" qualifier="transformers.models.bert.modeling_bert" value="BertForSequenceClassification%28%0A  %28bert%29%3A BertModel%28%0A    %28embeddings%29%3A BertEmbeddings%28%0A      %28word_embeddings%29%3A Embedding%2828996...anh%28%29%0A    %29%0A  %29%0A  %28dropout%29%3A Dropout%28p=0.1%2C inplace=False%29%0A  %28classifier%29%3A Linear%28in_features=768%2C out_features=2%2C bias=True%29%0A%29" isContainer="True" />
<var name="classifier" type="TextClassificationPipeline" qualifier="transformers.pipelines.text_classification" value="%3Ctransformers.pipelines.text_classification.TextClassificationPipeline object at 0x0000027DAAA56C10&gt;" isContainer="True" />
<var name="dataset" type="DatasetDict" qualifier="datasets.dataset_dict" value="DatasetDict%28%7B%0A    train%3A Dataset%28%7B%0A        features%3A %5B%27id%27%2C %27text%27%2C %27label%27%2C %27source_data%27%5D%2C%0A        num_rows%3A 10843%0A    %7D%29%0A%7D%29" isContainer="True" shape="('train',)" />
<var name="dataset_eval" type="Dataset" qualifier="datasets.arrow_dataset" value="Dataset%28%7B%0A    features%3A %5B%27id%27%2C %27text%27%2C %27label%27%2C %27source_data%27%2C %27input_ids%27%2C %27token_type_ids%27%2C %27attention_mask%27%5D%2C%0A    num_rows%3A 1085%0A%7D%29" isContainer="True" shape="(1085, 7)" />
<var name="dataset_tokens" type="DatasetDict" qualifier="datasets.dataset_dict" value="DatasetDict%28%7B%0A    train%3A Dataset%28%7B%0A        features%3A %5B%27id%27%2C %27text%27%2C %27label%27%2C %27source_data%27%2C %27input_ids%27%2C %27token_type_ids%27%2C %27attention_mask%27%5D%2C%0A        num_rows%3A 10843%0A    %7D%29%0A%7D%29" isContainer="True" shape="('train',)" />
<var name="dataset_train" type="Dataset" qualifier="datasets.arrow_dataset" value="Dataset%28%7B%0A    features%3A %5B%27id%27%2C %27text%27%2C %27label%27%2C %27source_data%27%2C %27input_ids%27%2C %27token_type_ids%27%2C %27attention_mask%27%5D%2C%0A    num_rows%3A 9758%0A%7D%29" isContainer="True" shape="(9758, 7)" />
<var name="ft_model" type="BertForSequenceClassification" qualifier="transformers.models.bert.modeling_bert" value="BertForSequenceClassification%28%0A  %28bert%29%3A BertModel%28%0A    %28embeddings%29%3A BertEmbeddings%28%0A      %28word_embeddings%29%3A Embedding%2828996...anh%28%29%0A    %29%0A  %29%0A  %28dropout%29%3A Dropout%28p=0.1%2C inplace=False%29%0A  %28classifier%29%3A Linear%28in_features=768%2C out_features=2%2C bias=True%29%0A%29" isContainer="True" />
<var name="ft_model_checkpoint" type="str" qualifier="builtins" value="test_trainer/checkpoint-7317" />
<var name="label_count" type="int" qualifier="builtins" value="2" />
<var name="model_name" type="str" qualifier="builtins" value="./bert-base-cased" />
<var name="result" type="list" qualifier="builtins" value="%5B%7B%27label%27%3A %27NEGATIVE%27%2C %27score%27%3A 0.9808326959609985%7D%5D" isContainer="True" shape="1" />
<var name="sample_out" type="SequenceClassifierOutput" qualifier="transformers.modeling_outputs" value="SequenceClassifierOutput%28loss=None%2C logits=tensor%28%5B%5B-3.6528%2C  3.2767%5D%5D%2C grad_fn=%3CAddmmBackward0&gt;%29%2C hidden_states=None%2C attentions=None%29" isContainer="True" shape="1" />
<var name="sample_text" type="str" qualifier="builtins" value="Hey%2C look - I found my social anxiety again. Was wondering where that went." />
<var name="sample_tokens" type="BatchEncoding" qualifier="transformers.tokenization_utils_base" value="%7B%27input_ids%27%3A tensor%28%5B%5B  101%2C  4403%2C   117%2C  1440%2C   118%2C   146%2C  1276%2C  1139%2C  1934%2C 10507%2C%0A          1254%2C   119%2C  3982%2C  61...%2C 0%2C 0%2C 0%2C%0A         0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C%0A         0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%5D%5D%29%7D" isContainer="True" shape="3" />
<var name="scores" type="ndarray" qualifier="numpy" value="%5B9.775396e-04 9.990225e-01%5D" isContainer="True" shape="(2,)" />
<var name="shuffle" type="Dataset" qualifier="datasets.arrow_dataset" value="Dataset%28%7B%0A    features%3A %5B%27id%27%2C %27text%27%2C %27label%27%2C %27source_data%27%2C %27input_ids%27%2C %27token_type_ids%27%2C %27attention_mask%27%5D%2C%0A    num_rows%3A 10843%0A%7D%29" isContainer="True" shape="(10843, 7)" />
<var name="tokenizer" type="BertTokenizerFast" qualifier="transformers.models.bert.tokenization_bert_fast" value="BertTokenizerFast%28name_or_path=%27./bert-base-cased%27%2C vocab_size=28996%2C model_max_length=1000000000000000019884624838656%2C is_fas...se%2C special=True%29%2C%0A%09103%3A AddedToken%28%22%5BMASK%5D%22%2C rstrip=False%2C lstrip=False%2C single_word=False%2C normalized=False%2C special=True%29%2C%0A%7D" isContainer="True" shape="28996" />
<var name="train_count" type="int" qualifier="builtins" value="9758" />
<var name="trainer" type="Trainer" qualifier="transformers.trainer" value="%3Ctransformers.trainer.Trainer object at 0x0000027DAAA33190&gt;" isContainer="True" />
<var name="training_args" type="TrainingArguments" qualifier="transformers.training_args" value="TrainingArguments%28%0A_n_gpu=1%2C%0Aadafactor=False%2C%0Aadam_beta1=0.9%2C%0Aadam_beta2=0.999%2C%0Aadam_epsilon=1e-08%2C%0Aauto_find_batch_size=False...use_ipex=False%2C%0Ause_legacy_prediction_loop=False%2C%0Ause_mps_device=False%2C%0Awarmup_ratio=0.0%2C%0Awarmup_steps=100%2C%0Aweight_decay=0.0%2C%0A%29" isContainer="True" />
</xml>
[{'label': 'NEGATIVE', 'score': 0.9963405132293701}]
depressive score: 0.99967575 neutral score: 0.00032425713
<xml><var name="_dummy_ipython_val"  />
<var name="_dummy_special_var"  />
<var name="acc_metric" type="Accuracy" qualifier="evaluate_modules.metrics.accuracy.f887c0aab52c2d38e1f8a215681126379eca617f96c447638f751434e8e65b14.accuracy" value="EvaluationModule%28name%3A %22accuracy%22%2C module_type%3A %22metric%22%2C features%3A %7B%27predictions%27%3A Value%28dtype=%27int32%27%2C id=None%29%2C %27references...weight=%5B0.5%2C 2%2C 0.7%2C 0.5%2C 9%2C 0.4%5D%29%0A        &gt;&gt;&gt; print%28results%29%0A        %7B%27accuracy%27%3A 0.8778625954198473%7D%0A%22%22%22%2C stored examples%3A 0%29" isContainer="True" shape="0" />
<var name="base_model" type="BertForSequenceClassification" qualifier="transformers.models.bert.modeling_bert" value="BertForSequenceClassification%28%0A  %28bert%29%3A BertModel%28%0A    %28embeddings%29%3A BertEmbeddings%28%0A      %28word_embeddings%29%3A Embedding%2828996...anh%28%29%0A    %29%0A  %29%0A  %28dropout%29%3A Dropout%28p=0.1%2C inplace=False%29%0A  %28classifier%29%3A Linear%28in_features=768%2C out_features=2%2C bias=True%29%0A%29" isContainer="True" />
<var name="classifier" type="TextClassificationPipeline" qualifier="transformers.pipelines.text_classification" value="%3Ctransformers.pipelines.text_classification.TextClassificationPipeline object at 0x0000027E5A4AAA10&gt;" isContainer="True" />
<var name="dataset" type="DatasetDict" qualifier="datasets.dataset_dict" value="DatasetDict%28%7B%0A    train%3A Dataset%28%7B%0A        features%3A %5B%27id%27%2C %27text%27%2C %27label%27%2C %27source_data%27%5D%2C%0A        num_rows%3A 10843%0A    %7D%29%0A%7D%29" isContainer="True" shape="('train',)" />
<var name="dataset_eval" type="Dataset" qualifier="datasets.arrow_dataset" value="Dataset%28%7B%0A    features%3A %5B%27id%27%2C %27text%27%2C %27label%27%2C %27source_data%27%2C %27input_ids%27%2C %27token_type_ids%27%2C %27attention_mask%27%5D%2C%0A    num_rows%3A 1085%0A%7D%29" isContainer="True" shape="(1085, 7)" />
<var name="dataset_tokens" type="DatasetDict" qualifier="datasets.dataset_dict" value="DatasetDict%28%7B%0A    train%3A Dataset%28%7B%0A        features%3A %5B%27id%27%2C %27text%27%2C %27label%27%2C %27source_data%27%2C %27input_ids%27%2C %27token_type_ids%27%2C %27attention_mask%27%5D%2C%0A        num_rows%3A 10843%0A    %7D%29%0A%7D%29" isContainer="True" shape="('train',)" />
<var name="dataset_train" type="Dataset" qualifier="datasets.arrow_dataset" value="Dataset%28%7B%0A    features%3A %5B%27id%27%2C %27text%27%2C %27label%27%2C %27source_data%27%2C %27input_ids%27%2C %27token_type_ids%27%2C %27attention_mask%27%5D%2C%0A    num_rows%3A 9758%0A%7D%29" isContainer="True" shape="(9758, 7)" />
<var name="ft_model" type="BertForSequenceClassification" qualifier="transformers.models.bert.modeling_bert" value="BertForSequenceClassification%28%0A  %28bert%29%3A BertModel%28%0A    %28embeddings%29%3A BertEmbeddings%28%0A      %28word_embeddings%29%3A Embedding%2828996...anh%28%29%0A    %29%0A  %29%0A  %28dropout%29%3A Dropout%28p=0.1%2C inplace=False%29%0A  %28classifier%29%3A Linear%28in_features=768%2C out_features=2%2C bias=True%29%0A%29" isContainer="True" />
<var name="ft_model_checkpoint" type="str" qualifier="builtins" value="test_trainer/checkpoint-7317" />
<var name="label_count" type="int" qualifier="builtins" value="2" />
<var name="model_name" type="str" qualifier="builtins" value="./bert-base-cased" />
<var name="result" type="list" qualifier="builtins" value="%5B%7B%27label%27%3A %27NEGATIVE%27%2C %27score%27%3A 0.9963405132293701%7D%5D" isContainer="True" shape="1" />
<var name="sample_out" type="SequenceClassifierOutput" qualifier="transformers.modeling_outputs" value="SequenceClassifierOutput%28loss=None%2C logits=tensor%28%5B%5B-4.3590%2C  3.6747%5D%5D%2C grad_fn=%3CAddmmBackward0&gt;%29%2C hidden_states=None%2C attentions=None%29" isContainer="True" shape="1" />
<var name="sample_text" type="str" qualifier="builtins" value="I die if I am unhappy" />
<var name="sample_tokens" type="BatchEncoding" qualifier="transformers.tokenization_utils_base" value="%7B%27input_ids%27%3A tensor%28%5B%5B  101%2C   146%2C  2939%2C  1191%2C   146%2C  1821%2C 13143%2C   102%2C     0%2C     0%2C%0A             0%2C     0%2C     0%2C    ...%2C 0%2C 0%2C 0%2C%0A         0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C%0A         0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%5D%5D%29%7D" isContainer="True" shape="3" />
<var name="scores" type="ndarray" qualifier="numpy" value="%5B3.2425713e-04 9.9967575e-01%5D" isContainer="True" shape="(2,)" />
<var name="shuffle" type="Dataset" qualifier="datasets.arrow_dataset" value="Dataset%28%7B%0A    features%3A %5B%27id%27%2C %27text%27%2C %27label%27%2C %27source_data%27%2C %27input_ids%27%2C %27token_type_ids%27%2C %27attention_mask%27%5D%2C%0A    num_rows%3A 10843%0A%7D%29" isContainer="True" shape="(10843, 7)" />
<var name="tokenizer" type="BertTokenizerFast" qualifier="transformers.models.bert.tokenization_bert_fast" value="BertTokenizerFast%28name_or_path=%27./bert-base-cased%27%2C vocab_size=28996%2C model_max_length=1000000000000000019884624838656%2C is_fas...se%2C special=True%29%2C%0A%09103%3A AddedToken%28%22%5BMASK%5D%22%2C rstrip=False%2C lstrip=False%2C single_word=False%2C normalized=False%2C special=True%29%2C%0A%7D" isContainer="True" shape="28996" />
<var name="train_count" type="int" qualifier="builtins" value="9758" />
<var name="trainer" type="Trainer" qualifier="transformers.trainer" value="%3Ctransformers.trainer.Trainer object at 0x0000027DAAA33190&gt;" isContainer="True" />
<var name="training_args" type="TrainingArguments" qualifier="transformers.training_args" value="TrainingArguments%28%0A_n_gpu=1%2C%0Aadafactor=False%2C%0Aadam_beta1=0.9%2C%0Aadam_beta2=0.999%2C%0Aadam_epsilon=1e-08%2C%0Aauto_find_batch_size=False...use_ipex=False%2C%0Ause_legacy_prediction_loop=False%2C%0Ause_mps_device=False%2C%0Awarmup_ratio=0.0%2C%0Awarmup_steps=100%2C%0Aweight_decay=0.0%2C%0A%29" isContainer="True" />
</xml>
[{'label': 'NEGATIVE', 'score': 0.9942924976348877}]
depressive score: 0.00029743253 neutral score: 0.9997025
<xml><var name="_dummy_ipython_val"  />
<var name="_dummy_special_var"  />
<var name="acc_metric" type="Accuracy" qualifier="evaluate_modules.metrics.accuracy.f887c0aab52c2d38e1f8a215681126379eca617f96c447638f751434e8e65b14.accuracy" value="EvaluationModule%28name%3A %22accuracy%22%2C module_type%3A %22metric%22%2C features%3A %7B%27predictions%27%3A Value%28dtype=%27int32%27%2C id=None%29%2C %27references...weight=%5B0.5%2C 2%2C 0.7%2C 0.5%2C 9%2C 0.4%5D%29%0A        &gt;&gt;&gt; print%28results%29%0A        %7B%27accuracy%27%3A 0.8778625954198473%7D%0A%22%22%22%2C stored examples%3A 0%29" isContainer="True" shape="0" />
<var name="base_model" type="BertForSequenceClassification" qualifier="transformers.models.bert.modeling_bert" value="BertForSequenceClassification%28%0A  %28bert%29%3A BertModel%28%0A    %28embeddings%29%3A BertEmbeddings%28%0A      %28word_embeddings%29%3A Embedding%2828996...anh%28%29%0A    %29%0A  %29%0A  %28dropout%29%3A Dropout%28p=0.1%2C inplace=False%29%0A  %28classifier%29%3A Linear%28in_features=768%2C out_features=2%2C bias=True%29%0A%29" isContainer="True" />
<var name="classifier" type="TextClassificationPipeline" qualifier="transformers.pipelines.text_classification" value="%3Ctransformers.pipelines.text_classification.TextClassificationPipeline object at 0x0000027DAAADEDD0&gt;" isContainer="True" />
<var name="dataset" type="DatasetDict" qualifier="datasets.dataset_dict" value="DatasetDict%28%7B%0A    train%3A Dataset%28%7B%0A        features%3A %5B%27id%27%2C %27text%27%2C %27label%27%2C %27source_data%27%5D%2C%0A        num_rows%3A 10843%0A    %7D%29%0A%7D%29" isContainer="True" shape="('train',)" />
<var name="dataset_eval" type="Dataset" qualifier="datasets.arrow_dataset" value="Dataset%28%7B%0A    features%3A %5B%27id%27%2C %27text%27%2C %27label%27%2C %27source_data%27%2C %27input_ids%27%2C %27token_type_ids%27%2C %27attention_mask%27%5D%2C%0A    num_rows%3A 1085%0A%7D%29" isContainer="True" shape="(1085, 7)" />
<var name="dataset_tokens" type="DatasetDict" qualifier="datasets.dataset_dict" value="DatasetDict%28%7B%0A    train%3A Dataset%28%7B%0A        features%3A %5B%27id%27%2C %27text%27%2C %27label%27%2C %27source_data%27%2C %27input_ids%27%2C %27token_type_ids%27%2C %27attention_mask%27%5D%2C%0A        num_rows%3A 10843%0A    %7D%29%0A%7D%29" isContainer="True" shape="('train',)" />
<var name="dataset_train" type="Dataset" qualifier="datasets.arrow_dataset" value="Dataset%28%7B%0A    features%3A %5B%27id%27%2C %27text%27%2C %27label%27%2C %27source_data%27%2C %27input_ids%27%2C %27token_type_ids%27%2C %27attention_mask%27%5D%2C%0A    num_rows%3A 9758%0A%7D%29" isContainer="True" shape="(9758, 7)" />
<var name="ft_model" type="BertForSequenceClassification" qualifier="transformers.models.bert.modeling_bert" value="BertForSequenceClassification%28%0A  %28bert%29%3A BertModel%28%0A    %28embeddings%29%3A BertEmbeddings%28%0A      %28word_embeddings%29%3A Embedding%2828996...anh%28%29%0A    %29%0A  %29%0A  %28dropout%29%3A Dropout%28p=0.1%2C inplace=False%29%0A  %28classifier%29%3A Linear%28in_features=768%2C out_features=2%2C bias=True%29%0A%29" isContainer="True" />
<var name="ft_model_checkpoint" type="str" qualifier="builtins" value="test_trainer/checkpoint-7317" />
<var name="label_count" type="int" qualifier="builtins" value="2" />
<var name="model_name" type="str" qualifier="builtins" value="./bert-base-cased" />
<var name="result" type="list" qualifier="builtins" value="%5B%7B%27label%27%3A %27NEGATIVE%27%2C %27score%27%3A 0.9942924976348877%7D%5D" isContainer="True" shape="1" />
<var name="sample_out" type="SequenceClassifierOutput" qualifier="transformers.modeling_outputs" value="SequenceClassifierOutput%28loss=None%2C logits=tensor%28%5B%5B 4.0596%2C -4.0604%5D%5D%2C grad_fn=%3CAddmmBackward0&gt;%29%2C hidden_states=None%2C attentions=None%29" isContainer="True" shape="1" />
<var name="sample_text" type="str" qualifier="builtins" value="I die if I am happy" />
<var name="sample_tokens" type="BatchEncoding" qualifier="transformers.tokenization_utils_base" value="%7B%27input_ids%27%3A tensor%28%5B%5B 101%2C  146%2C 2939%2C 1191%2C  146%2C 1821%2C 2816%2C  102%2C    0%2C    0%2C    0%2C    0%2C%0A            0%2C    0%2C    0%2C    0...%2C 0%2C 0%2C 0%2C%0A         0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C%0A         0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%5D%5D%29%7D" isContainer="True" shape="3" />
<var name="scores" type="ndarray" qualifier="numpy" value="%5B9.9970251e-01 2.9743253e-04%5D" isContainer="True" shape="(2,)" />
<var name="shuffle" type="Dataset" qualifier="datasets.arrow_dataset" value="Dataset%28%7B%0A    features%3A %5B%27id%27%2C %27text%27%2C %27label%27%2C %27source_data%27%2C %27input_ids%27%2C %27token_type_ids%27%2C %27attention_mask%27%5D%2C%0A    num_rows%3A 10843%0A%7D%29" isContainer="True" shape="(10843, 7)" />
<var name="tokenizer" type="BertTokenizerFast" qualifier="transformers.models.bert.tokenization_bert_fast" value="BertTokenizerFast%28name_or_path=%27./bert-base-cased%27%2C vocab_size=28996%2C model_max_length=1000000000000000019884624838656%2C is_fas...se%2C special=True%29%2C%0A%09103%3A AddedToken%28%22%5BMASK%5D%22%2C rstrip=False%2C lstrip=False%2C single_word=False%2C normalized=False%2C special=True%29%2C%0A%7D" isContainer="True" shape="28996" />
<var name="train_count" type="int" qualifier="builtins" value="9758" />
<var name="trainer" type="Trainer" qualifier="transformers.trainer" value="%3Ctransformers.trainer.Trainer object at 0x0000027DAAA33190&gt;" isContainer="True" />
<var name="training_args" type="TrainingArguments" qualifier="transformers.training_args" value="TrainingArguments%28%0A_n_gpu=1%2C%0Aadafactor=False%2C%0Aadam_beta1=0.9%2C%0Aadam_beta2=0.999%2C%0Aadam_epsilon=1e-08%2C%0Aauto_find_batch_size=False...use_ipex=False%2C%0Ause_legacy_prediction_loop=False%2C%0Ause_mps_device=False%2C%0Awarmup_ratio=0.0%2C%0Awarmup_steps=100%2C%0Aweight_decay=0.0%2C%0A%29" isContainer="True" />
</xml>
[{'label': 'NEGATIVE', 'score': 0.9963405132293701}]
depressive score: 0.99967575 neutral score: 0.00032425713
<xml><var name="_dummy_ipython_val"  />
<var name="_dummy_special_var"  />
<var name="acc_metric" type="Accuracy" qualifier="evaluate_modules.metrics.accuracy.f887c0aab52c2d38e1f8a215681126379eca617f96c447638f751434e8e65b14.accuracy" value="EvaluationModule%28name%3A %22accuracy%22%2C module_type%3A %22metric%22%2C features%3A %7B%27predictions%27%3A Value%28dtype=%27int32%27%2C id=None%29%2C %27references...weight=%5B0.5%2C 2%2C 0.7%2C 0.5%2C 9%2C 0.4%5D%29%0A        &gt;&gt;&gt; print%28results%29%0A        %7B%27accuracy%27%3A 0.8778625954198473%7D%0A%22%22%22%2C stored examples%3A 0%29" isContainer="True" shape="0" />
<var name="base_model" type="BertForSequenceClassification" qualifier="transformers.models.bert.modeling_bert" value="BertForSequenceClassification%28%0A  %28bert%29%3A BertModel%28%0A    %28embeddings%29%3A BertEmbeddings%28%0A      %28word_embeddings%29%3A Embedding%2828996...anh%28%29%0A    %29%0A  %29%0A  %28dropout%29%3A Dropout%28p=0.1%2C inplace=False%29%0A  %28classifier%29%3A Linear%28in_features=768%2C out_features=2%2C bias=True%29%0A%29" isContainer="True" />
<var name="classifier" type="TextClassificationPipeline" qualifier="transformers.pipelines.text_classification" value="%3Ctransformers.pipelines.text_classification.TextClassificationPipeline object at 0x0000027E453D5210&gt;" isContainer="True" />
<var name="dataset" type="DatasetDict" qualifier="datasets.dataset_dict" value="DatasetDict%28%7B%0A    train%3A Dataset%28%7B%0A        features%3A %5B%27id%27%2C %27text%27%2C %27label%27%2C %27source_data%27%5D%2C%0A        num_rows%3A 10843%0A    %7D%29%0A%7D%29" isContainer="True" shape="('train',)" />
<var name="dataset_eval" type="Dataset" qualifier="datasets.arrow_dataset" value="Dataset%28%7B%0A    features%3A %5B%27id%27%2C %27text%27%2C %27label%27%2C %27source_data%27%2C %27input_ids%27%2C %27token_type_ids%27%2C %27attention_mask%27%5D%2C%0A    num_rows%3A 1085%0A%7D%29" isContainer="True" shape="(1085, 7)" />
<var name="dataset_tokens" type="DatasetDict" qualifier="datasets.dataset_dict" value="DatasetDict%28%7B%0A    train%3A Dataset%28%7B%0A        features%3A %5B%27id%27%2C %27text%27%2C %27label%27%2C %27source_data%27%2C %27input_ids%27%2C %27token_type_ids%27%2C %27attention_mask%27%5D%2C%0A        num_rows%3A 10843%0A    %7D%29%0A%7D%29" isContainer="True" shape="('train',)" />
<var name="dataset_train" type="Dataset" qualifier="datasets.arrow_dataset" value="Dataset%28%7B%0A    features%3A %5B%27id%27%2C %27text%27%2C %27label%27%2C %27source_data%27%2C %27input_ids%27%2C %27token_type_ids%27%2C %27attention_mask%27%5D%2C%0A    num_rows%3A 9758%0A%7D%29" isContainer="True" shape="(9758, 7)" />
<var name="ft_model" type="BertForSequenceClassification" qualifier="transformers.models.bert.modeling_bert" value="BertForSequenceClassification%28%0A  %28bert%29%3A BertModel%28%0A    %28embeddings%29%3A BertEmbeddings%28%0A      %28word_embeddings%29%3A Embedding%2828996...anh%28%29%0A    %29%0A  %29%0A  %28dropout%29%3A Dropout%28p=0.1%2C inplace=False%29%0A  %28classifier%29%3A Linear%28in_features=768%2C out_features=2%2C bias=True%29%0A%29" isContainer="True" />
<var name="ft_model_checkpoint" type="str" qualifier="builtins" value="test_trainer/checkpoint-7317" />
<var name="label_count" type="int" qualifier="builtins" value="2" />
<var name="model_name" type="str" qualifier="builtins" value="./bert-base-cased" />
<var name="result" type="list" qualifier="builtins" value="%5B%7B%27label%27%3A %27NEGATIVE%27%2C %27score%27%3A 0.9963405132293701%7D%5D" isContainer="True" shape="1" />
<var name="sample_out" type="SequenceClassifierOutput" qualifier="transformers.modeling_outputs" value="SequenceClassifierOutput%28loss=None%2C logits=tensor%28%5B%5B-4.3590%2C  3.6747%5D%5D%2C grad_fn=%3CAddmmBackward0&gt;%29%2C hidden_states=None%2C attentions=None%29" isContainer="True" shape="1" />
<var name="sample_text" type="str" qualifier="builtins" value="I die if I am unhappy" />
<var name="sample_tokens" type="BatchEncoding" qualifier="transformers.tokenization_utils_base" value="%7B%27input_ids%27%3A tensor%28%5B%5B  101%2C   146%2C  2939%2C  1191%2C   146%2C  1821%2C 13143%2C   102%2C     0%2C     0%2C%0A             0%2C     0%2C     0%2C    ...%2C 0%2C 0%2C 0%2C%0A         0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C%0A         0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%5D%5D%29%7D" isContainer="True" shape="3" />
<var name="scores" type="ndarray" qualifier="numpy" value="%5B3.2425713e-04 9.9967575e-01%5D" isContainer="True" shape="(2,)" />
<var name="shuffle" type="Dataset" qualifier="datasets.arrow_dataset" value="Dataset%28%7B%0A    features%3A %5B%27id%27%2C %27text%27%2C %27label%27%2C %27source_data%27%2C %27input_ids%27%2C %27token_type_ids%27%2C %27attention_mask%27%5D%2C%0A    num_rows%3A 10843%0A%7D%29" isContainer="True" shape="(10843, 7)" />
<var name="tokenizer" type="BertTokenizerFast" qualifier="transformers.models.bert.tokenization_bert_fast" value="BertTokenizerFast%28name_or_path=%27./bert-base-cased%27%2C vocab_size=28996%2C model_max_length=1000000000000000019884624838656%2C is_fas...se%2C special=True%29%2C%0A%09103%3A AddedToken%28%22%5BMASK%5D%22%2C rstrip=False%2C lstrip=False%2C single_word=False%2C normalized=False%2C special=True%29%2C%0A%7D" isContainer="True" shape="28996" />
<var name="train_count" type="int" qualifier="builtins" value="9758" />
<var name="trainer" type="Trainer" qualifier="transformers.trainer" value="%3Ctransformers.trainer.Trainer object at 0x0000027DAAA33190&gt;" isContainer="True" />
<var name="training_args" type="TrainingArguments" qualifier="transformers.training_args" value="TrainingArguments%28%0A_n_gpu=1%2C%0Aadafactor=False%2C%0Aadam_beta1=0.9%2C%0Aadam_beta2=0.999%2C%0Aadam_epsilon=1e-08%2C%0Aauto_find_batch_size=False...use_ipex=False%2C%0Ause_legacy_prediction_loop=False%2C%0Ause_mps_device=False%2C%0Awarmup_ratio=0.0%2C%0Awarmup_steps=100%2C%0Aweight_decay=0.0%2C%0A%29" isContainer="True" />
</xml>
[{'label': 'NEGATIVE', 'score': 0.9997407793998718}]
depressive score: 0.99967635 neutral score: 0.00032368326
<xml><var name="_dummy_ipython_val"  />
<var name="_dummy_special_var"  />
<var name="acc_metric" type="Accuracy" qualifier="evaluate_modules.metrics.accuracy.f887c0aab52c2d38e1f8a215681126379eca617f96c447638f751434e8e65b14.accuracy" value="EvaluationModule%28name%3A %22accuracy%22%2C module_type%3A %22metric%22%2C features%3A %7B%27predictions%27%3A Value%28dtype=%27int32%27%2C id=None%29%2C %27references...weight=%5B0.5%2C 2%2C 0.7%2C 0.5%2C 9%2C 0.4%5D%29%0A        &gt;&gt;&gt; print%28results%29%0A        %7B%27accuracy%27%3A 0.8778625954198473%7D%0A%22%22%22%2C stored examples%3A 0%29" isContainer="True" shape="0" />
<var name="base_model" type="BertForSequenceClassification" qualifier="transformers.models.bert.modeling_bert" value="BertForSequenceClassification%28%0A  %28bert%29%3A BertModel%28%0A    %28embeddings%29%3A BertEmbeddings%28%0A      %28word_embeddings%29%3A Embedding%2828996...anh%28%29%0A    %29%0A  %29%0A  %28dropout%29%3A Dropout%28p=0.1%2C inplace=False%29%0A  %28classifier%29%3A Linear%28in_features=768%2C out_features=2%2C bias=True%29%0A%29" isContainer="True" />
<var name="classifier" type="TextClassificationPipeline" qualifier="transformers.pipelines.text_classification" value="%3Ctransformers.pipelines.text_classification.TextClassificationPipeline object at 0x0000027DAAA325D0&gt;" isContainer="True" />
<var name="dataset" type="DatasetDict" qualifier="datasets.dataset_dict" value="DatasetDict%28%7B%0A    train%3A Dataset%28%7B%0A        features%3A %5B%27id%27%2C %27text%27%2C %27label%27%2C %27source_data%27%5D%2C%0A        num_rows%3A 10843%0A    %7D%29%0A%7D%29" isContainer="True" shape="('train',)" />
<var name="dataset_eval" type="Dataset" qualifier="datasets.arrow_dataset" value="Dataset%28%7B%0A    features%3A %5B%27id%27%2C %27text%27%2C %27label%27%2C %27source_data%27%2C %27input_ids%27%2C %27token_type_ids%27%2C %27attention_mask%27%5D%2C%0A    num_rows%3A 1085%0A%7D%29" isContainer="True" shape="(1085, 7)" />
<var name="dataset_tokens" type="DatasetDict" qualifier="datasets.dataset_dict" value="DatasetDict%28%7B%0A    train%3A Dataset%28%7B%0A        features%3A %5B%27id%27%2C %27text%27%2C %27label%27%2C %27source_data%27%2C %27input_ids%27%2C %27token_type_ids%27%2C %27attention_mask%27%5D%2C%0A        num_rows%3A 10843%0A    %7D%29%0A%7D%29" isContainer="True" shape="('train',)" />
<var name="dataset_train" type="Dataset" qualifier="datasets.arrow_dataset" value="Dataset%28%7B%0A    features%3A %5B%27id%27%2C %27text%27%2C %27label%27%2C %27source_data%27%2C %27input_ids%27%2C %27token_type_ids%27%2C %27attention_mask%27%5D%2C%0A    num_rows%3A 9758%0A%7D%29" isContainer="True" shape="(9758, 7)" />
<var name="ft_model" type="BertForSequenceClassification" qualifier="transformers.models.bert.modeling_bert" value="BertForSequenceClassification%28%0A  %28bert%29%3A BertModel%28%0A    %28embeddings%29%3A BertEmbeddings%28%0A      %28word_embeddings%29%3A Embedding%2828996...anh%28%29%0A    %29%0A  %29%0A  %28dropout%29%3A Dropout%28p=0.1%2C inplace=False%29%0A  %28classifier%29%3A Linear%28in_features=768%2C out_features=2%2C bias=True%29%0A%29" isContainer="True" />
<var name="ft_model_checkpoint" type="str" qualifier="builtins" value="test_trainer/checkpoint-7317" />
<var name="label_count" type="int" qualifier="builtins" value="2" />
<var name="model_name" type="str" qualifier="builtins" value="./bert-base-cased" />
<var name="result" type="list" qualifier="builtins" value="%5B%7B%27label%27%3A %27NEGATIVE%27%2C %27score%27%3A 0.9997407793998718%7D%5D" isContainer="True" shape="1" />
<var name="sample_out" type="SequenceClassifierOutput" qualifier="transformers.modeling_outputs" value="SequenceClassifierOutput%28loss=None%2C logits=tensor%28%5B%5B-4.3319%2C  3.7035%5D%5D%2C grad_fn=%3CAddmmBackward0&gt;%29%2C hidden_states=None%2C attentions=None%29" isContainer="True" shape="1" />
<var name="sample_text" type="str" qualifier="builtins" value="I am unhappy" />
<var name="sample_tokens" type="BatchEncoding" qualifier="transformers.tokenization_utils_base" value="%7B%27input_ids%27%3A tensor%28%5B%5B  101%2C   146%2C  1821%2C 13143%2C   102%2C     0%2C     0%2C     0%2C     0%2C     0%2C%0A             0%2C     0%2C     0%2C    ...%2C 0%2C 0%2C 0%2C%0A         0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C%0A         0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%5D%5D%29%7D" isContainer="True" shape="3" />
<var name="scores" type="ndarray" qualifier="numpy" value="%5B3.2368326e-04 9.9967635e-01%5D" isContainer="True" shape="(2,)" />
<var name="shuffle" type="Dataset" qualifier="datasets.arrow_dataset" value="Dataset%28%7B%0A    features%3A %5B%27id%27%2C %27text%27%2C %27label%27%2C %27source_data%27%2C %27input_ids%27%2C %27token_type_ids%27%2C %27attention_mask%27%5D%2C%0A    num_rows%3A 10843%0A%7D%29" isContainer="True" shape="(10843, 7)" />
<var name="tokenizer" type="BertTokenizerFast" qualifier="transformers.models.bert.tokenization_bert_fast" value="BertTokenizerFast%28name_or_path=%27./bert-base-cased%27%2C vocab_size=28996%2C model_max_length=1000000000000000019884624838656%2C is_fas...se%2C special=True%29%2C%0A%09103%3A AddedToken%28%22%5BMASK%5D%22%2C rstrip=False%2C lstrip=False%2C single_word=False%2C normalized=False%2C special=True%29%2C%0A%7D" isContainer="True" shape="28996" />
<var name="train_count" type="int" qualifier="builtins" value="9758" />
<var name="trainer" type="Trainer" qualifier="transformers.trainer" value="%3Ctransformers.trainer.Trainer object at 0x0000027DAAA33190&gt;" isContainer="True" />
<var name="training_args" type="TrainingArguments" qualifier="transformers.training_args" value="TrainingArguments%28%0A_n_gpu=1%2C%0Aadafactor=False%2C%0Aadam_beta1=0.9%2C%0Aadam_beta2=0.999%2C%0Aadam_epsilon=1e-08%2C%0Aauto_find_batch_size=False...use_ipex=False%2C%0Ause_legacy_prediction_loop=False%2C%0Ause_mps_device=False%2C%0Awarmup_ratio=0.0%2C%0Awarmup_steps=100%2C%0Aweight_decay=0.0%2C%0A%29" isContainer="True" />
</xml>
[{'label': 'POSITIVE', 'score': 0.9998801946640015}]
depressive score: 0.00014537173 neutral score: 0.99985456
<xml><var name="_dummy_ipython_val"  />
<var name="_dummy_special_var"  />
<var name="acc_metric" type="Accuracy" qualifier="evaluate_modules.metrics.accuracy.f887c0aab52c2d38e1f8a215681126379eca617f96c447638f751434e8e65b14.accuracy" value="EvaluationModule%28name%3A %22accuracy%22%2C module_type%3A %22metric%22%2C features%3A %7B%27predictions%27%3A Value%28dtype=%27int32%27%2C id=None%29%2C %27references...weight=%5B0.5%2C 2%2C 0.7%2C 0.5%2C 9%2C 0.4%5D%29%0A        &gt;&gt;&gt; print%28results%29%0A        %7B%27accuracy%27%3A 0.8778625954198473%7D%0A%22%22%22%2C stored examples%3A 0%29" isContainer="True" shape="0" />
<var name="base_model" type="BertForSequenceClassification" qualifier="transformers.models.bert.modeling_bert" value="BertForSequenceClassification%28%0A  %28bert%29%3A BertModel%28%0A    %28embeddings%29%3A BertEmbeddings%28%0A      %28word_embeddings%29%3A Embedding%2828996...anh%28%29%0A    %29%0A  %29%0A  %28dropout%29%3A Dropout%28p=0.1%2C inplace=False%29%0A  %28classifier%29%3A Linear%28in_features=768%2C out_features=2%2C bias=True%29%0A%29" isContainer="True" />
<var name="classifier" type="TextClassificationPipeline" qualifier="transformers.pipelines.text_classification" value="%3Ctransformers.pipelines.text_classification.TextClassificationPipeline object at 0x0000027E5A51F410&gt;" isContainer="True" />
<var name="dataset" type="DatasetDict" qualifier="datasets.dataset_dict" value="DatasetDict%28%7B%0A    train%3A Dataset%28%7B%0A        features%3A %5B%27id%27%2C %27text%27%2C %27label%27%2C %27source_data%27%5D%2C%0A        num_rows%3A 10843%0A    %7D%29%0A%7D%29" isContainer="True" shape="('train',)" />
<var name="dataset_eval" type="Dataset" qualifier="datasets.arrow_dataset" value="Dataset%28%7B%0A    features%3A %5B%27id%27%2C %27text%27%2C %27label%27%2C %27source_data%27%2C %27input_ids%27%2C %27token_type_ids%27%2C %27attention_mask%27%5D%2C%0A    num_rows%3A 1085%0A%7D%29" isContainer="True" shape="(1085, 7)" />
<var name="dataset_tokens" type="DatasetDict" qualifier="datasets.dataset_dict" value="DatasetDict%28%7B%0A    train%3A Dataset%28%7B%0A        features%3A %5B%27id%27%2C %27text%27%2C %27label%27%2C %27source_data%27%2C %27input_ids%27%2C %27token_type_ids%27%2C %27attention_mask%27%5D%2C%0A        num_rows%3A 10843%0A    %7D%29%0A%7D%29" isContainer="True" shape="('train',)" />
<var name="dataset_train" type="Dataset" qualifier="datasets.arrow_dataset" value="Dataset%28%7B%0A    features%3A %5B%27id%27%2C %27text%27%2C %27label%27%2C %27source_data%27%2C %27input_ids%27%2C %27token_type_ids%27%2C %27attention_mask%27%5D%2C%0A    num_rows%3A 9758%0A%7D%29" isContainer="True" shape="(9758, 7)" />
<var name="ft_model" type="BertForSequenceClassification" qualifier="transformers.models.bert.modeling_bert" value="BertForSequenceClassification%28%0A  %28bert%29%3A BertModel%28%0A    %28embeddings%29%3A BertEmbeddings%28%0A      %28word_embeddings%29%3A Embedding%2828996...anh%28%29%0A    %29%0A  %29%0A  %28dropout%29%3A Dropout%28p=0.1%2C inplace=False%29%0A  %28classifier%29%3A Linear%28in_features=768%2C out_features=2%2C bias=True%29%0A%29" isContainer="True" />
<var name="ft_model_checkpoint" type="str" qualifier="builtins" value="test_trainer/checkpoint-7317" />
<var name="label_count" type="int" qualifier="builtins" value="2" />
<var name="model_name" type="str" qualifier="builtins" value="./bert-base-cased" />
<var name="result" type="list" qualifier="builtins" value="%5B%7B%27label%27%3A %27POSITIVE%27%2C %27score%27%3A 0.9998801946640015%7D%5D" isContainer="True" shape="1" />
<var name="sample_out" type="SequenceClassifierOutput" qualifier="transformers.modeling_outputs" value="SequenceClassifierOutput%28loss=None%2C logits=tensor%28%5B%5B 4.4874%2C -4.3486%5D%5D%2C grad_fn=%3CAddmmBackward0&gt;%29%2C hidden_states=None%2C attentions=None%29" isContainer="True" shape="1" />
<var name="sample_text" type="str" qualifier="builtins" value="I am happy" />
<var name="sample_tokens" type="BatchEncoding" qualifier="transformers.tokenization_utils_base" value="%7B%27input_ids%27%3A tensor%28%5B%5B 101%2C  146%2C 1821%2C 2816%2C  102%2C    0%2C    0%2C    0%2C    0%2C    0%2C    0%2C    0%2C%0A            0%2C    0%2C    0%2C    0...%2C 0%2C 0%2C 0%2C%0A         0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C%0A         0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%5D%5D%29%7D" isContainer="True" shape="3" />
<var name="scores" type="ndarray" qualifier="numpy" value="%5B9.9985456e-01 1.4537173e-04%5D" isContainer="True" shape="(2,)" />
<var name="shuffle" type="Dataset" qualifier="datasets.arrow_dataset" value="Dataset%28%7B%0A    features%3A %5B%27id%27%2C %27text%27%2C %27label%27%2C %27source_data%27%2C %27input_ids%27%2C %27token_type_ids%27%2C %27attention_mask%27%5D%2C%0A    num_rows%3A 10843%0A%7D%29" isContainer="True" shape="(10843, 7)" />
<var name="tokenizer" type="BertTokenizerFast" qualifier="transformers.models.bert.tokenization_bert_fast" value="BertTokenizerFast%28name_or_path=%27./bert-base-cased%27%2C vocab_size=28996%2C model_max_length=1000000000000000019884624838656%2C is_fas...se%2C special=True%29%2C%0A%09103%3A AddedToken%28%22%5BMASK%5D%22%2C rstrip=False%2C lstrip=False%2C single_word=False%2C normalized=False%2C special=True%29%2C%0A%7D" isContainer="True" shape="28996" />
<var name="train_count" type="int" qualifier="builtins" value="9758" />
<var name="trainer" type="Trainer" qualifier="transformers.trainer" value="%3Ctransformers.trainer.Trainer object at 0x0000027DAAA33190&gt;" isContainer="True" />
<var name="training_args" type="TrainingArguments" qualifier="transformers.training_args" value="TrainingArguments%28%0A_n_gpu=1%2C%0Aadafactor=False%2C%0Aadam_beta1=0.9%2C%0Aadam_beta2=0.999%2C%0Aadam_epsilon=1e-08%2C%0Aauto_find_batch_size=False...use_ipex=False%2C%0Ause_legacy_prediction_loop=False%2C%0Ause_mps_device=False%2C%0Awarmup_ratio=0.0%2C%0Awarmup_steps=100%2C%0Aweight_decay=0.0%2C%0A%29" isContainer="True" />
</xml>
[{'label': 'POSITIVE', 'score': 0.9998801946640015}]
depressive score: 0.00014537173 neutral score: 0.99985456
<xml><var name="_dummy_ipython_val"  />
<var name="_dummy_special_var"  />
<var name="acc_metric" type="Accuracy" qualifier="evaluate_modules.metrics.accuracy.f887c0aab52c2d38e1f8a215681126379eca617f96c447638f751434e8e65b14.accuracy" value="EvaluationModule%28name%3A %22accuracy%22%2C module_type%3A %22metric%22%2C features%3A %7B%27predictions%27%3A Value%28dtype=%27int32%27%2C id=None%29%2C %27references...weight=%5B0.5%2C 2%2C 0.7%2C 0.5%2C 9%2C 0.4%5D%29%0A        &gt;&gt;&gt; print%28results%29%0A        %7B%27accuracy%27%3A 0.8778625954198473%7D%0A%22%22%22%2C stored examples%3A 0%29" isContainer="True" shape="0" />
<var name="base_model" type="BertForSequenceClassification" qualifier="transformers.models.bert.modeling_bert" value="BertForSequenceClassification%28%0A  %28bert%29%3A BertModel%28%0A    %28embeddings%29%3A BertEmbeddings%28%0A      %28word_embeddings%29%3A Embedding%2828996...anh%28%29%0A    %29%0A  %29%0A  %28dropout%29%3A Dropout%28p=0.1%2C inplace=False%29%0A  %28classifier%29%3A Linear%28in_features=768%2C out_features=2%2C bias=True%29%0A%29" isContainer="True" />
<var name="classifier" type="TextClassificationPipeline" qualifier="transformers.pipelines.text_classification" value="%3Ctransformers.pipelines.text_classification.TextClassificationPipeline object at 0x0000027E5A444E10&gt;" isContainer="True" />
<var name="dataset" type="DatasetDict" qualifier="datasets.dataset_dict" value="DatasetDict%28%7B%0A    train%3A Dataset%28%7B%0A        features%3A %5B%27id%27%2C %27text%27%2C %27label%27%2C %27source_data%27%5D%2C%0A        num_rows%3A 10843%0A    %7D%29%0A%7D%29" isContainer="True" shape="('train',)" />
<var name="dataset_eval" type="Dataset" qualifier="datasets.arrow_dataset" value="Dataset%28%7B%0A    features%3A %5B%27id%27%2C %27text%27%2C %27label%27%2C %27source_data%27%2C %27input_ids%27%2C %27token_type_ids%27%2C %27attention_mask%27%5D%2C%0A    num_rows%3A 1085%0A%7D%29" isContainer="True" shape="(1085, 7)" />
<var name="dataset_tokens" type="DatasetDict" qualifier="datasets.dataset_dict" value="DatasetDict%28%7B%0A    train%3A Dataset%28%7B%0A        features%3A %5B%27id%27%2C %27text%27%2C %27label%27%2C %27source_data%27%2C %27input_ids%27%2C %27token_type_ids%27%2C %27attention_mask%27%5D%2C%0A        num_rows%3A 10843%0A    %7D%29%0A%7D%29" isContainer="True" shape="('train',)" />
<var name="dataset_train" type="Dataset" qualifier="datasets.arrow_dataset" value="Dataset%28%7B%0A    features%3A %5B%27id%27%2C %27text%27%2C %27label%27%2C %27source_data%27%2C %27input_ids%27%2C %27token_type_ids%27%2C %27attention_mask%27%5D%2C%0A    num_rows%3A 9758%0A%7D%29" isContainer="True" shape="(9758, 7)" />
<var name="ft_model" type="BertForSequenceClassification" qualifier="transformers.models.bert.modeling_bert" value="BertForSequenceClassification%28%0A  %28bert%29%3A BertModel%28%0A    %28embeddings%29%3A BertEmbeddings%28%0A      %28word_embeddings%29%3A Embedding%2828996...anh%28%29%0A    %29%0A  %29%0A  %28dropout%29%3A Dropout%28p=0.1%2C inplace=False%29%0A  %28classifier%29%3A Linear%28in_features=768%2C out_features=2%2C bias=True%29%0A%29" isContainer="True" />
<var name="ft_model_checkpoint" type="str" qualifier="builtins" value="test_trainer/checkpoint-7317" />
<var name="label_count" type="int" qualifier="builtins" value="2" />
<var name="model_name" type="str" qualifier="builtins" value="./bert-base-cased" />
<var name="result" type="list" qualifier="builtins" value="%5B%7B%27label%27%3A %27POSITIVE%27%2C %27score%27%3A 0.9998801946640015%7D%5D" isContainer="True" shape="1" />
<var name="sample_out" type="SequenceClassifierOutput" qualifier="transformers.modeling_outputs" value="SequenceClassifierOutput%28loss=None%2C logits=tensor%28%5B%5B 4.4874%2C -4.3486%5D%5D%2C grad_fn=%3CAddmmBackward0&gt;%29%2C hidden_states=None%2C attentions=None%29" isContainer="True" shape="1" />
<var name="sample_text" type="str" qualifier="builtins" value="I am happy" />
<var name="sample_tokens" type="BatchEncoding" qualifier="transformers.tokenization_utils_base" value="%7B%27input_ids%27%3A tensor%28%5B%5B 101%2C  146%2C 1821%2C 2816%2C  102%2C    0%2C    0%2C    0%2C    0%2C    0%2C    0%2C    0%2C%0A            0%2C    0%2C    0%2C    0...%2C 0%2C 0%2C 0%2C%0A         0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C%0A         0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%5D%5D%29%7D" isContainer="True" shape="3" />
<var name="scores" type="ndarray" qualifier="numpy" value="%5B9.9985456e-01 1.4537173e-04%5D" isContainer="True" shape="(2,)" />
<var name="shuffle" type="Dataset" qualifier="datasets.arrow_dataset" value="Dataset%28%7B%0A    features%3A %5B%27id%27%2C %27text%27%2C %27label%27%2C %27source_data%27%2C %27input_ids%27%2C %27token_type_ids%27%2C %27attention_mask%27%5D%2C%0A    num_rows%3A 10843%0A%7D%29" isContainer="True" shape="(10843, 7)" />
<var name="tokenizer" type="BertTokenizerFast" qualifier="transformers.models.bert.tokenization_bert_fast" value="BertTokenizerFast%28name_or_path=%27./bert-base-cased%27%2C vocab_size=28996%2C model_max_length=1000000000000000019884624838656%2C is_fas...se%2C special=True%29%2C%0A%09103%3A AddedToken%28%22%5BMASK%5D%22%2C rstrip=False%2C lstrip=False%2C single_word=False%2C normalized=False%2C special=True%29%2C%0A%7D" isContainer="True" shape="28996" />
<var name="train_count" type="int" qualifier="builtins" value="9758" />
<var name="trainer" type="Trainer" qualifier="transformers.trainer" value="%3Ctransformers.trainer.Trainer object at 0x0000027DAAA33190&gt;" isContainer="True" />
<var name="training_args" type="TrainingArguments" qualifier="transformers.training_args" value="TrainingArguments%28%0A_n_gpu=1%2C%0Aadafactor=False%2C%0Aadam_beta1=0.9%2C%0Aadam_beta2=0.999%2C%0Aadam_epsilon=1e-08%2C%0Aauto_find_batch_size=False...use_ipex=False%2C%0Ause_legacy_prediction_loop=False%2C%0Ause_mps_device=False%2C%0Awarmup_ratio=0.0%2C%0Awarmup_steps=100%2C%0Aweight_decay=0.0%2C%0A%29" isContainer="True" />
</xml>
[{'label': 'NEGATIVE', 'score': 0.9997407793998718}]
depressive score: 0.99967635 neutral score: 0.00032368326
<xml><var name="_dummy_ipython_val"  />
<var name="_dummy_special_var"  />
<var name="acc_metric" type="Accuracy" qualifier="evaluate_modules.metrics.accuracy.f887c0aab52c2d38e1f8a215681126379eca617f96c447638f751434e8e65b14.accuracy" value="EvaluationModule%28name%3A %22accuracy%22%2C module_type%3A %22metric%22%2C features%3A %7B%27predictions%27%3A Value%28dtype=%27int32%27%2C id=None%29%2C %27references...weight=%5B0.5%2C 2%2C 0.7%2C 0.5%2C 9%2C 0.4%5D%29%0A        &gt;&gt;&gt; print%28results%29%0A        %7B%27accuracy%27%3A 0.8778625954198473%7D%0A%22%22%22%2C stored examples%3A 0%29" isContainer="True" shape="0" />
<var name="base_model" type="BertForSequenceClassification" qualifier="transformers.models.bert.modeling_bert" value="BertForSequenceClassification%28%0A  %28bert%29%3A BertModel%28%0A    %28embeddings%29%3A BertEmbeddings%28%0A      %28word_embeddings%29%3A Embedding%2828996...anh%28%29%0A    %29%0A  %29%0A  %28dropout%29%3A Dropout%28p=0.1%2C inplace=False%29%0A  %28classifier%29%3A Linear%28in_features=768%2C out_features=2%2C bias=True%29%0A%29" isContainer="True" />
<var name="classifier" type="TextClassificationPipeline" qualifier="transformers.pipelines.text_classification" value="%3Ctransformers.pipelines.text_classification.TextClassificationPipeline object at 0x0000027D894ABE10&gt;" isContainer="True" />
<var name="dataset" type="DatasetDict" qualifier="datasets.dataset_dict" value="DatasetDict%28%7B%0A    train%3A Dataset%28%7B%0A        features%3A %5B%27id%27%2C %27text%27%2C %27label%27%2C %27source_data%27%5D%2C%0A        num_rows%3A 10843%0A    %7D%29%0A%7D%29" isContainer="True" shape="('train',)" />
<var name="dataset_eval" type="Dataset" qualifier="datasets.arrow_dataset" value="Dataset%28%7B%0A    features%3A %5B%27id%27%2C %27text%27%2C %27label%27%2C %27source_data%27%2C %27input_ids%27%2C %27token_type_ids%27%2C %27attention_mask%27%5D%2C%0A    num_rows%3A 1085%0A%7D%29" isContainer="True" shape="(1085, 7)" />
<var name="dataset_tokens" type="DatasetDict" qualifier="datasets.dataset_dict" value="DatasetDict%28%7B%0A    train%3A Dataset%28%7B%0A        features%3A %5B%27id%27%2C %27text%27%2C %27label%27%2C %27source_data%27%2C %27input_ids%27%2C %27token_type_ids%27%2C %27attention_mask%27%5D%2C%0A        num_rows%3A 10843%0A    %7D%29%0A%7D%29" isContainer="True" shape="('train',)" />
<var name="dataset_train" type="Dataset" qualifier="datasets.arrow_dataset" value="Dataset%28%7B%0A    features%3A %5B%27id%27%2C %27text%27%2C %27label%27%2C %27source_data%27%2C %27input_ids%27%2C %27token_type_ids%27%2C %27attention_mask%27%5D%2C%0A    num_rows%3A 9758%0A%7D%29" isContainer="True" shape="(9758, 7)" />
<var name="ft_model" type="BertForSequenceClassification" qualifier="transformers.models.bert.modeling_bert" value="BertForSequenceClassification%28%0A  %28bert%29%3A BertModel%28%0A    %28embeddings%29%3A BertEmbeddings%28%0A      %28word_embeddings%29%3A Embedding%2828996...anh%28%29%0A    %29%0A  %29%0A  %28dropout%29%3A Dropout%28p=0.1%2C inplace=False%29%0A  %28classifier%29%3A Linear%28in_features=768%2C out_features=2%2C bias=True%29%0A%29" isContainer="True" />
<var name="ft_model_checkpoint" type="str" qualifier="builtins" value="test_trainer/checkpoint-7317" />
<var name="label_count" type="int" qualifier="builtins" value="2" />
<var name="model_name" type="str" qualifier="builtins" value="./bert-base-cased" />
<var name="result" type="list" qualifier="builtins" value="%5B%7B%27label%27%3A %27NEGATIVE%27%2C %27score%27%3A 0.9997407793998718%7D%5D" isContainer="True" shape="1" />
<var name="sample_out" type="SequenceClassifierOutput" qualifier="transformers.modeling_outputs" value="SequenceClassifierOutput%28loss=None%2C logits=tensor%28%5B%5B-4.3319%2C  3.7035%5D%5D%2C grad_fn=%3CAddmmBackward0&gt;%29%2C hidden_states=None%2C attentions=None%29" isContainer="True" shape="1" />
<var name="sample_text" type="str" qualifier="builtins" value="I am unhappy" />
<var name="sample_tokens" type="BatchEncoding" qualifier="transformers.tokenization_utils_base" value="%7B%27input_ids%27%3A tensor%28%5B%5B  101%2C   146%2C  1821%2C 13143%2C   102%2C     0%2C     0%2C     0%2C     0%2C     0%2C%0A             0%2C     0%2C     0%2C    ...%2C 0%2C 0%2C 0%2C%0A         0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C%0A         0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%5D%5D%29%7D" isContainer="True" shape="3" />
<var name="scores" type="ndarray" qualifier="numpy" value="%5B3.2368326e-04 9.9967635e-01%5D" isContainer="True" shape="(2,)" />
<var name="shuffle" type="Dataset" qualifier="datasets.arrow_dataset" value="Dataset%28%7B%0A    features%3A %5B%27id%27%2C %27text%27%2C %27label%27%2C %27source_data%27%2C %27input_ids%27%2C %27token_type_ids%27%2C %27attention_mask%27%5D%2C%0A    num_rows%3A 10843%0A%7D%29" isContainer="True" shape="(10843, 7)" />
<var name="tokenizer" type="BertTokenizerFast" qualifier="transformers.models.bert.tokenization_bert_fast" value="BertTokenizerFast%28name_or_path=%27./bert-base-cased%27%2C vocab_size=28996%2C model_max_length=1000000000000000019884624838656%2C is_fas...se%2C special=True%29%2C%0A%09103%3A AddedToken%28%22%5BMASK%5D%22%2C rstrip=False%2C lstrip=False%2C single_word=False%2C normalized=False%2C special=True%29%2C%0A%7D" isContainer="True" shape="28996" />
<var name="train_count" type="int" qualifier="builtins" value="9758" />
<var name="trainer" type="Trainer" qualifier="transformers.trainer" value="%3Ctransformers.trainer.Trainer object at 0x0000027DAAA33190&gt;" isContainer="True" />
<var name="training_args" type="TrainingArguments" qualifier="transformers.training_args" value="TrainingArguments%28%0A_n_gpu=1%2C%0Aadafactor=False%2C%0Aadam_beta1=0.9%2C%0Aadam_beta2=0.999%2C%0Aadam_epsilon=1e-08%2C%0Aauto_find_batch_size=False...use_ipex=False%2C%0Ause_legacy_prediction_loop=False%2C%0Ause_mps_device=False%2C%0Awarmup_ratio=0.0%2C%0Awarmup_steps=100%2C%0Aweight_decay=0.0%2C%0A%29" isContainer="True" />
</xml>
[{'label': 'POSITIVE', 'score': 0.9998801946640015}]
depressive score: 0.00014537173 neutral score: 0.99985456
<xml><var name="_dummy_ipython_val"  />
<var name="_dummy_special_var"  />
<var name="acc_metric" type="Accuracy" qualifier="evaluate_modules.metrics.accuracy.f887c0aab52c2d38e1f8a215681126379eca617f96c447638f751434e8e65b14.accuracy" value="EvaluationModule%28name%3A %22accuracy%22%2C module_type%3A %22metric%22%2C features%3A %7B%27predictions%27%3A Value%28dtype=%27int32%27%2C id=None%29%2C %27references...weight=%5B0.5%2C 2%2C 0.7%2C 0.5%2C 9%2C 0.4%5D%29%0A        &gt;&gt;&gt; print%28results%29%0A        %7B%27accuracy%27%3A 0.8778625954198473%7D%0A%22%22%22%2C stored examples%3A 0%29" isContainer="True" shape="0" />
<var name="base_model" type="BertForSequenceClassification" qualifier="transformers.models.bert.modeling_bert" value="BertForSequenceClassification%28%0A  %28bert%29%3A BertModel%28%0A    %28embeddings%29%3A BertEmbeddings%28%0A      %28word_embeddings%29%3A Embedding%2828996...anh%28%29%0A    %29%0A  %29%0A  %28dropout%29%3A Dropout%28p=0.1%2C inplace=False%29%0A  %28classifier%29%3A Linear%28in_features=768%2C out_features=2%2C bias=True%29%0A%29" isContainer="True" />
<var name="classifier" type="TextClassificationPipeline" qualifier="transformers.pipelines.text_classification" value="%3Ctransformers.pipelines.text_classification.TextClassificationPipeline object at 0x0000027DD5D57DD0&gt;" isContainer="True" />
<var name="dataset" type="DatasetDict" qualifier="datasets.dataset_dict" value="DatasetDict%28%7B%0A    train%3A Dataset%28%7B%0A        features%3A %5B%27id%27%2C %27text%27%2C %27label%27%2C %27source_data%27%5D%2C%0A        num_rows%3A 10843%0A    %7D%29%0A%7D%29" isContainer="True" shape="('train',)" />
<var name="dataset_eval" type="Dataset" qualifier="datasets.arrow_dataset" value="Dataset%28%7B%0A    features%3A %5B%27id%27%2C %27text%27%2C %27label%27%2C %27source_data%27%2C %27input_ids%27%2C %27token_type_ids%27%2C %27attention_mask%27%5D%2C%0A    num_rows%3A 1085%0A%7D%29" isContainer="True" shape="(1085, 7)" />
<var name="dataset_tokens" type="DatasetDict" qualifier="datasets.dataset_dict" value="DatasetDict%28%7B%0A    train%3A Dataset%28%7B%0A        features%3A %5B%27id%27%2C %27text%27%2C %27label%27%2C %27source_data%27%2C %27input_ids%27%2C %27token_type_ids%27%2C %27attention_mask%27%5D%2C%0A        num_rows%3A 10843%0A    %7D%29%0A%7D%29" isContainer="True" shape="('train',)" />
<var name="dataset_train" type="Dataset" qualifier="datasets.arrow_dataset" value="Dataset%28%7B%0A    features%3A %5B%27id%27%2C %27text%27%2C %27label%27%2C %27source_data%27%2C %27input_ids%27%2C %27token_type_ids%27%2C %27attention_mask%27%5D%2C%0A    num_rows%3A 9758%0A%7D%29" isContainer="True" shape="(9758, 7)" />
<var name="ft_model" type="BertForSequenceClassification" qualifier="transformers.models.bert.modeling_bert" value="BertForSequenceClassification%28%0A  %28bert%29%3A BertModel%28%0A    %28embeddings%29%3A BertEmbeddings%28%0A      %28word_embeddings%29%3A Embedding%2828996...anh%28%29%0A    %29%0A  %29%0A  %28dropout%29%3A Dropout%28p=0.1%2C inplace=False%29%0A  %28classifier%29%3A Linear%28in_features=768%2C out_features=2%2C bias=True%29%0A%29" isContainer="True" />
<var name="ft_model_checkpoint" type="str" qualifier="builtins" value="test_trainer/checkpoint-7317" />
<var name="label_count" type="int" qualifier="builtins" value="2" />
<var name="model_name" type="str" qualifier="builtins" value="./bert-base-cased" />
<var name="result" type="list" qualifier="builtins" value="%5B%7B%27label%27%3A %27POSITIVE%27%2C %27score%27%3A 0.9998801946640015%7D%5D" isContainer="True" shape="1" />
<var name="sample_out" type="SequenceClassifierOutput" qualifier="transformers.modeling_outputs" value="SequenceClassifierOutput%28loss=None%2C logits=tensor%28%5B%5B 4.4874%2C -4.3486%5D%5D%2C grad_fn=%3CAddmmBackward0&gt;%29%2C hidden_states=None%2C attentions=None%29" isContainer="True" shape="1" />
<var name="sample_text" type="str" qualifier="builtins" value="I am happy" />
<var name="sample_tokens" type="BatchEncoding" qualifier="transformers.tokenization_utils_base" value="%7B%27input_ids%27%3A tensor%28%5B%5B 101%2C  146%2C 1821%2C 2816%2C  102%2C    0%2C    0%2C    0%2C    0%2C    0%2C    0%2C    0%2C%0A            0%2C    0%2C    0%2C    0...%2C 0%2C 0%2C 0%2C%0A         0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C%0A         0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%5D%5D%29%7D" isContainer="True" shape="3" />
<var name="scores" type="ndarray" qualifier="numpy" value="%5B9.9985456e-01 1.4537173e-04%5D" isContainer="True" shape="(2,)" />
<var name="shuffle" type="Dataset" qualifier="datasets.arrow_dataset" value="Dataset%28%7B%0A    features%3A %5B%27id%27%2C %27text%27%2C %27label%27%2C %27source_data%27%2C %27input_ids%27%2C %27token_type_ids%27%2C %27attention_mask%27%5D%2C%0A    num_rows%3A 10843%0A%7D%29" isContainer="True" shape="(10843, 7)" />
<var name="tokenizer" type="BertTokenizerFast" qualifier="transformers.models.bert.tokenization_bert_fast" value="BertTokenizerFast%28name_or_path=%27./bert-base-cased%27%2C vocab_size=28996%2C model_max_length=1000000000000000019884624838656%2C is_fas...se%2C special=True%29%2C%0A%09103%3A AddedToken%28%22%5BMASK%5D%22%2C rstrip=False%2C lstrip=False%2C single_word=False%2C normalized=False%2C special=True%29%2C%0A%7D" isContainer="True" shape="28996" />
<var name="train_count" type="int" qualifier="builtins" value="9758" />
<var name="trainer" type="Trainer" qualifier="transformers.trainer" value="%3Ctransformers.trainer.Trainer object at 0x0000027DAAA33190&gt;" isContainer="True" />
<var name="training_args" type="TrainingArguments" qualifier="transformers.training_args" value="TrainingArguments%28%0A_n_gpu=1%2C%0Aadafactor=False%2C%0Aadam_beta1=0.9%2C%0Aadam_beta2=0.999%2C%0Aadam_epsilon=1e-08%2C%0Aauto_find_batch_size=False...use_ipex=False%2C%0Ause_legacy_prediction_loop=False%2C%0Ause_mps_device=False%2C%0Awarmup_ratio=0.0%2C%0Awarmup_steps=100%2C%0Aweight_decay=0.0%2C%0A%29" isContainer="True" />
</xml>
[{'label': 'NEGATIVE', 'score': 0.9997407793998718}]
depressive score: 0.99967635 neutral score: 0.00032368326
<xml><var name="_dummy_ipython_val"  />
<var name="_dummy_special_var"  />
<var name="acc_metric" type="Accuracy" qualifier="evaluate_modules.metrics.accuracy.f887c0aab52c2d38e1f8a215681126379eca617f96c447638f751434e8e65b14.accuracy" value="EvaluationModule%28name%3A %22accuracy%22%2C module_type%3A %22metric%22%2C features%3A %7B%27predictions%27%3A Value%28dtype=%27int32%27%2C id=None%29%2C %27references...weight=%5B0.5%2C 2%2C 0.7%2C 0.5%2C 9%2C 0.4%5D%29%0A        &gt;&gt;&gt; print%28results%29%0A        %7B%27accuracy%27%3A 0.8778625954198473%7D%0A%22%22%22%2C stored examples%3A 0%29" isContainer="True" shape="0" />
<var name="base_model" type="BertForSequenceClassification" qualifier="transformers.models.bert.modeling_bert" value="BertForSequenceClassification%28%0A  %28bert%29%3A BertModel%28%0A    %28embeddings%29%3A BertEmbeddings%28%0A      %28word_embeddings%29%3A Embedding%2828996...anh%28%29%0A    %29%0A  %29%0A  %28dropout%29%3A Dropout%28p=0.1%2C inplace=False%29%0A  %28classifier%29%3A Linear%28in_features=768%2C out_features=2%2C bias=True%29%0A%29" isContainer="True" />
<var name="classifier" type="TextClassificationPipeline" qualifier="transformers.pipelines.text_classification" value="%3Ctransformers.pipelines.text_classification.TextClassificationPipeline object at 0x0000027E5A4FAB10&gt;" isContainer="True" />
<var name="dataset" type="DatasetDict" qualifier="datasets.dataset_dict" value="DatasetDict%28%7B%0A    train%3A Dataset%28%7B%0A        features%3A %5B%27id%27%2C %27text%27%2C %27label%27%2C %27source_data%27%5D%2C%0A        num_rows%3A 10843%0A    %7D%29%0A%7D%29" isContainer="True" shape="('train',)" />
<var name="dataset_eval" type="Dataset" qualifier="datasets.arrow_dataset" value="Dataset%28%7B%0A    features%3A %5B%27id%27%2C %27text%27%2C %27label%27%2C %27source_data%27%2C %27input_ids%27%2C %27token_type_ids%27%2C %27attention_mask%27%5D%2C%0A    num_rows%3A 1085%0A%7D%29" isContainer="True" shape="(1085, 7)" />
<var name="dataset_tokens" type="DatasetDict" qualifier="datasets.dataset_dict" value="DatasetDict%28%7B%0A    train%3A Dataset%28%7B%0A        features%3A %5B%27id%27%2C %27text%27%2C %27label%27%2C %27source_data%27%2C %27input_ids%27%2C %27token_type_ids%27%2C %27attention_mask%27%5D%2C%0A        num_rows%3A 10843%0A    %7D%29%0A%7D%29" isContainer="True" shape="('train',)" />
<var name="dataset_train" type="Dataset" qualifier="datasets.arrow_dataset" value="Dataset%28%7B%0A    features%3A %5B%27id%27%2C %27text%27%2C %27label%27%2C %27source_data%27%2C %27input_ids%27%2C %27token_type_ids%27%2C %27attention_mask%27%5D%2C%0A    num_rows%3A 9758%0A%7D%29" isContainer="True" shape="(9758, 7)" />
<var name="ft_model" type="BertForSequenceClassification" qualifier="transformers.models.bert.modeling_bert" value="BertForSequenceClassification%28%0A  %28bert%29%3A BertModel%28%0A    %28embeddings%29%3A BertEmbeddings%28%0A      %28word_embeddings%29%3A Embedding%2828996...anh%28%29%0A    %29%0A  %29%0A  %28dropout%29%3A Dropout%28p=0.1%2C inplace=False%29%0A  %28classifier%29%3A Linear%28in_features=768%2C out_features=2%2C bias=True%29%0A%29" isContainer="True" />
<var name="ft_model_checkpoint" type="str" qualifier="builtins" value="test_trainer/checkpoint-7317" />
<var name="label_count" type="int" qualifier="builtins" value="2" />
<var name="model_name" type="str" qualifier="builtins" value="./bert-base-cased" />
<var name="result" type="list" qualifier="builtins" value="%5B%7B%27label%27%3A %27NEGATIVE%27%2C %27score%27%3A 0.9997407793998718%7D%5D" isContainer="True" shape="1" />
<var name="sample_out" type="SequenceClassifierOutput" qualifier="transformers.modeling_outputs" value="SequenceClassifierOutput%28loss=None%2C logits=tensor%28%5B%5B-4.3319%2C  3.7035%5D%5D%2C grad_fn=%3CAddmmBackward0&gt;%29%2C hidden_states=None%2C attentions=None%29" isContainer="True" shape="1" />
<var name="sample_text" type="str" qualifier="builtins" value="I am unhappy" />
<var name="sample_tokens" type="BatchEncoding" qualifier="transformers.tokenization_utils_base" value="%7B%27input_ids%27%3A tensor%28%5B%5B  101%2C   146%2C  1821%2C 13143%2C   102%2C     0%2C     0%2C     0%2C     0%2C     0%2C%0A             0%2C     0%2C     0%2C    ...%2C 0%2C 0%2C 0%2C%0A         0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C%0A         0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%5D%5D%29%7D" isContainer="True" shape="3" />
<var name="scores" type="ndarray" qualifier="numpy" value="%5B3.2368326e-04 9.9967635e-01%5D" isContainer="True" shape="(2,)" />
<var name="shuffle" type="Dataset" qualifier="datasets.arrow_dataset" value="Dataset%28%7B%0A    features%3A %5B%27id%27%2C %27text%27%2C %27label%27%2C %27source_data%27%2C %27input_ids%27%2C %27token_type_ids%27%2C %27attention_mask%27%5D%2C%0A    num_rows%3A 10843%0A%7D%29" isContainer="True" shape="(10843, 7)" />
<var name="tokenizer" type="BertTokenizerFast" qualifier="transformers.models.bert.tokenization_bert_fast" value="BertTokenizerFast%28name_or_path=%27./bert-base-cased%27%2C vocab_size=28996%2C model_max_length=1000000000000000019884624838656%2C is_fas...se%2C special=True%29%2C%0A%09103%3A AddedToken%28%22%5BMASK%5D%22%2C rstrip=False%2C lstrip=False%2C single_word=False%2C normalized=False%2C special=True%29%2C%0A%7D" isContainer="True" shape="28996" />
<var name="train_count" type="int" qualifier="builtins" value="9758" />
<var name="trainer" type="Trainer" qualifier="transformers.trainer" value="%3Ctransformers.trainer.Trainer object at 0x0000027DAAA33190&gt;" isContainer="True" />
<var name="training_args" type="TrainingArguments" qualifier="transformers.training_args" value="TrainingArguments%28%0A_n_gpu=1%2C%0Aadafactor=False%2C%0Aadam_beta1=0.9%2C%0Aadam_beta2=0.999%2C%0Aadam_epsilon=1e-08%2C%0Aauto_find_batch_size=False...use_ipex=False%2C%0Ause_legacy_prediction_loop=False%2C%0Ause_mps_device=False%2C%0Awarmup_ratio=0.0%2C%0Awarmup_steps=100%2C%0Aweight_decay=0.0%2C%0A%29" isContainer="True" />
</xml>
[{'label': 'POSITIVE', 'score': 0.9635627865791321}]
depressive score: 0.99951553 neutral score: 0.00048450698
<xml><var name="_dummy_ipython_val"  />
<var name="_dummy_special_var"  />
<var name="acc_metric" type="Accuracy" qualifier="evaluate_modules.metrics.accuracy.f887c0aab52c2d38e1f8a215681126379eca617f96c447638f751434e8e65b14.accuracy" value="EvaluationModule%28name%3A %22accuracy%22%2C module_type%3A %22metric%22%2C features%3A %7B%27predictions%27%3A Value%28dtype=%27int32%27%2C id=None%29%2C %27references...weight=%5B0.5%2C 2%2C 0.7%2C 0.5%2C 9%2C 0.4%5D%29%0A        &gt;&gt;&gt; print%28results%29%0A        %7B%27accuracy%27%3A 0.8778625954198473%7D%0A%22%22%22%2C stored examples%3A 0%29" isContainer="True" shape="0" />
<var name="base_model" type="BertForSequenceClassification" qualifier="transformers.models.bert.modeling_bert" value="BertForSequenceClassification%28%0A  %28bert%29%3A BertModel%28%0A    %28embeddings%29%3A BertEmbeddings%28%0A      %28word_embeddings%29%3A Embedding%2828996...anh%28%29%0A    %29%0A  %29%0A  %28dropout%29%3A Dropout%28p=0.1%2C inplace=False%29%0A  %28classifier%29%3A Linear%28in_features=768%2C out_features=2%2C bias=True%29%0A%29" isContainer="True" />
<var name="classifier" type="TextClassificationPipeline" qualifier="transformers.pipelines.text_classification" value="%3Ctransformers.pipelines.text_classification.TextClassificationPipeline object at 0x0000027E5A528E90&gt;" isContainer="True" />
<var name="dataset" type="DatasetDict" qualifier="datasets.dataset_dict" value="DatasetDict%28%7B%0A    train%3A Dataset%28%7B%0A        features%3A %5B%27id%27%2C %27text%27%2C %27label%27%2C %27source_data%27%5D%2C%0A        num_rows%3A 10843%0A    %7D%29%0A%7D%29" isContainer="True" shape="('train',)" />
<var name="dataset_eval" type="Dataset" qualifier="datasets.arrow_dataset" value="Dataset%28%7B%0A    features%3A %5B%27id%27%2C %27text%27%2C %27label%27%2C %27source_data%27%2C %27input_ids%27%2C %27token_type_ids%27%2C %27attention_mask%27%5D%2C%0A    num_rows%3A 1085%0A%7D%29" isContainer="True" shape="(1085, 7)" />
<var name="dataset_tokens" type="DatasetDict" qualifier="datasets.dataset_dict" value="DatasetDict%28%7B%0A    train%3A Dataset%28%7B%0A        features%3A %5B%27id%27%2C %27text%27%2C %27label%27%2C %27source_data%27%2C %27input_ids%27%2C %27token_type_ids%27%2C %27attention_mask%27%5D%2C%0A        num_rows%3A 10843%0A    %7D%29%0A%7D%29" isContainer="True" shape="('train',)" />
<var name="dataset_train" type="Dataset" qualifier="datasets.arrow_dataset" value="Dataset%28%7B%0A    features%3A %5B%27id%27%2C %27text%27%2C %27label%27%2C %27source_data%27%2C %27input_ids%27%2C %27token_type_ids%27%2C %27attention_mask%27%5D%2C%0A    num_rows%3A 9758%0A%7D%29" isContainer="True" shape="(9758, 7)" />
<var name="ft_model" type="BertForSequenceClassification" qualifier="transformers.models.bert.modeling_bert" value="BertForSequenceClassification%28%0A  %28bert%29%3A BertModel%28%0A    %28embeddings%29%3A BertEmbeddings%28%0A      %28word_embeddings%29%3A Embedding%2828996...anh%28%29%0A    %29%0A  %29%0A  %28dropout%29%3A Dropout%28p=0.1%2C inplace=False%29%0A  %28classifier%29%3A Linear%28in_features=768%2C out_features=2%2C bias=True%29%0A%29" isContainer="True" />
<var name="ft_model_checkpoint" type="str" qualifier="builtins" value="test_trainer/checkpoint-7317" />
<var name="label_count" type="int" qualifier="builtins" value="2" />
<var name="model_name" type="str" qualifier="builtins" value="./bert-base-cased" />
<var name="result" type="list" qualifier="builtins" value="%5B%7B%27label%27%3A %27POSITIVE%27%2C %27score%27%3A 0.9635627865791321%7D%5D" isContainer="True" shape="1" />
<var name="sample_out" type="SequenceClassifierOutput" qualifier="transformers.modeling_outputs" value="SequenceClassifierOutput%28loss=None%2C logits=tensor%28%5B%5B-4.0664%2C  3.5655%5D%5D%2C grad_fn=%3CAddmmBackward0&gt;%29%2C hidden_states=None%2C attentions=None%29" isContainer="True" shape="1" />
<var name="sample_text" type="str" qualifier="builtins" value="I have had ZERO anxiety since I got to the beach house. Tonight%27s our last night and that missing anxiety has returned with a vengeance." />
<var name="sample_tokens" type="BatchEncoding" qualifier="transformers.tokenization_utils_base" value="%7B%27input_ids%27%3A tensor%28%5B%5B  101%2C   146%2C  1138%2C  1125%2C   163%2C  9637%2C  2346%2C 10507%2C  1290%2C   146%2C%0A          1400%2C  1106%2C  1103%2C  46...%2C 0%2C 0%2C 0%2C%0A         0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C%0A         0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%5D%5D%29%7D" isContainer="True" shape="3" />
<var name="scores" type="ndarray" qualifier="numpy" value="%5B4.8450698e-04 9.9951553e-01%5D" isContainer="True" shape="(2,)" />
<var name="shuffle" type="Dataset" qualifier="datasets.arrow_dataset" value="Dataset%28%7B%0A    features%3A %5B%27id%27%2C %27text%27%2C %27label%27%2C %27source_data%27%2C %27input_ids%27%2C %27token_type_ids%27%2C %27attention_mask%27%5D%2C%0A    num_rows%3A 10843%0A%7D%29" isContainer="True" shape="(10843, 7)" />
<var name="tokenizer" type="BertTokenizerFast" qualifier="transformers.models.bert.tokenization_bert_fast" value="BertTokenizerFast%28name_or_path=%27./bert-base-cased%27%2C vocab_size=28996%2C model_max_length=1000000000000000019884624838656%2C is_fas...se%2C special=True%29%2C%0A%09103%3A AddedToken%28%22%5BMASK%5D%22%2C rstrip=False%2C lstrip=False%2C single_word=False%2C normalized=False%2C special=True%29%2C%0A%7D" isContainer="True" shape="28996" />
<var name="train_count" type="int" qualifier="builtins" value="9758" />
<var name="trainer" type="Trainer" qualifier="transformers.trainer" value="%3Ctransformers.trainer.Trainer object at 0x0000027DAAA33190&gt;" isContainer="True" />
<var name="training_args" type="TrainingArguments" qualifier="transformers.training_args" value="TrainingArguments%28%0A_n_gpu=1%2C%0Aadafactor=False%2C%0Aadam_beta1=0.9%2C%0Aadam_beta2=0.999%2C%0Aadam_epsilon=1e-08%2C%0Aauto_find_batch_size=False...use_ipex=False%2C%0Ause_legacy_prediction_loop=False%2C%0Ause_mps_device=False%2C%0Awarmup_ratio=0.0%2C%0Awarmup_steps=100%2C%0Aweight_decay=0.0%2C%0A%29" isContainer="True" />
</xml>
[{'label': 'NEGATIVE', 'score': 0.9932871460914612}]
depressive score: 0.00036327876 neutral score: 0.99963665
<xml><var name="_dummy_ipython_val"  />
<var name="_dummy_special_var"  />
<var name="acc_metric" type="Accuracy" qualifier="evaluate_modules.metrics.accuracy.f887c0aab52c2d38e1f8a215681126379eca617f96c447638f751434e8e65b14.accuracy" value="EvaluationModule%28name%3A %22accuracy%22%2C module_type%3A %22metric%22%2C features%3A %7B%27predictions%27%3A Value%28dtype=%27int32%27%2C id=None%29%2C %27references...weight=%5B0.5%2C 2%2C 0.7%2C 0.5%2C 9%2C 0.4%5D%29%0A        &gt;&gt;&gt; print%28results%29%0A        %7B%27accuracy%27%3A 0.8778625954198473%7D%0A%22%22%22%2C stored examples%3A 0%29" isContainer="True" shape="0" />
<var name="base_model" type="BertForSequenceClassification" qualifier="transformers.models.bert.modeling_bert" value="BertForSequenceClassification%28%0A  %28bert%29%3A BertModel%28%0A    %28embeddings%29%3A BertEmbeddings%28%0A      %28word_embeddings%29%3A Embedding%2828996...anh%28%29%0A    %29%0A  %29%0A  %28dropout%29%3A Dropout%28p=0.1%2C inplace=False%29%0A  %28classifier%29%3A Linear%28in_features=768%2C out_features=2%2C bias=True%29%0A%29" isContainer="True" />
<var name="classifier" type="TextClassificationPipeline" qualifier="transformers.pipelines.text_classification" value="%3Ctransformers.pipelines.text_classification.TextClassificationPipeline object at 0x0000027E5A53F150&gt;" isContainer="True" />
<var name="dataset" type="DatasetDict" qualifier="datasets.dataset_dict" value="DatasetDict%28%7B%0A    train%3A Dataset%28%7B%0A        features%3A %5B%27id%27%2C %27text%27%2C %27label%27%2C %27source_data%27%5D%2C%0A        num_rows%3A 10843%0A    %7D%29%0A%7D%29" isContainer="True" shape="('train',)" />
<var name="dataset_eval" type="Dataset" qualifier="datasets.arrow_dataset" value="Dataset%28%7B%0A    features%3A %5B%27id%27%2C %27text%27%2C %27label%27%2C %27source_data%27%2C %27input_ids%27%2C %27token_type_ids%27%2C %27attention_mask%27%5D%2C%0A    num_rows%3A 1085%0A%7D%29" isContainer="True" shape="(1085, 7)" />
<var name="dataset_tokens" type="DatasetDict" qualifier="datasets.dataset_dict" value="DatasetDict%28%7B%0A    train%3A Dataset%28%7B%0A        features%3A %5B%27id%27%2C %27text%27%2C %27label%27%2C %27source_data%27%2C %27input_ids%27%2C %27token_type_ids%27%2C %27attention_mask%27%5D%2C%0A        num_rows%3A 10843%0A    %7D%29%0A%7D%29" isContainer="True" shape="('train',)" />
<var name="dataset_train" type="Dataset" qualifier="datasets.arrow_dataset" value="Dataset%28%7B%0A    features%3A %5B%27id%27%2C %27text%27%2C %27label%27%2C %27source_data%27%2C %27input_ids%27%2C %27token_type_ids%27%2C %27attention_mask%27%5D%2C%0A    num_rows%3A 9758%0A%7D%29" isContainer="True" shape="(9758, 7)" />
<var name="ft_model" type="BertForSequenceClassification" qualifier="transformers.models.bert.modeling_bert" value="BertForSequenceClassification%28%0A  %28bert%29%3A BertModel%28%0A    %28embeddings%29%3A BertEmbeddings%28%0A      %28word_embeddings%29%3A Embedding%2828996...anh%28%29%0A    %29%0A  %29%0A  %28dropout%29%3A Dropout%28p=0.1%2C inplace=False%29%0A  %28classifier%29%3A Linear%28in_features=768%2C out_features=2%2C bias=True%29%0A%29" isContainer="True" />
<var name="ft_model_checkpoint" type="str" qualifier="builtins" value="test_trainer/checkpoint-7317" />
<var name="label_count" type="int" qualifier="builtins" value="2" />
<var name="model_name" type="str" qualifier="builtins" value="./bert-base-cased" />
<var name="result" type="list" qualifier="builtins" value="%5B%7B%27label%27%3A %27NEGATIVE%27%2C %27score%27%3A 0.9932871460914612%7D%5D" isContainer="True" shape="1" />
<var name="sample_out" type="SequenceClassifierOutput" qualifier="transformers.modeling_outputs" value="SequenceClassifierOutput%28loss=None%2C logits=tensor%28%5B%5B 3.9275%2C -3.9925%5D%5D%2C grad_fn=%3CAddmmBackward0&gt;%29%2C hidden_states=None%2C attentions=None%29" isContainer="True" shape="1" />
<var name="sample_text" type="str" qualifier="builtins" value="Depression cure%3F Taking THIS every day could help symptoms https%3A//t.co/WXAiakGChA" />
<var name="sample_tokens" type="BatchEncoding" qualifier="transformers.tokenization_utils_base" value="%7B%27input_ids%27%3A tensor%28%5B%5B  101%2C 11442%2C 11200%2C   136%2C  9251%2C   157%2C  3048%2C  6258%2C  1451%2C  1285%2C%0A          1180%2C  1494%2C  8006%2C 186...%2C 0%2C 0%2C 0%2C%0A         0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C%0A         0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%5D%5D%29%7D" isContainer="True" shape="3" />
<var name="scores" type="ndarray" qualifier="numpy" value="%5B9.9963665e-01 3.6327876e-04%5D" isContainer="True" shape="(2,)" />
<var name="shuffle" type="Dataset" qualifier="datasets.arrow_dataset" value="Dataset%28%7B%0A    features%3A %5B%27id%27%2C %27text%27%2C %27label%27%2C %27source_data%27%2C %27input_ids%27%2C %27token_type_ids%27%2C %27attention_mask%27%5D%2C%0A    num_rows%3A 10843%0A%7D%29" isContainer="True" shape="(10843, 7)" />
<var name="tokenizer" type="BertTokenizerFast" qualifier="transformers.models.bert.tokenization_bert_fast" value="BertTokenizerFast%28name_or_path=%27./bert-base-cased%27%2C vocab_size=28996%2C model_max_length=1000000000000000019884624838656%2C is_fas...se%2C special=True%29%2C%0A%09103%3A AddedToken%28%22%5BMASK%5D%22%2C rstrip=False%2C lstrip=False%2C single_word=False%2C normalized=False%2C special=True%29%2C%0A%7D" isContainer="True" shape="28996" />
<var name="train_count" type="int" qualifier="builtins" value="9758" />
<var name="trainer" type="Trainer" qualifier="transformers.trainer" value="%3Ctransformers.trainer.Trainer object at 0x0000027DAAA33190&gt;" isContainer="True" />
<var name="training_args" type="TrainingArguments" qualifier="transformers.training_args" value="TrainingArguments%28%0A_n_gpu=1%2C%0Aadafactor=False%2C%0Aadam_beta1=0.9%2C%0Aadam_beta2=0.999%2C%0Aadam_epsilon=1e-08%2C%0Aauto_find_batch_size=False...use_ipex=False%2C%0Ause_legacy_prediction_loop=False%2C%0Ause_mps_device=False%2C%0Awarmup_ratio=0.0%2C%0Awarmup_steps=100%2C%0Aweight_decay=0.0%2C%0A%29" isContainer="True" />
</xml>
[{'label': 'NEGATIVE', 'score': 0.9808326959609985}]
depressive score: 0.9990225 neutral score: 0.0009775396
<xml><var name="_dummy_ipython_val"  />
<var name="_dummy_special_var"  />
<var name="acc_metric" type="Accuracy" qualifier="evaluate_modules.metrics.accuracy.f887c0aab52c2d38e1f8a215681126379eca617f96c447638f751434e8e65b14.accuracy" value="EvaluationModule%28name%3A %22accuracy%22%2C module_type%3A %22metric%22%2C features%3A %7B%27predictions%27%3A Value%28dtype=%27int32%27%2C id=None%29%2C %27references...weight=%5B0.5%2C 2%2C 0.7%2C 0.5%2C 9%2C 0.4%5D%29%0A        &gt;&gt;&gt; print%28results%29%0A        %7B%27accuracy%27%3A 0.8778625954198473%7D%0A%22%22%22%2C stored examples%3A 0%29" isContainer="True" shape="0" />
<var name="base_model" type="BertForSequenceClassification" qualifier="transformers.models.bert.modeling_bert" value="BertForSequenceClassification%28%0A  %28bert%29%3A BertModel%28%0A    %28embeddings%29%3A BertEmbeddings%28%0A      %28word_embeddings%29%3A Embedding%2828996...anh%28%29%0A    %29%0A  %29%0A  %28dropout%29%3A Dropout%28p=0.1%2C inplace=False%29%0A  %28classifier%29%3A Linear%28in_features=768%2C out_features=2%2C bias=True%29%0A%29" isContainer="True" />
<var name="classifier" type="TextClassificationPipeline" qualifier="transformers.pipelines.text_classification" value="%3Ctransformers.pipelines.text_classification.TextClassificationPipeline object at 0x0000027DF5E50410&gt;" isContainer="True" />
<var name="dataset" type="DatasetDict" qualifier="datasets.dataset_dict" value="DatasetDict%28%7B%0A    train%3A Dataset%28%7B%0A        features%3A %5B%27id%27%2C %27text%27%2C %27label%27%2C %27source_data%27%5D%2C%0A        num_rows%3A 10843%0A    %7D%29%0A%7D%29" isContainer="True" shape="('train',)" />
<var name="dataset_eval" type="Dataset" qualifier="datasets.arrow_dataset" value="Dataset%28%7B%0A    features%3A %5B%27id%27%2C %27text%27%2C %27label%27%2C %27source_data%27%2C %27input_ids%27%2C %27token_type_ids%27%2C %27attention_mask%27%5D%2C%0A    num_rows%3A 1085%0A%7D%29" isContainer="True" shape="(1085, 7)" />
<var name="dataset_tokens" type="DatasetDict" qualifier="datasets.dataset_dict" value="DatasetDict%28%7B%0A    train%3A Dataset%28%7B%0A        features%3A %5B%27id%27%2C %27text%27%2C %27label%27%2C %27source_data%27%2C %27input_ids%27%2C %27token_type_ids%27%2C %27attention_mask%27%5D%2C%0A        num_rows%3A 10843%0A    %7D%29%0A%7D%29" isContainer="True" shape="('train',)" />
<var name="dataset_train" type="Dataset" qualifier="datasets.arrow_dataset" value="Dataset%28%7B%0A    features%3A %5B%27id%27%2C %27text%27%2C %27label%27%2C %27source_data%27%2C %27input_ids%27%2C %27token_type_ids%27%2C %27attention_mask%27%5D%2C%0A    num_rows%3A 9758%0A%7D%29" isContainer="True" shape="(9758, 7)" />
<var name="ft_model" type="BertForSequenceClassification" qualifier="transformers.models.bert.modeling_bert" value="BertForSequenceClassification%28%0A  %28bert%29%3A BertModel%28%0A    %28embeddings%29%3A BertEmbeddings%28%0A      %28word_embeddings%29%3A Embedding%2828996...anh%28%29%0A    %29%0A  %29%0A  %28dropout%29%3A Dropout%28p=0.1%2C inplace=False%29%0A  %28classifier%29%3A Linear%28in_features=768%2C out_features=2%2C bias=True%29%0A%29" isContainer="True" />
<var name="ft_model_checkpoint" type="str" qualifier="builtins" value="test_trainer/checkpoint-7317" />
<var name="label_count" type="int" qualifier="builtins" value="2" />
<var name="model_name" type="str" qualifier="builtins" value="./bert-base-cased" />
<var name="result" type="list" qualifier="builtins" value="%5B%7B%27label%27%3A %27NEGATIVE%27%2C %27score%27%3A 0.9808326959609985%7D%5D" isContainer="True" shape="1" />
<var name="sample_out" type="SequenceClassifierOutput" qualifier="transformers.modeling_outputs" value="SequenceClassifierOutput%28loss=None%2C logits=tensor%28%5B%5B-3.6528%2C  3.2767%5D%5D%2C grad_fn=%3CAddmmBackward0&gt;%29%2C hidden_states=None%2C attentions=None%29" isContainer="True" shape="1" />
<var name="sample_text" type="str" qualifier="builtins" value="Hey%2C look - I found my social anxiety again. Was wondering where that went." />
<var name="sample_tokens" type="BatchEncoding" qualifier="transformers.tokenization_utils_base" value="%7B%27input_ids%27%3A tensor%28%5B%5B  101%2C  4403%2C   117%2C  1440%2C   118%2C   146%2C  1276%2C  1139%2C  1934%2C 10507%2C%0A          1254%2C   119%2C  3982%2C  61...%2C 0%2C 0%2C 0%2C%0A         0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C%0A         0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%5D%5D%29%7D" isContainer="True" shape="3" />
<var name="scores" type="ndarray" qualifier="numpy" value="%5B9.775396e-04 9.990225e-01%5D" isContainer="True" shape="(2,)" />
<var name="shuffle" type="Dataset" qualifier="datasets.arrow_dataset" value="Dataset%28%7B%0A    features%3A %5B%27id%27%2C %27text%27%2C %27label%27%2C %27source_data%27%2C %27input_ids%27%2C %27token_type_ids%27%2C %27attention_mask%27%5D%2C%0A    num_rows%3A 10843%0A%7D%29" isContainer="True" shape="(10843, 7)" />
<var name="tokenizer" type="BertTokenizerFast" qualifier="transformers.models.bert.tokenization_bert_fast" value="BertTokenizerFast%28name_or_path=%27./bert-base-cased%27%2C vocab_size=28996%2C model_max_length=1000000000000000019884624838656%2C is_fas...se%2C special=True%29%2C%0A%09103%3A AddedToken%28%22%5BMASK%5D%22%2C rstrip=False%2C lstrip=False%2C single_word=False%2C normalized=False%2C special=True%29%2C%0A%7D" isContainer="True" shape="28996" />
<var name="train_count" type="int" qualifier="builtins" value="9758" />
<var name="trainer" type="Trainer" qualifier="transformers.trainer" value="%3Ctransformers.trainer.Trainer object at 0x0000027DAAA33190&gt;" isContainer="True" />
<var name="training_args" type="TrainingArguments" qualifier="transformers.training_args" value="TrainingArguments%28%0A_n_gpu=1%2C%0Aadafactor=False%2C%0Aadam_beta1=0.9%2C%0Aadam_beta2=0.999%2C%0Aadam_epsilon=1e-08%2C%0Aauto_find_batch_size=False...use_ipex=False%2C%0Ause_legacy_prediction_loop=False%2C%0Ause_mps_device=False%2C%0Awarmup_ratio=0.0%2C%0Awarmup_steps=100%2C%0Aweight_decay=0.0%2C%0A%29" isContainer="True" />
</xml>
[{'label': 'NEGATIVE', 'score': 0.9724207520484924}]
depressive score: 0.0001397597 neutral score: 0.99986017
<xml><var name="_dummy_ipython_val"  />
<var name="_dummy_special_var"  />
<var name="acc_metric" type="Accuracy" qualifier="evaluate_modules.metrics.accuracy.f887c0aab52c2d38e1f8a215681126379eca617f96c447638f751434e8e65b14.accuracy" value="EvaluationModule%28name%3A %22accuracy%22%2C module_type%3A %22metric%22%2C features%3A %7B%27predictions%27%3A Value%28dtype=%27int32%27%2C id=None%29%2C %27references...weight=%5B0.5%2C 2%2C 0.7%2C 0.5%2C 9%2C 0.4%5D%29%0A        &gt;&gt;&gt; print%28results%29%0A        %7B%27accuracy%27%3A 0.8778625954198473%7D%0A%22%22%22%2C stored examples%3A 0%29" isContainer="True" shape="0" />
<var name="base_model" type="BertForSequenceClassification" qualifier="transformers.models.bert.modeling_bert" value="BertForSequenceClassification%28%0A  %28bert%29%3A BertModel%28%0A    %28embeddings%29%3A BertEmbeddings%28%0A      %28word_embeddings%29%3A Embedding%2828996...anh%28%29%0A    %29%0A  %29%0A  %28dropout%29%3A Dropout%28p=0.1%2C inplace=False%29%0A  %28classifier%29%3A Linear%28in_features=768%2C out_features=2%2C bias=True%29%0A%29" isContainer="True" />
<var name="classifier" type="TextClassificationPipeline" qualifier="transformers.pipelines.text_classification" value="%3Ctransformers.pipelines.text_classification.TextClassificationPipeline object at 0x0000027E5A530C50&gt;" isContainer="True" />
<var name="dataset" type="DatasetDict" qualifier="datasets.dataset_dict" value="DatasetDict%28%7B%0A    train%3A Dataset%28%7B%0A        features%3A %5B%27id%27%2C %27text%27%2C %27label%27%2C %27source_data%27%5D%2C%0A        num_rows%3A 10843%0A    %7D%29%0A%7D%29" isContainer="True" shape="('train',)" />
<var name="dataset_eval" type="Dataset" qualifier="datasets.arrow_dataset" value="Dataset%28%7B%0A    features%3A %5B%27id%27%2C %27text%27%2C %27label%27%2C %27source_data%27%2C %27input_ids%27%2C %27token_type_ids%27%2C %27attention_mask%27%5D%2C%0A    num_rows%3A 1085%0A%7D%29" isContainer="True" shape="(1085, 7)" />
<var name="dataset_tokens" type="DatasetDict" qualifier="datasets.dataset_dict" value="DatasetDict%28%7B%0A    train%3A Dataset%28%7B%0A        features%3A %5B%27id%27%2C %27text%27%2C %27label%27%2C %27source_data%27%2C %27input_ids%27%2C %27token_type_ids%27%2C %27attention_mask%27%5D%2C%0A        num_rows%3A 10843%0A    %7D%29%0A%7D%29" isContainer="True" shape="('train',)" />
<var name="dataset_train" type="Dataset" qualifier="datasets.arrow_dataset" value="Dataset%28%7B%0A    features%3A %5B%27id%27%2C %27text%27%2C %27label%27%2C %27source_data%27%2C %27input_ids%27%2C %27token_type_ids%27%2C %27attention_mask%27%5D%2C%0A    num_rows%3A 9758%0A%7D%29" isContainer="True" shape="(9758, 7)" />
<var name="ft_model" type="BertForSequenceClassification" qualifier="transformers.models.bert.modeling_bert" value="BertForSequenceClassification%28%0A  %28bert%29%3A BertModel%28%0A    %28embeddings%29%3A BertEmbeddings%28%0A      %28word_embeddings%29%3A Embedding%2828996...anh%28%29%0A    %29%0A  %29%0A  %28dropout%29%3A Dropout%28p=0.1%2C inplace=False%29%0A  %28classifier%29%3A Linear%28in_features=768%2C out_features=2%2C bias=True%29%0A%29" isContainer="True" />
<var name="ft_model_checkpoint" type="str" qualifier="builtins" value="test_trainer/checkpoint-7317" />
<var name="label_count" type="int" qualifier="builtins" value="2" />
<var name="model_name" type="str" qualifier="builtins" value="./bert-base-cased" />
<var name="result" type="list" qualifier="builtins" value="%5B%7B%27label%27%3A %27NEGATIVE%27%2C %27score%27%3A 0.9724207520484924%7D%5D" isContainer="True" shape="1" />
<var name="sample_out" type="SequenceClassifierOutput" qualifier="transformers.modeling_outputs" value="SequenceClassifierOutput%28loss=None%2C logits=tensor%28%5B%5B 4.5593%2C -4.3161%5D%5D%2C grad_fn=%3CAddmmBackward0&gt;%29%2C hidden_states=None%2C attentions=None%29" isContainer="True" shape="1" />
<var name="sample_text" type="str" qualifier="builtins" value="Gossip Girl and Donald Trump give me so much anxiety" />
<var name="sample_tokens" type="BatchEncoding" qualifier="transformers.tokenization_utils_base" value="%7B%27input_ids%27%3A tensor%28%5B%5B  101%2C  3414%2C 19828%2C  1643%2C  4537%2C  1105%2C  5554%2C  8499%2C  1660%2C  1143%2C%0A          1177%2C  1277%2C 10507%2C   1...%2C 0%2C 0%2C 0%2C%0A         0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C%0A         0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%5D%5D%29%7D" isContainer="True" shape="3" />
<var name="scores" type="ndarray" qualifier="numpy" value="%5B9.9986017e-01 1.3975969e-04%5D" isContainer="True" shape="(2,)" />
<var name="shuffle" type="Dataset" qualifier="datasets.arrow_dataset" value="Dataset%28%7B%0A    features%3A %5B%27id%27%2C %27text%27%2C %27label%27%2C %27source_data%27%2C %27input_ids%27%2C %27token_type_ids%27%2C %27attention_mask%27%5D%2C%0A    num_rows%3A 10843%0A%7D%29" isContainer="True" shape="(10843, 7)" />
<var name="tokenizer" type="BertTokenizerFast" qualifier="transformers.models.bert.tokenization_bert_fast" value="BertTokenizerFast%28name_or_path=%27./bert-base-cased%27%2C vocab_size=28996%2C model_max_length=1000000000000000019884624838656%2C is_fas...se%2C special=True%29%2C%0A%09103%3A AddedToken%28%22%5BMASK%5D%22%2C rstrip=False%2C lstrip=False%2C single_word=False%2C normalized=False%2C special=True%29%2C%0A%7D" isContainer="True" shape="28996" />
<var name="train_count" type="int" qualifier="builtins" value="9758" />
<var name="trainer" type="Trainer" qualifier="transformers.trainer" value="%3Ctransformers.trainer.Trainer object at 0x0000027DAAA33190&gt;" isContainer="True" />
<var name="training_args" type="TrainingArguments" qualifier="transformers.training_args" value="TrainingArguments%28%0A_n_gpu=1%2C%0Aadafactor=False%2C%0Aadam_beta1=0.9%2C%0Aadam_beta2=0.999%2C%0Aadam_epsilon=1e-08%2C%0Aauto_find_batch_size=False...use_ipex=False%2C%0Ause_legacy_prediction_loop=False%2C%0Ause_mps_device=False%2C%0Awarmup_ratio=0.0%2C%0Awarmup_steps=100%2C%0Aweight_decay=0.0%2C%0A%29" isContainer="True" />
</xml>
[{'label': 'NEGATIVE', 'score': 0.9985626339912415}]
depressive score: 0.00038152843 neutral score: 0.9996184
<xml><var name="_dummy_ipython_val"  />
<var name="_dummy_special_var"  />
<var name="acc_metric" type="Accuracy" qualifier="evaluate_modules.metrics.accuracy.f887c0aab52c2d38e1f8a215681126379eca617f96c447638f751434e8e65b14.accuracy" value="EvaluationModule%28name%3A %22accuracy%22%2C module_type%3A %22metric%22%2C features%3A %7B%27predictions%27%3A Value%28dtype=%27int32%27%2C id=None%29%2C %27references...weight=%5B0.5%2C 2%2C 0.7%2C 0.5%2C 9%2C 0.4%5D%29%0A        &gt;&gt;&gt; print%28results%29%0A        %7B%27accuracy%27%3A 0.8778625954198473%7D%0A%22%22%22%2C stored examples%3A 0%29" isContainer="True" shape="0" />
<var name="base_model" type="BertForSequenceClassification" qualifier="transformers.models.bert.modeling_bert" value="BertForSequenceClassification%28%0A  %28bert%29%3A BertModel%28%0A    %28embeddings%29%3A BertEmbeddings%28%0A      %28word_embeddings%29%3A Embedding%2828996...anh%28%29%0A    %29%0A  %29%0A  %28dropout%29%3A Dropout%28p=0.1%2C inplace=False%29%0A  %28classifier%29%3A Linear%28in_features=768%2C out_features=2%2C bias=True%29%0A%29" isContainer="True" />
<var name="classifier" type="TextClassificationPipeline" qualifier="transformers.pipelines.text_classification" value="%3Ctransformers.pipelines.text_classification.TextClassificationPipeline object at 0x0000027D87709DD0&gt;" isContainer="True" />
<var name="dataset" type="DatasetDict" qualifier="datasets.dataset_dict" value="DatasetDict%28%7B%0A    train%3A Dataset%28%7B%0A        features%3A %5B%27id%27%2C %27text%27%2C %27label%27%2C %27source_data%27%5D%2C%0A        num_rows%3A 10843%0A    %7D%29%0A%7D%29" isContainer="True" shape="('train',)" />
<var name="dataset_eval" type="Dataset" qualifier="datasets.arrow_dataset" value="Dataset%28%7B%0A    features%3A %5B%27id%27%2C %27text%27%2C %27label%27%2C %27source_data%27%2C %27input_ids%27%2C %27token_type_ids%27%2C %27attention_mask%27%5D%2C%0A    num_rows%3A 1085%0A%7D%29" isContainer="True" shape="(1085, 7)" />
<var name="dataset_tokens" type="DatasetDict" qualifier="datasets.dataset_dict" value="DatasetDict%28%7B%0A    train%3A Dataset%28%7B%0A        features%3A %5B%27id%27%2C %27text%27%2C %27label%27%2C %27source_data%27%2C %27input_ids%27%2C %27token_type_ids%27%2C %27attention_mask%27%5D%2C%0A        num_rows%3A 10843%0A    %7D%29%0A%7D%29" isContainer="True" shape="('train',)" />
<var name="dataset_train" type="Dataset" qualifier="datasets.arrow_dataset" value="Dataset%28%7B%0A    features%3A %5B%27id%27%2C %27text%27%2C %27label%27%2C %27source_data%27%2C %27input_ids%27%2C %27token_type_ids%27%2C %27attention_mask%27%5D%2C%0A    num_rows%3A 9758%0A%7D%29" isContainer="True" shape="(9758, 7)" />
<var name="ft_model" type="BertForSequenceClassification" qualifier="transformers.models.bert.modeling_bert" value="BertForSequenceClassification%28%0A  %28bert%29%3A BertModel%28%0A    %28embeddings%29%3A BertEmbeddings%28%0A      %28word_embeddings%29%3A Embedding%2828996...anh%28%29%0A    %29%0A  %29%0A  %28dropout%29%3A Dropout%28p=0.1%2C inplace=False%29%0A  %28classifier%29%3A Linear%28in_features=768%2C out_features=2%2C bias=True%29%0A%29" isContainer="True" />
<var name="ft_model_checkpoint" type="str" qualifier="builtins" value="test_trainer/checkpoint-7317" />
<var name="label_count" type="int" qualifier="builtins" value="2" />
<var name="model_name" type="str" qualifier="builtins" value="./bert-base-cased" />
<var name="result" type="list" qualifier="builtins" value="%5B%7B%27label%27%3A %27NEGATIVE%27%2C %27score%27%3A 0.9985626339912415%7D%5D" isContainer="True" shape="1" />
<var name="sample_out" type="SequenceClassifierOutput" qualifier="transformers.modeling_outputs" value="SequenceClassifierOutput%28loss=None%2C logits=tensor%28%5B%5B 3.8844%2C -3.9866%5D%5D%2C grad_fn=%3CAddmmBackward0&gt;%29%2C hidden_states=None%2C attentions=None%29" isContainer="True" shape="1" />
<var name="sample_text" type="str" qualifier="builtins" value="I%27m glad I understand what it is now tho. I used to go through anxiety attacks %26amp%3B be confused %26amp%3B make it worse." />
<var name="sample_tokens" type="BatchEncoding" qualifier="transformers.tokenization_utils_base" value="%7B%27input_ids%27%3A tensor%28%5B%5B  101%2C   146%2C   112%2C   182%2C  5171%2C   146%2C  2437%2C  1184%2C  1122%2C  1110%2C%0A          1208%2C 24438%2C  1186%2C   1...%2C 0%2C 0%2C 0%2C%0A         0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C%0A         0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%5D%5D%29%7D" isContainer="True" shape="3" />
<var name="scores" type="ndarray" qualifier="numpy" value="%5B9.9961841e-01 3.8152843e-04%5D" isContainer="True" shape="(2,)" />
<var name="shuffle" type="Dataset" qualifier="datasets.arrow_dataset" value="Dataset%28%7B%0A    features%3A %5B%27id%27%2C %27text%27%2C %27label%27%2C %27source_data%27%2C %27input_ids%27%2C %27token_type_ids%27%2C %27attention_mask%27%5D%2C%0A    num_rows%3A 10843%0A%7D%29" isContainer="True" shape="(10843, 7)" />
<var name="tokenizer" type="BertTokenizerFast" qualifier="transformers.models.bert.tokenization_bert_fast" value="BertTokenizerFast%28name_or_path=%27./bert-base-cased%27%2C vocab_size=28996%2C model_max_length=1000000000000000019884624838656%2C is_fas...se%2C special=True%29%2C%0A%09103%3A AddedToken%28%22%5BMASK%5D%22%2C rstrip=False%2C lstrip=False%2C single_word=False%2C normalized=False%2C special=True%29%2C%0A%7D" isContainer="True" shape="28996" />
<var name="train_count" type="int" qualifier="builtins" value="9758" />
<var name="trainer" type="Trainer" qualifier="transformers.trainer" value="%3Ctransformers.trainer.Trainer object at 0x0000027DAAA33190&gt;" isContainer="True" />
<var name="training_args" type="TrainingArguments" qualifier="transformers.training_args" value="TrainingArguments%28%0A_n_gpu=1%2C%0Aadafactor=False%2C%0Aadam_beta1=0.9%2C%0Aadam_beta2=0.999%2C%0Aadam_epsilon=1e-08%2C%0Aauto_find_batch_size=False...use_ipex=False%2C%0Ause_legacy_prediction_loop=False%2C%0Ause_mps_device=False%2C%0Awarmup_ratio=0.0%2C%0Awarmup_steps=100%2C%0Aweight_decay=0.0%2C%0A%29" isContainer="True" />
</xml>
[{'label': 'NEGATIVE', 'score': 0.9990676045417786}]
depressive score: 0.05800468 neutral score: 0.9419953
<xml><var name="_dummy_ipython_val"  />
<var name="_dummy_special_var"  />
<var name="acc_metric" type="Accuracy" qualifier="evaluate_modules.metrics.accuracy.f887c0aab52c2d38e1f8a215681126379eca617f96c447638f751434e8e65b14.accuracy" value="EvaluationModule%28name%3A %22accuracy%22%2C module_type%3A %22metric%22%2C features%3A %7B%27predictions%27%3A Value%28dtype=%27int32%27%2C id=None%29%2C %27references...weight=%5B0.5%2C 2%2C 0.7%2C 0.5%2C 9%2C 0.4%5D%29%0A        &gt;&gt;&gt; print%28results%29%0A        %7B%27accuracy%27%3A 0.8778625954198473%7D%0A%22%22%22%2C stored examples%3A 0%29" isContainer="True" shape="0" />
<var name="base_model" type="BertForSequenceClassification" qualifier="transformers.models.bert.modeling_bert" value="BertForSequenceClassification%28%0A  %28bert%29%3A BertModel%28%0A    %28embeddings%29%3A BertEmbeddings%28%0A      %28word_embeddings%29%3A Embedding%2828996...anh%28%29%0A    %29%0A  %29%0A  %28dropout%29%3A Dropout%28p=0.1%2C inplace=False%29%0A  %28classifier%29%3A Linear%28in_features=768%2C out_features=2%2C bias=True%29%0A%29" isContainer="True" />
<var name="classifier" type="TextClassificationPipeline" qualifier="transformers.pipelines.text_classification" value="%3Ctransformers.pipelines.text_classification.TextClassificationPipeline object at 0x0000027DD523F5D0&gt;" isContainer="True" />
<var name="dataset" type="DatasetDict" qualifier="datasets.dataset_dict" value="DatasetDict%28%7B%0A    train%3A Dataset%28%7B%0A        features%3A %5B%27id%27%2C %27text%27%2C %27label%27%2C %27source_data%27%5D%2C%0A        num_rows%3A 10843%0A    %7D%29%0A%7D%29" isContainer="True" shape="('train',)" />
<var name="dataset_eval" type="Dataset" qualifier="datasets.arrow_dataset" value="Dataset%28%7B%0A    features%3A %5B%27id%27%2C %27text%27%2C %27label%27%2C %27source_data%27%2C %27input_ids%27%2C %27token_type_ids%27%2C %27attention_mask%27%5D%2C%0A    num_rows%3A 1085%0A%7D%29" isContainer="True" shape="(1085, 7)" />
<var name="dataset_tokens" type="DatasetDict" qualifier="datasets.dataset_dict" value="DatasetDict%28%7B%0A    train%3A Dataset%28%7B%0A        features%3A %5B%27id%27%2C %27text%27%2C %27label%27%2C %27source_data%27%2C %27input_ids%27%2C %27token_type_ids%27%2C %27attention_mask%27%5D%2C%0A        num_rows%3A 10843%0A    %7D%29%0A%7D%29" isContainer="True" shape="('train',)" />
<var name="dataset_train" type="Dataset" qualifier="datasets.arrow_dataset" value="Dataset%28%7B%0A    features%3A %5B%27id%27%2C %27text%27%2C %27label%27%2C %27source_data%27%2C %27input_ids%27%2C %27token_type_ids%27%2C %27attention_mask%27%5D%2C%0A    num_rows%3A 9758%0A%7D%29" isContainer="True" shape="(9758, 7)" />
<var name="ft_model" type="BertForSequenceClassification" qualifier="transformers.models.bert.modeling_bert" value="BertForSequenceClassification%28%0A  %28bert%29%3A BertModel%28%0A    %28embeddings%29%3A BertEmbeddings%28%0A      %28word_embeddings%29%3A Embedding%2828996...anh%28%29%0A    %29%0A  %29%0A  %28dropout%29%3A Dropout%28p=0.1%2C inplace=False%29%0A  %28classifier%29%3A Linear%28in_features=768%2C out_features=2%2C bias=True%29%0A%29" isContainer="True" />
<var name="ft_model_checkpoint" type="str" qualifier="builtins" value="test_trainer/checkpoint-7317" />
<var name="label_count" type="int" qualifier="builtins" value="2" />
<var name="model_name" type="str" qualifier="builtins" value="./bert-base-cased" />
<var name="result" type="list" qualifier="builtins" value="%5B%7B%27label%27%3A %27NEGATIVE%27%2C %27score%27%3A 0.9990676045417786%7D%5D" isContainer="True" shape="1" />
<var name="sample_out" type="SequenceClassifierOutput" qualifier="transformers.modeling_outputs" value="SequenceClassifierOutput%28loss=None%2C logits=tensor%28%5B%5B 1.2554%2C -1.5321%5D%5D%2C grad_fn=%3CAddmmBackward0&gt;%29%2C hidden_states=None%2C attentions=None%29" isContainer="True" shape="1" />
<var name="sample_text" type="str" qualifier="builtins" value="RT %40oraltwjnk%3A Depression https%3A//t.co/g4QIZjnRj1" />
<var name="sample_tokens" type="BatchEncoding" qualifier="transformers.tokenization_utils_base" value="%7B%27input_ids%27%3A tensor%28%5B%5B  101%2C   155%2C  1942%2C   137%2C  9619%2C  1204%2C  2246%2C 22923%2C  1377%2C   131%2C%0A         11442%2C 18630%2C   131%2C   1...%2C 0%2C 0%2C 0%2C%0A         0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C%0A         0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%5D%5D%29%7D" isContainer="True" shape="3" />
<var name="scores" type="ndarray" qualifier="numpy" value="%5B0.9419953  0.05800468%5D" isContainer="True" shape="(2,)" />
<var name="shuffle" type="Dataset" qualifier="datasets.arrow_dataset" value="Dataset%28%7B%0A    features%3A %5B%27id%27%2C %27text%27%2C %27label%27%2C %27source_data%27%2C %27input_ids%27%2C %27token_type_ids%27%2C %27attention_mask%27%5D%2C%0A    num_rows%3A 10843%0A%7D%29" isContainer="True" shape="(10843, 7)" />
<var name="tokenizer" type="BertTokenizerFast" qualifier="transformers.models.bert.tokenization_bert_fast" value="BertTokenizerFast%28name_or_path=%27./bert-base-cased%27%2C vocab_size=28996%2C model_max_length=1000000000000000019884624838656%2C is_fas...se%2C special=True%29%2C%0A%09103%3A AddedToken%28%22%5BMASK%5D%22%2C rstrip=False%2C lstrip=False%2C single_word=False%2C normalized=False%2C special=True%29%2C%0A%7D" isContainer="True" shape="28996" />
<var name="train_count" type="int" qualifier="builtins" value="9758" />
<var name="trainer" type="Trainer" qualifier="transformers.trainer" value="%3Ctransformers.trainer.Trainer object at 0x0000027DAAA33190&gt;" isContainer="True" />
<var name="training_args" type="TrainingArguments" qualifier="transformers.training_args" value="TrainingArguments%28%0A_n_gpu=1%2C%0Aadafactor=False%2C%0Aadam_beta1=0.9%2C%0Aadam_beta2=0.999%2C%0Aadam_epsilon=1e-08%2C%0Aauto_find_batch_size=False...use_ipex=False%2C%0Ause_legacy_prediction_loop=False%2C%0Ause_mps_device=False%2C%0Awarmup_ratio=0.0%2C%0Awarmup_steps=100%2C%0Aweight_decay=0.0%2C%0A%29" isContainer="True" />
</xml>
[{'label': 'NEGATIVE', 'score': 0.9971976280212402}]
depressive score: 0.00013547632 neutral score: 0.99986446
<xml><var name="_dummy_ipython_val"  />
<var name="_dummy_special_var"  />
<var name="acc_metric" type="Accuracy" qualifier="evaluate_modules.metrics.accuracy.f887c0aab52c2d38e1f8a215681126379eca617f96c447638f751434e8e65b14.accuracy" value="EvaluationModule%28name%3A %22accuracy%22%2C module_type%3A %22metric%22%2C features%3A %7B%27predictions%27%3A Value%28dtype=%27int32%27%2C id=None%29%2C %27references...weight=%5B0.5%2C 2%2C 0.7%2C 0.5%2C 9%2C 0.4%5D%29%0A        &gt;&gt;&gt; print%28results%29%0A        %7B%27accuracy%27%3A 0.8778625954198473%7D%0A%22%22%22%2C stored examples%3A 0%29" isContainer="True" shape="0" />
<var name="base_model" type="BertForSequenceClassification" qualifier="transformers.models.bert.modeling_bert" value="BertForSequenceClassification%28%0A  %28bert%29%3A BertModel%28%0A    %28embeddings%29%3A BertEmbeddings%28%0A      %28word_embeddings%29%3A Embedding%2828996...anh%28%29%0A    %29%0A  %29%0A  %28dropout%29%3A Dropout%28p=0.1%2C inplace=False%29%0A  %28classifier%29%3A Linear%28in_features=768%2C out_features=2%2C bias=True%29%0A%29" isContainer="True" />
<var name="classifier" type="TextClassificationPipeline" qualifier="transformers.pipelines.text_classification" value="%3Ctransformers.pipelines.text_classification.TextClassificationPipeline object at 0x0000027E5A528E90&gt;" isContainer="True" />
<var name="dataset" type="DatasetDict" qualifier="datasets.dataset_dict" value="DatasetDict%28%7B%0A    train%3A Dataset%28%7B%0A        features%3A %5B%27id%27%2C %27text%27%2C %27label%27%2C %27source_data%27%5D%2C%0A        num_rows%3A 10843%0A    %7D%29%0A%7D%29" isContainer="True" shape="('train',)" />
<var name="dataset_eval" type="Dataset" qualifier="datasets.arrow_dataset" value="Dataset%28%7B%0A    features%3A %5B%27id%27%2C %27text%27%2C %27label%27%2C %27source_data%27%2C %27input_ids%27%2C %27token_type_ids%27%2C %27attention_mask%27%5D%2C%0A    num_rows%3A 1085%0A%7D%29" isContainer="True" shape="(1085, 7)" />
<var name="dataset_tokens" type="DatasetDict" qualifier="datasets.dataset_dict" value="DatasetDict%28%7B%0A    train%3A Dataset%28%7B%0A        features%3A %5B%27id%27%2C %27text%27%2C %27label%27%2C %27source_data%27%2C %27input_ids%27%2C %27token_type_ids%27%2C %27attention_mask%27%5D%2C%0A        num_rows%3A 10843%0A    %7D%29%0A%7D%29" isContainer="True" shape="('train',)" />
<var name="dataset_train" type="Dataset" qualifier="datasets.arrow_dataset" value="Dataset%28%7B%0A    features%3A %5B%27id%27%2C %27text%27%2C %27label%27%2C %27source_data%27%2C %27input_ids%27%2C %27token_type_ids%27%2C %27attention_mask%27%5D%2C%0A    num_rows%3A 9758%0A%7D%29" isContainer="True" shape="(9758, 7)" />
<var name="ft_model" type="BertForSequenceClassification" qualifier="transformers.models.bert.modeling_bert" value="BertForSequenceClassification%28%0A  %28bert%29%3A BertModel%28%0A    %28embeddings%29%3A BertEmbeddings%28%0A      %28word_embeddings%29%3A Embedding%2828996...anh%28%29%0A    %29%0A  %29%0A  %28dropout%29%3A Dropout%28p=0.1%2C inplace=False%29%0A  %28classifier%29%3A Linear%28in_features=768%2C out_features=2%2C bias=True%29%0A%29" isContainer="True" />
<var name="ft_model_checkpoint" type="str" qualifier="builtins" value="test_trainer/checkpoint-7317" />
<var name="label_count" type="int" qualifier="builtins" value="2" />
<var name="model_name" type="str" qualifier="builtins" value="./bert-base-cased" />
<var name="result" type="list" qualifier="builtins" value="%5B%7B%27label%27%3A %27NEGATIVE%27%2C %27score%27%3A 0.9971976280212402%7D%5D" isContainer="True" shape="1" />
<var name="sample_out" type="SequenceClassifierOutput" qualifier="transformers.modeling_outputs" value="SequenceClassifierOutput%28loss=None%2C logits=tensor%28%5B%5B 4.5909%2C -4.3157%5D%5D%2C grad_fn=%3CAddmmBackward0&gt;%29%2C hidden_states=None%2C attentions=None%29" isContainer="True" shape="1" />
<var name="sample_text" type="str" qualifier="builtins" value="RT %40COCONUTOILBAE%3A when you want to be friends w ppl but ppl think ur mean and unapproachable cus u have a resting bitch face and soci%E2%80%A6 " />
<var name="sample_tokens" type="BatchEncoding" qualifier="transformers.tokenization_utils_base" value="%7B%27input_ids%27%3A tensor%28%5B%5B  101%2C   155%2C  1942%2C   137%2C 18732%2C 15678%2C 21760%2C 18082%2C 17656%2C  8215%2C%0A          2036%2C   131%2C  1165%2C  11...%2C 0%2C 0%2C 0%2C%0A         0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C%0A         0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%5D%5D%29%7D" isContainer="True" shape="3" />
<var name="scores" type="ndarray" qualifier="numpy" value="%5B9.9986446e-01 1.3547632e-04%5D" isContainer="True" shape="(2,)" />
<var name="shuffle" type="Dataset" qualifier="datasets.arrow_dataset" value="Dataset%28%7B%0A    features%3A %5B%27id%27%2C %27text%27%2C %27label%27%2C %27source_data%27%2C %27input_ids%27%2C %27token_type_ids%27%2C %27attention_mask%27%5D%2C%0A    num_rows%3A 10843%0A%7D%29" isContainer="True" shape="(10843, 7)" />
<var name="tokenizer" type="BertTokenizerFast" qualifier="transformers.models.bert.tokenization_bert_fast" value="BertTokenizerFast%28name_or_path=%27./bert-base-cased%27%2C vocab_size=28996%2C model_max_length=1000000000000000019884624838656%2C is_fas...se%2C special=True%29%2C%0A%09103%3A AddedToken%28%22%5BMASK%5D%22%2C rstrip=False%2C lstrip=False%2C single_word=False%2C normalized=False%2C special=True%29%2C%0A%7D" isContainer="True" shape="28996" />
<var name="train_count" type="int" qualifier="builtins" value="9758" />
<var name="trainer" type="Trainer" qualifier="transformers.trainer" value="%3Ctransformers.trainer.Trainer object at 0x0000027DAAA33190&gt;" isContainer="True" />
<var name="training_args" type="TrainingArguments" qualifier="transformers.training_args" value="TrainingArguments%28%0A_n_gpu=1%2C%0Aadafactor=False%2C%0Aadam_beta1=0.9%2C%0Aadam_beta2=0.999%2C%0Aadam_epsilon=1e-08%2C%0Aauto_find_batch_size=False...use_ipex=False%2C%0Ause_legacy_prediction_loop=False%2C%0Ause_mps_device=False%2C%0Awarmup_ratio=0.0%2C%0Awarmup_steps=100%2C%0Aweight_decay=0.0%2C%0A%29" isContainer="True" />
</xml>
[{'label': 'NEGATIVE', 'score': 0.9192779660224915}]
depressive score: 0.99954057 neutral score: 0.00045951107
<xml><var name="_dummy_ipython_val"  />
<var name="_dummy_special_var"  />
<var name="acc_metric" type="Accuracy" qualifier="evaluate_modules.metrics.accuracy.f887c0aab52c2d38e1f8a215681126379eca617f96c447638f751434e8e65b14.accuracy" value="EvaluationModule%28name%3A %22accuracy%22%2C module_type%3A %22metric%22%2C features%3A %7B%27predictions%27%3A Value%28dtype=%27int32%27%2C id=None%29%2C %27references...weight=%5B0.5%2C 2%2C 0.7%2C 0.5%2C 9%2C 0.4%5D%29%0A        &gt;&gt;&gt; print%28results%29%0A        %7B%27accuracy%27%3A 0.8778625954198473%7D%0A%22%22%22%2C stored examples%3A 0%29" isContainer="True" shape="0" />
<var name="base_model" type="BertForSequenceClassification" qualifier="transformers.models.bert.modeling_bert" value="BertForSequenceClassification%28%0A  %28bert%29%3A BertModel%28%0A    %28embeddings%29%3A BertEmbeddings%28%0A      %28word_embeddings%29%3A Embedding%2828996...anh%28%29%0A    %29%0A  %29%0A  %28dropout%29%3A Dropout%28p=0.1%2C inplace=False%29%0A  %28classifier%29%3A Linear%28in_features=768%2C out_features=2%2C bias=True%29%0A%29" isContainer="True" />
<var name="classifier" type="TextClassificationPipeline" qualifier="transformers.pipelines.text_classification" value="%3Ctransformers.pipelines.text_classification.TextClassificationPipeline object at 0x0000027DD3BF6310&gt;" isContainer="True" />
<var name="dataset" type="DatasetDict" qualifier="datasets.dataset_dict" value="DatasetDict%28%7B%0A    train%3A Dataset%28%7B%0A        features%3A %5B%27id%27%2C %27text%27%2C %27label%27%2C %27source_data%27%5D%2C%0A        num_rows%3A 10843%0A    %7D%29%0A%7D%29" isContainer="True" shape="('train',)" />
<var name="dataset_eval" type="Dataset" qualifier="datasets.arrow_dataset" value="Dataset%28%7B%0A    features%3A %5B%27id%27%2C %27text%27%2C %27label%27%2C %27source_data%27%2C %27input_ids%27%2C %27token_type_ids%27%2C %27attention_mask%27%5D%2C%0A    num_rows%3A 1085%0A%7D%29" isContainer="True" shape="(1085, 7)" />
<var name="dataset_tokens" type="DatasetDict" qualifier="datasets.dataset_dict" value="DatasetDict%28%7B%0A    train%3A Dataset%28%7B%0A        features%3A %5B%27id%27%2C %27text%27%2C %27label%27%2C %27source_data%27%2C %27input_ids%27%2C %27token_type_ids%27%2C %27attention_mask%27%5D%2C%0A        num_rows%3A 10843%0A    %7D%29%0A%7D%29" isContainer="True" shape="('train',)" />
<var name="dataset_train" type="Dataset" qualifier="datasets.arrow_dataset" value="Dataset%28%7B%0A    features%3A %5B%27id%27%2C %27text%27%2C %27label%27%2C %27source_data%27%2C %27input_ids%27%2C %27token_type_ids%27%2C %27attention_mask%27%5D%2C%0A    num_rows%3A 9758%0A%7D%29" isContainer="True" shape="(9758, 7)" />
<var name="ft_model" type="BertForSequenceClassification" qualifier="transformers.models.bert.modeling_bert" value="BertForSequenceClassification%28%0A  %28bert%29%3A BertModel%28%0A    %28embeddings%29%3A BertEmbeddings%28%0A      %28word_embeddings%29%3A Embedding%2828996...anh%28%29%0A    %29%0A  %29%0A  %28dropout%29%3A Dropout%28p=0.1%2C inplace=False%29%0A  %28classifier%29%3A Linear%28in_features=768%2C out_features=2%2C bias=True%29%0A%29" isContainer="True" />
<var name="ft_model_checkpoint" type="str" qualifier="builtins" value="test_trainer/checkpoint-7317" />
<var name="label_count" type="int" qualifier="builtins" value="2" />
<var name="model_name" type="str" qualifier="builtins" value="./bert-base-cased" />
<var name="result" type="list" qualifier="builtins" value="%5B%7B%27label%27%3A %27NEGATIVE%27%2C %27score%27%3A 0.9192779660224915%7D%5D" isContainer="True" shape="1" />
<var name="sample_out" type="SequenceClassifierOutput" qualifier="transformers.modeling_outputs" value="SequenceClassifierOutput%28loss=None%2C logits=tensor%28%5B%5B-4.1096%2C  3.5752%5D%5D%2C grad_fn=%3CAddmmBackward0&gt;%29%2C hidden_states=None%2C attentions=None%29" isContainer="True" shape="1" />
<var name="sample_text" type="str" qualifier="builtins" value="RT %40loopzoop%3A Hello%3F 2 hour depression nap%3F Do you remember me...in monaco... i made u that bracelet" />
<var name="sample_tokens" type="BatchEncoding" qualifier="transformers.tokenization_utils_base" value="%7B%27input_ids%27%3A tensor%28%5B%5B  101%2C   155%2C  1942%2C   137%2C  7812%2C  6112%2C  4184%2C   131%2C  8667%2C   136%2C%0A           123%2C  2396%2C  7560%2C 229...%2C 0%2C 0%2C 0%2C%0A         0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C%0A         0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%5D%5D%29%7D" isContainer="True" shape="3" />
<var name="scores" type="ndarray" qualifier="numpy" value="%5B4.5951107e-04 9.9954057e-01%5D" isContainer="True" shape="(2,)" />
<var name="shuffle" type="Dataset" qualifier="datasets.arrow_dataset" value="Dataset%28%7B%0A    features%3A %5B%27id%27%2C %27text%27%2C %27label%27%2C %27source_data%27%2C %27input_ids%27%2C %27token_type_ids%27%2C %27attention_mask%27%5D%2C%0A    num_rows%3A 10843%0A%7D%29" isContainer="True" shape="(10843, 7)" />
<var name="tokenizer" type="BertTokenizerFast" qualifier="transformers.models.bert.tokenization_bert_fast" value="BertTokenizerFast%28name_or_path=%27./bert-base-cased%27%2C vocab_size=28996%2C model_max_length=1000000000000000019884624838656%2C is_fas...se%2C special=True%29%2C%0A%09103%3A AddedToken%28%22%5BMASK%5D%22%2C rstrip=False%2C lstrip=False%2C single_word=False%2C normalized=False%2C special=True%29%2C%0A%7D" isContainer="True" shape="28996" />
<var name="train_count" type="int" qualifier="builtins" value="9758" />
<var name="trainer" type="Trainer" qualifier="transformers.trainer" value="%3Ctransformers.trainer.Trainer object at 0x0000027DAAA33190&gt;" isContainer="True" />
<var name="training_args" type="TrainingArguments" qualifier="transformers.training_args" value="TrainingArguments%28%0A_n_gpu=1%2C%0Aadafactor=False%2C%0Aadam_beta1=0.9%2C%0Aadam_beta2=0.999%2C%0Aadam_epsilon=1e-08%2C%0Aauto_find_batch_size=False...use_ipex=False%2C%0Ause_legacy_prediction_loop=False%2C%0Ause_mps_device=False%2C%0Awarmup_ratio=0.0%2C%0Awarmup_steps=100%2C%0Aweight_decay=0.0%2C%0A%29" isContainer="True" />
</xml>
[{'label': 'NEGATIVE', 'score': 0.9984478950500488}]
depressive score: 0.99867463 neutral score: 0.0013253915
<xml><var name="_dummy_ipython_val"  />
<var name="_dummy_special_var"  />
<var name="acc_metric" type="Accuracy" qualifier="evaluate_modules.metrics.accuracy.f887c0aab52c2d38e1f8a215681126379eca617f96c447638f751434e8e65b14.accuracy" value="EvaluationModule%28name%3A %22accuracy%22%2C module_type%3A %22metric%22%2C features%3A %7B%27predictions%27%3A Value%28dtype=%27int32%27%2C id=None%29%2C %27references...weight=%5B0.5%2C 2%2C 0.7%2C 0.5%2C 9%2C 0.4%5D%29%0A        &gt;&gt;&gt; print%28results%29%0A        %7B%27accuracy%27%3A 0.8778625954198473%7D%0A%22%22%22%2C stored examples%3A 0%29" isContainer="True" shape="0" />
<var name="base_model" type="BertForSequenceClassification" qualifier="transformers.models.bert.modeling_bert" value="BertForSequenceClassification%28%0A  %28bert%29%3A BertModel%28%0A    %28embeddings%29%3A BertEmbeddings%28%0A      %28word_embeddings%29%3A Embedding%2828996...anh%28%29%0A    %29%0A  %29%0A  %28dropout%29%3A Dropout%28p=0.1%2C inplace=False%29%0A  %28classifier%29%3A Linear%28in_features=768%2C out_features=2%2C bias=True%29%0A%29" isContainer="True" />
<var name="classifier" type="TextClassificationPipeline" qualifier="transformers.pipelines.text_classification" value="%3Ctransformers.pipelines.text_classification.TextClassificationPipeline object at 0x0000027D89569410&gt;" isContainer="True" />
<var name="dataset" type="DatasetDict" qualifier="datasets.dataset_dict" value="DatasetDict%28%7B%0A    train%3A Dataset%28%7B%0A        features%3A %5B%27id%27%2C %27text%27%2C %27label%27%2C %27source_data%27%5D%2C%0A        num_rows%3A 10843%0A    %7D%29%0A%7D%29" isContainer="True" shape="('train',)" />
<var name="dataset_eval" type="Dataset" qualifier="datasets.arrow_dataset" value="Dataset%28%7B%0A    features%3A %5B%27id%27%2C %27text%27%2C %27label%27%2C %27source_data%27%2C %27input_ids%27%2C %27token_type_ids%27%2C %27attention_mask%27%5D%2C%0A    num_rows%3A 1085%0A%7D%29" isContainer="True" shape="(1085, 7)" />
<var name="dataset_tokens" type="DatasetDict" qualifier="datasets.dataset_dict" value="DatasetDict%28%7B%0A    train%3A Dataset%28%7B%0A        features%3A %5B%27id%27%2C %27text%27%2C %27label%27%2C %27source_data%27%2C %27input_ids%27%2C %27token_type_ids%27%2C %27attention_mask%27%5D%2C%0A        num_rows%3A 10843%0A    %7D%29%0A%7D%29" isContainer="True" shape="('train',)" />
<var name="dataset_train" type="Dataset" qualifier="datasets.arrow_dataset" value="Dataset%28%7B%0A    features%3A %5B%27id%27%2C %27text%27%2C %27label%27%2C %27source_data%27%2C %27input_ids%27%2C %27token_type_ids%27%2C %27attention_mask%27%5D%2C%0A    num_rows%3A 9758%0A%7D%29" isContainer="True" shape="(9758, 7)" />
<var name="ft_model" type="BertForSequenceClassification" qualifier="transformers.models.bert.modeling_bert" value="BertForSequenceClassification%28%0A  %28bert%29%3A BertModel%28%0A    %28embeddings%29%3A BertEmbeddings%28%0A      %28word_embeddings%29%3A Embedding%2828996...anh%28%29%0A    %29%0A  %29%0A  %28dropout%29%3A Dropout%28p=0.1%2C inplace=False%29%0A  %28classifier%29%3A Linear%28in_features=768%2C out_features=2%2C bias=True%29%0A%29" isContainer="True" />
<var name="ft_model_checkpoint" type="str" qualifier="builtins" value="test_trainer/checkpoint-7317" />
<var name="label_count" type="int" qualifier="builtins" value="2" />
<var name="model_name" type="str" qualifier="builtins" value="./bert-base-cased" />
<var name="result" type="list" qualifier="builtins" value="%5B%7B%27label%27%3A %27NEGATIVE%27%2C %27score%27%3A 0.9984478950500488%7D%5D" isContainer="True" shape="1" />
<var name="sample_out" type="SequenceClassifierOutput" qualifier="transformers.modeling_outputs" value="SequenceClassifierOutput%28loss=None%2C logits=tensor%28%5B%5B-3.5052%2C  3.1195%5D%5D%2C grad_fn=%3CAddmmBackward0&gt;%29%2C hidden_states=None%2C attentions=None%29" isContainer="True" shape="1" />
<var name="sample_text" type="str" qualifier="builtins" value="RT %40RTFFacts%3A According to studies%2C high-anxiety people are more likely to make bad decisions because they tend to catastrophize uncertain%E2%80%A6" />
<var name="sample_tokens" type="BatchEncoding" qualifier="transformers.tokenization_utils_base" value="%7B%27input_ids%27%3A tensor%28%5B%5B  101%2C   155%2C  1942%2C   137%2C   155%2C 22169%2C  2271%2C 19523%2C   131%2C  1792%2C%0A          1106%2C  2527%2C   117%2C  13...%2C 0%2C 0%2C 0%2C%0A         0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C%0A         0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%5D%5D%29%7D" isContainer="True" shape="3" />
<var name="scores" type="ndarray" qualifier="numpy" value="%5B0.00132539 0.99867463%5D" isContainer="True" shape="(2,)" />
<var name="shuffle" type="Dataset" qualifier="datasets.arrow_dataset" value="Dataset%28%7B%0A    features%3A %5B%27id%27%2C %27text%27%2C %27label%27%2C %27source_data%27%2C %27input_ids%27%2C %27token_type_ids%27%2C %27attention_mask%27%5D%2C%0A    num_rows%3A 10843%0A%7D%29" isContainer="True" shape="(10843, 7)" />
<var name="tokenizer" type="BertTokenizerFast" qualifier="transformers.models.bert.tokenization_bert_fast" value="BertTokenizerFast%28name_or_path=%27./bert-base-cased%27%2C vocab_size=28996%2C model_max_length=1000000000000000019884624838656%2C is_fas...se%2C special=True%29%2C%0A%09103%3A AddedToken%28%22%5BMASK%5D%22%2C rstrip=False%2C lstrip=False%2C single_word=False%2C normalized=False%2C special=True%29%2C%0A%7D" isContainer="True" shape="28996" />
<var name="train_count" type="int" qualifier="builtins" value="9758" />
<var name="trainer" type="Trainer" qualifier="transformers.trainer" value="%3Ctransformers.trainer.Trainer object at 0x0000027DAAA33190&gt;" isContainer="True" />
<var name="training_args" type="TrainingArguments" qualifier="transformers.training_args" value="TrainingArguments%28%0A_n_gpu=1%2C%0Aadafactor=False%2C%0Aadam_beta1=0.9%2C%0Aadam_beta2=0.999%2C%0Aadam_epsilon=1e-08%2C%0Aauto_find_batch_size=False...use_ipex=False%2C%0Ause_legacy_prediction_loop=False%2C%0Ause_mps_device=False%2C%0Awarmup_ratio=0.0%2C%0Awarmup_steps=100%2C%0Aweight_decay=0.0%2C%0A%29" isContainer="True" />
</xml>
[{'label': 'POSITIVE', 'score': 0.9628696441650391}]
depressive score: 0.00029226564 neutral score: 0.99970776
<xml><var name="_dummy_ipython_val"  />
<var name="_dummy_special_var"  />
<var name="acc_metric" type="Accuracy" qualifier="evaluate_modules.metrics.accuracy.f887c0aab52c2d38e1f8a215681126379eca617f96c447638f751434e8e65b14.accuracy" value="EvaluationModule%28name%3A %22accuracy%22%2C module_type%3A %22metric%22%2C features%3A %7B%27predictions%27%3A Value%28dtype=%27int32%27%2C id=None%29%2C %27references...weight=%5B0.5%2C 2%2C 0.7%2C 0.5%2C 9%2C 0.4%5D%29%0A        &gt;&gt;&gt; print%28results%29%0A        %7B%27accuracy%27%3A 0.8778625954198473%7D%0A%22%22%22%2C stored examples%3A 0%29" isContainer="True" shape="0" />
<var name="base_model" type="BertForSequenceClassification" qualifier="transformers.models.bert.modeling_bert" value="BertForSequenceClassification%28%0A  %28bert%29%3A BertModel%28%0A    %28embeddings%29%3A BertEmbeddings%28%0A      %28word_embeddings%29%3A Embedding%2828996...anh%28%29%0A    %29%0A  %29%0A  %28dropout%29%3A Dropout%28p=0.1%2C inplace=False%29%0A  %28classifier%29%3A Linear%28in_features=768%2C out_features=2%2C bias=True%29%0A%29" isContainer="True" />
<var name="classifier" type="TextClassificationPipeline" qualifier="transformers.pipelines.text_classification" value="%3Ctransformers.pipelines.text_classification.TextClassificationPipeline object at 0x0000027DD519AA90&gt;" isContainer="True" />
<var name="dataset" type="DatasetDict" qualifier="datasets.dataset_dict" value="DatasetDict%28%7B%0A    train%3A Dataset%28%7B%0A        features%3A %5B%27id%27%2C %27text%27%2C %27label%27%2C %27source_data%27%5D%2C%0A        num_rows%3A 10843%0A    %7D%29%0A%7D%29" isContainer="True" shape="('train',)" />
<var name="dataset_eval" type="Dataset" qualifier="datasets.arrow_dataset" value="Dataset%28%7B%0A    features%3A %5B%27id%27%2C %27text%27%2C %27label%27%2C %27source_data%27%2C %27input_ids%27%2C %27token_type_ids%27%2C %27attention_mask%27%5D%2C%0A    num_rows%3A 1085%0A%7D%29" isContainer="True" shape="(1085, 7)" />
<var name="dataset_tokens" type="DatasetDict" qualifier="datasets.dataset_dict" value="DatasetDict%28%7B%0A    train%3A Dataset%28%7B%0A        features%3A %5B%27id%27%2C %27text%27%2C %27label%27%2C %27source_data%27%2C %27input_ids%27%2C %27token_type_ids%27%2C %27attention_mask%27%5D%2C%0A        num_rows%3A 10843%0A    %7D%29%0A%7D%29" isContainer="True" shape="('train',)" />
<var name="dataset_train" type="Dataset" qualifier="datasets.arrow_dataset" value="Dataset%28%7B%0A    features%3A %5B%27id%27%2C %27text%27%2C %27label%27%2C %27source_data%27%2C %27input_ids%27%2C %27token_type_ids%27%2C %27attention_mask%27%5D%2C%0A    num_rows%3A 9758%0A%7D%29" isContainer="True" shape="(9758, 7)" />
<var name="ft_model" type="BertForSequenceClassification" qualifier="transformers.models.bert.modeling_bert" value="BertForSequenceClassification%28%0A  %28bert%29%3A BertModel%28%0A    %28embeddings%29%3A BertEmbeddings%28%0A      %28word_embeddings%29%3A Embedding%2828996...anh%28%29%0A    %29%0A  %29%0A  %28dropout%29%3A Dropout%28p=0.1%2C inplace=False%29%0A  %28classifier%29%3A Linear%28in_features=768%2C out_features=2%2C bias=True%29%0A%29" isContainer="True" />
<var name="ft_model_checkpoint" type="str" qualifier="builtins" value="test_trainer/checkpoint-7317" />
<var name="label_count" type="int" qualifier="builtins" value="2" />
<var name="model_name" type="str" qualifier="builtins" value="./bert-base-cased" />
<var name="result" type="list" qualifier="builtins" value="%5B%7B%27label%27%3A %27POSITIVE%27%2C %27score%27%3A 0.9628696441650391%7D%5D" isContainer="True" shape="1" />
<var name="sample_out" type="SequenceClassifierOutput" qualifier="transformers.modeling_outputs" value="SequenceClassifierOutput%28loss=None%2C logits=tensor%28%5B%5B 4.0796%2C -4.0580%5D%5D%2C grad_fn=%3CAddmmBackward0&gt;%29%2C hidden_states=None%2C attentions=None%29" isContainer="True" shape="1" />
<var name="sample_text" type="str" qualifier="builtins" value="Anyone looking for organic products that can help with%3B boosting energy%2C depression%2C pain%2C inflammation%2C diabetes%2C sleep%2C and more. DM me %F0%9F%A4%99" />
<var name="sample_tokens" type="BatchEncoding" qualifier="transformers.tokenization_utils_base" value="%7B%27input_ids%27%3A tensor%28%5B%5B  101%2C 15859%2C  1702%2C  1111%2C  7878%2C  2982%2C  1115%2C  1169%2C  1494%2C  1114%2C%0A           132%2C 14112%2C  1158%2C  23...%2C 0%2C 0%2C 0%2C%0A         0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C%0A         0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%5D%5D%29%7D" isContainer="True" shape="3" />
<var name="scores" type="ndarray" qualifier="numpy" value="%5B9.9970776e-01 2.9226564e-04%5D" isContainer="True" shape="(2,)" />
<var name="shuffle" type="Dataset" qualifier="datasets.arrow_dataset" value="Dataset%28%7B%0A    features%3A %5B%27id%27%2C %27text%27%2C %27label%27%2C %27source_data%27%2C %27input_ids%27%2C %27token_type_ids%27%2C %27attention_mask%27%5D%2C%0A    num_rows%3A 10843%0A%7D%29" isContainer="True" shape="(10843, 7)" />
<var name="tokenizer" type="BertTokenizerFast" qualifier="transformers.models.bert.tokenization_bert_fast" value="BertTokenizerFast%28name_or_path=%27./bert-base-cased%27%2C vocab_size=28996%2C model_max_length=1000000000000000019884624838656%2C is_fas...se%2C special=True%29%2C%0A%09103%3A AddedToken%28%22%5BMASK%5D%22%2C rstrip=False%2C lstrip=False%2C single_word=False%2C normalized=False%2C special=True%29%2C%0A%7D" isContainer="True" shape="28996" />
<var name="train_count" type="int" qualifier="builtins" value="9758" />
<var name="trainer" type="Trainer" qualifier="transformers.trainer" value="%3Ctransformers.trainer.Trainer object at 0x0000027DAAA33190&gt;" isContainer="True" />
<var name="training_args" type="TrainingArguments" qualifier="transformers.training_args" value="TrainingArguments%28%0A_n_gpu=1%2C%0Aadafactor=False%2C%0Aadam_beta1=0.9%2C%0Aadam_beta2=0.999%2C%0Aadam_epsilon=1e-08%2C%0Aauto_find_batch_size=False...use_ipex=False%2C%0Ause_legacy_prediction_loop=False%2C%0Ause_mps_device=False%2C%0Awarmup_ratio=0.0%2C%0Awarmup_steps=100%2C%0Aweight_decay=0.0%2C%0A%29" isContainer="True" />
</xml>
[{'label': 'POSITIVE', 'score': 0.9739630222320557}]
depressive score: 0.05803999 neutral score: 0.94196004
<xml><var name="_dummy_ipython_val"  />
<var name="_dummy_special_var"  />
<var name="acc_metric" type="Accuracy" qualifier="evaluate_modules.metrics.accuracy.f887c0aab52c2d38e1f8a215681126379eca617f96c447638f751434e8e65b14.accuracy" value="EvaluationModule%28name%3A %22accuracy%22%2C module_type%3A %22metric%22%2C features%3A %7B%27predictions%27%3A Value%28dtype=%27int32%27%2C id=None%29%2C %27references...weight=%5B0.5%2C 2%2C 0.7%2C 0.5%2C 9%2C 0.4%5D%29%0A        &gt;&gt;&gt; print%28results%29%0A        %7B%27accuracy%27%3A 0.8778625954198473%7D%0A%22%22%22%2C stored examples%3A 0%29" isContainer="True" shape="0" />
<var name="base_model" type="BertForSequenceClassification" qualifier="transformers.models.bert.modeling_bert" value="BertForSequenceClassification%28%0A  %28bert%29%3A BertModel%28%0A    %28embeddings%29%3A BertEmbeddings%28%0A      %28word_embeddings%29%3A Embedding%2828996...anh%28%29%0A    %29%0A  %29%0A  %28dropout%29%3A Dropout%28p=0.1%2C inplace=False%29%0A  %28classifier%29%3A Linear%28in_features=768%2C out_features=2%2C bias=True%29%0A%29" isContainer="True" />
<var name="classifier" type="TextClassificationPipeline" qualifier="transformers.pipelines.text_classification" value="%3Ctransformers.pipelines.text_classification.TextClassificationPipeline object at 0x0000027E5A54B150&gt;" isContainer="True" />
<var name="dataset" type="DatasetDict" qualifier="datasets.dataset_dict" value="DatasetDict%28%7B%0A    train%3A Dataset%28%7B%0A        features%3A %5B%27id%27%2C %27text%27%2C %27label%27%2C %27source_data%27%5D%2C%0A        num_rows%3A 10843%0A    %7D%29%0A%7D%29" isContainer="True" shape="('train',)" />
<var name="dataset_eval" type="Dataset" qualifier="datasets.arrow_dataset" value="Dataset%28%7B%0A    features%3A %5B%27id%27%2C %27text%27%2C %27label%27%2C %27source_data%27%2C %27input_ids%27%2C %27token_type_ids%27%2C %27attention_mask%27%5D%2C%0A    num_rows%3A 1085%0A%7D%29" isContainer="True" shape="(1085, 7)" />
<var name="dataset_tokens" type="DatasetDict" qualifier="datasets.dataset_dict" value="DatasetDict%28%7B%0A    train%3A Dataset%28%7B%0A        features%3A %5B%27id%27%2C %27text%27%2C %27label%27%2C %27source_data%27%2C %27input_ids%27%2C %27token_type_ids%27%2C %27attention_mask%27%5D%2C%0A        num_rows%3A 10843%0A    %7D%29%0A%7D%29" isContainer="True" shape="('train',)" />
<var name="dataset_train" type="Dataset" qualifier="datasets.arrow_dataset" value="Dataset%28%7B%0A    features%3A %5B%27id%27%2C %27text%27%2C %27label%27%2C %27source_data%27%2C %27input_ids%27%2C %27token_type_ids%27%2C %27attention_mask%27%5D%2C%0A    num_rows%3A 9758%0A%7D%29" isContainer="True" shape="(9758, 7)" />
<var name="ft_model" type="BertForSequenceClassification" qualifier="transformers.models.bert.modeling_bert" value="BertForSequenceClassification%28%0A  %28bert%29%3A BertModel%28%0A    %28embeddings%29%3A BertEmbeddings%28%0A      %28word_embeddings%29%3A Embedding%2828996...anh%28%29%0A    %29%0A  %29%0A  %28dropout%29%3A Dropout%28p=0.1%2C inplace=False%29%0A  %28classifier%29%3A Linear%28in_features=768%2C out_features=2%2C bias=True%29%0A%29" isContainer="True" />
<var name="ft_model_checkpoint" type="str" qualifier="builtins" value="test_trainer/checkpoint-7317" />
<var name="label_count" type="int" qualifier="builtins" value="2" />
<var name="model_name" type="str" qualifier="builtins" value="./bert-base-cased" />
<var name="result" type="list" qualifier="builtins" value="%5B%7B%27label%27%3A %27POSITIVE%27%2C %27score%27%3A 0.9739630222320557%7D%5D" isContainer="True" shape="1" />
<var name="sample_out" type="SequenceClassifierOutput" qualifier="transformers.modeling_outputs" value="SequenceClassifierOutput%28loss=None%2C logits=tensor%28%5B%5B 1.2591%2C -1.5277%5D%5D%2C grad_fn=%3CAddmmBackward0&gt;%29%2C hidden_states=None%2C attentions=None%29" isContainer="True" shape="1" />
<var name="sample_text" type="str" qualifier="builtins" value="UR PRECIOUS AND ADORABLE HBAHDDHADDBAJ https%3A//t.co/MR6GwE7Aex" />
<var name="sample_tokens" type="BatchEncoding" qualifier="transformers.tokenization_utils_base" value="%7B%27input_ids%27%3A tensor%28%5B%5B  101%2C   158%2C  2069%2C 11629%2C  8231%2C 19368%2C 13329%2C 16716%2C  5844%2C  9565%2C%0A         19985%2C 17516%2C   145%2C  82...%2C 0%2C 0%2C 0%2C%0A         0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C%0A         0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%5D%5D%29%7D" isContainer="True" shape="3" />
<var name="scores" type="ndarray" qualifier="numpy" value="%5B0.94196004 0.05803999%5D" isContainer="True" shape="(2,)" />
<var name="shuffle" type="Dataset" qualifier="datasets.arrow_dataset" value="Dataset%28%7B%0A    features%3A %5B%27id%27%2C %27text%27%2C %27label%27%2C %27source_data%27%2C %27input_ids%27%2C %27token_type_ids%27%2C %27attention_mask%27%5D%2C%0A    num_rows%3A 10843%0A%7D%29" isContainer="True" shape="(10843, 7)" />
<var name="tokenizer" type="BertTokenizerFast" qualifier="transformers.models.bert.tokenization_bert_fast" value="BertTokenizerFast%28name_or_path=%27./bert-base-cased%27%2C vocab_size=28996%2C model_max_length=1000000000000000019884624838656%2C is_fas...se%2C special=True%29%2C%0A%09103%3A AddedToken%28%22%5BMASK%5D%22%2C rstrip=False%2C lstrip=False%2C single_word=False%2C normalized=False%2C special=True%29%2C%0A%7D" isContainer="True" shape="28996" />
<var name="train_count" type="int" qualifier="builtins" value="9758" />
<var name="trainer" type="Trainer" qualifier="transformers.trainer" value="%3Ctransformers.trainer.Trainer object at 0x0000027DAAA33190&gt;" isContainer="True" />
<var name="training_args" type="TrainingArguments" qualifier="transformers.training_args" value="TrainingArguments%28%0A_n_gpu=1%2C%0Aadafactor=False%2C%0Aadam_beta1=0.9%2C%0Aadam_beta2=0.999%2C%0Aadam_epsilon=1e-08%2C%0Aauto_find_batch_size=False...use_ipex=False%2C%0Ause_legacy_prediction_loop=False%2C%0Ause_mps_device=False%2C%0Awarmup_ratio=0.0%2C%0Awarmup_steps=100%2C%0Aweight_decay=0.0%2C%0A%29" isContainer="True" />
</xml>
[{'label': 'POSITIVE', 'score': 0.9495112299919128}]
depressive score: 0.9987092 neutral score: 0.0012907829
<xml><var name="_dummy_ipython_val"  />
<var name="_dummy_special_var"  />
<var name="acc_metric" type="Accuracy" qualifier="evaluate_modules.metrics.accuracy.f887c0aab52c2d38e1f8a215681126379eca617f96c447638f751434e8e65b14.accuracy" value="EvaluationModule%28name%3A %22accuracy%22%2C module_type%3A %22metric%22%2C features%3A %7B%27predictions%27%3A Value%28dtype=%27int32%27%2C id=None%29%2C %27references...weight=%5B0.5%2C 2%2C 0.7%2C 0.5%2C 9%2C 0.4%5D%29%0A        &gt;&gt;&gt; print%28results%29%0A        %7B%27accuracy%27%3A 0.8778625954198473%7D%0A%22%22%22%2C stored examples%3A 0%29" isContainer="True" shape="0" />
<var name="base_model" type="BertForSequenceClassification" qualifier="transformers.models.bert.modeling_bert" value="BertForSequenceClassification%28%0A  %28bert%29%3A BertModel%28%0A    %28embeddings%29%3A BertEmbeddings%28%0A      %28word_embeddings%29%3A Embedding%2828996...anh%28%29%0A    %29%0A  %29%0A  %28dropout%29%3A Dropout%28p=0.1%2C inplace=False%29%0A  %28classifier%29%3A Linear%28in_features=768%2C out_features=2%2C bias=True%29%0A%29" isContainer="True" />
<var name="classifier" type="TextClassificationPipeline" qualifier="transformers.pipelines.text_classification" value="%3Ctransformers.pipelines.text_classification.TextClassificationPipeline object at 0x0000027E453A7A10&gt;" isContainer="True" />
<var name="dataset" type="DatasetDict" qualifier="datasets.dataset_dict" value="DatasetDict%28%7B%0A    train%3A Dataset%28%7B%0A        features%3A %5B%27id%27%2C %27text%27%2C %27label%27%2C %27source_data%27%5D%2C%0A        num_rows%3A 10843%0A    %7D%29%0A%7D%29" isContainer="True" shape="('train',)" />
<var name="dataset_eval" type="Dataset" qualifier="datasets.arrow_dataset" value="Dataset%28%7B%0A    features%3A %5B%27id%27%2C %27text%27%2C %27label%27%2C %27source_data%27%2C %27input_ids%27%2C %27token_type_ids%27%2C %27attention_mask%27%5D%2C%0A    num_rows%3A 1085%0A%7D%29" isContainer="True" shape="(1085, 7)" />
<var name="dataset_tokens" type="DatasetDict" qualifier="datasets.dataset_dict" value="DatasetDict%28%7B%0A    train%3A Dataset%28%7B%0A        features%3A %5B%27id%27%2C %27text%27%2C %27label%27%2C %27source_data%27%2C %27input_ids%27%2C %27token_type_ids%27%2C %27attention_mask%27%5D%2C%0A        num_rows%3A 10843%0A    %7D%29%0A%7D%29" isContainer="True" shape="('train',)" />
<var name="dataset_train" type="Dataset" qualifier="datasets.arrow_dataset" value="Dataset%28%7B%0A    features%3A %5B%27id%27%2C %27text%27%2C %27label%27%2C %27source_data%27%2C %27input_ids%27%2C %27token_type_ids%27%2C %27attention_mask%27%5D%2C%0A    num_rows%3A 9758%0A%7D%29" isContainer="True" shape="(9758, 7)" />
<var name="ft_model" type="BertForSequenceClassification" qualifier="transformers.models.bert.modeling_bert" value="BertForSequenceClassification%28%0A  %28bert%29%3A BertModel%28%0A    %28embeddings%29%3A BertEmbeddings%28%0A      %28word_embeddings%29%3A Embedding%2828996...anh%28%29%0A    %29%0A  %29%0A  %28dropout%29%3A Dropout%28p=0.1%2C inplace=False%29%0A  %28classifier%29%3A Linear%28in_features=768%2C out_features=2%2C bias=True%29%0A%29" isContainer="True" />
<var name="ft_model_checkpoint" type="str" qualifier="builtins" value="test_trainer/checkpoint-7317" />
<var name="label_count" type="int" qualifier="builtins" value="2" />
<var name="model_name" type="str" qualifier="builtins" value="./bert-base-cased" />
<var name="result" type="list" qualifier="builtins" value="%5B%7B%27label%27%3A %27POSITIVE%27%2C %27score%27%3A 0.9495112299919128%7D%5D" isContainer="True" shape="1" />
<var name="sample_out" type="SequenceClassifierOutput" qualifier="transformers.modeling_outputs" value="SequenceClassifierOutput%28loss=None%2C logits=tensor%28%5B%5B-3.5516%2C  3.0996%5D%5D%2C grad_fn=%3CAddmmBackward0&gt;%29%2C hidden_states=None%2C attentions=None%29" isContainer="True" shape="1" />
<var name="sample_text" type="str" qualifier="builtins" value="RT %40RevoltTV%3A Prayers up %F0%9F%99%8F %40AugustAlsina got real about his battle with depression %26amp%3B liver disease %23PositiveVibesONLY %23watchREVOLT https%3A//%E2%80%A6" />
<var name="sample_tokens" type="BatchEncoding" qualifier="transformers.tokenization_utils_base" value="%7B%27input_ids%27%3A tensor%28%5B%5B  101%2C   155%2C  1942%2C   137%2C  6750%2C 17772%2C  7073%2C   131%2C 16203%2C  1116%2C%0A          1146%2C   100%2C   137%2C  13...%2C 0%2C 0%2C 0%2C%0A         0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C%0A         0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%5D%5D%29%7D" isContainer="True" shape="3" />
<var name="scores" type="ndarray" qualifier="numpy" value="%5B0.00129078 0.9987092 %5D" isContainer="True" shape="(2,)" />
<var name="shuffle" type="Dataset" qualifier="datasets.arrow_dataset" value="Dataset%28%7B%0A    features%3A %5B%27id%27%2C %27text%27%2C %27label%27%2C %27source_data%27%2C %27input_ids%27%2C %27token_type_ids%27%2C %27attention_mask%27%5D%2C%0A    num_rows%3A 10843%0A%7D%29" isContainer="True" shape="(10843, 7)" />
<var name="tokenizer" type="BertTokenizerFast" qualifier="transformers.models.bert.tokenization_bert_fast" value="BertTokenizerFast%28name_or_path=%27./bert-base-cased%27%2C vocab_size=28996%2C model_max_length=1000000000000000019884624838656%2C is_fas...se%2C special=True%29%2C%0A%09103%3A AddedToken%28%22%5BMASK%5D%22%2C rstrip=False%2C lstrip=False%2C single_word=False%2C normalized=False%2C special=True%29%2C%0A%7D" isContainer="True" shape="28996" />
<var name="train_count" type="int" qualifier="builtins" value="9758" />
<var name="trainer" type="Trainer" qualifier="transformers.trainer" value="%3Ctransformers.trainer.Trainer object at 0x0000027DAAA33190&gt;" isContainer="True" />
<var name="training_args" type="TrainingArguments" qualifier="transformers.training_args" value="TrainingArguments%28%0A_n_gpu=1%2C%0Aadafactor=False%2C%0Aadam_beta1=0.9%2C%0Aadam_beta2=0.999%2C%0Aadam_epsilon=1e-08%2C%0Aauto_find_batch_size=False...use_ipex=False%2C%0Ause_legacy_prediction_loop=False%2C%0Ause_mps_device=False%2C%0Awarmup_ratio=0.0%2C%0Awarmup_steps=100%2C%0Aweight_decay=0.0%2C%0A%29" isContainer="True" />
</xml>
[{'label': 'POSITIVE', 'score': 0.748120903968811}]
depressive score: 0.041032515 neutral score: 0.95896745
<xml><var name="_dummy_ipython_val"  />
<var name="_dummy_special_var"  />
<var name="acc_metric" type="Accuracy" qualifier="evaluate_modules.metrics.accuracy.f887c0aab52c2d38e1f8a215681126379eca617f96c447638f751434e8e65b14.accuracy" value="EvaluationModule%28name%3A %22accuracy%22%2C module_type%3A %22metric%22%2C features%3A %7B%27predictions%27%3A Value%28dtype=%27int32%27%2C id=None%29%2C %27references...weight=%5B0.5%2C 2%2C 0.7%2C 0.5%2C 9%2C 0.4%5D%29%0A        &gt;&gt;&gt; print%28results%29%0A        %7B%27accuracy%27%3A 0.8778625954198473%7D%0A%22%22%22%2C stored examples%3A 0%29" isContainer="True" shape="0" />
<var name="base_model" type="BertForSequenceClassification" qualifier="transformers.models.bert.modeling_bert" value="BertForSequenceClassification%28%0A  %28bert%29%3A BertModel%28%0A    %28embeddings%29%3A BertEmbeddings%28%0A      %28word_embeddings%29%3A Embedding%2828996...anh%28%29%0A    %29%0A  %29%0A  %28dropout%29%3A Dropout%28p=0.1%2C inplace=False%29%0A  %28classifier%29%3A Linear%28in_features=768%2C out_features=2%2C bias=True%29%0A%29" isContainer="True" />
<var name="classifier" type="TextClassificationPipeline" qualifier="transformers.pipelines.text_classification" value="%3Ctransformers.pipelines.text_classification.TextClassificationPipeline object at 0x0000027F0E90D2D0&gt;" isContainer="True" />
<var name="dataset" type="DatasetDict" qualifier="datasets.dataset_dict" value="DatasetDict%28%7B%0A    train%3A Dataset%28%7B%0A        features%3A %5B%27id%27%2C %27text%27%2C %27label%27%2C %27source_data%27%5D%2C%0A        num_rows%3A 10843%0A    %7D%29%0A%7D%29" isContainer="True" shape="('train',)" />
<var name="dataset_eval" type="Dataset" qualifier="datasets.arrow_dataset" value="Dataset%28%7B%0A    features%3A %5B%27id%27%2C %27text%27%2C %27label%27%2C %27source_data%27%2C %27input_ids%27%2C %27token_type_ids%27%2C %27attention_mask%27%5D%2C%0A    num_rows%3A 1085%0A%7D%29" isContainer="True" shape="(1085, 7)" />
<var name="dataset_tokens" type="DatasetDict" qualifier="datasets.dataset_dict" value="DatasetDict%28%7B%0A    train%3A Dataset%28%7B%0A        features%3A %5B%27id%27%2C %27text%27%2C %27label%27%2C %27source_data%27%2C %27input_ids%27%2C %27token_type_ids%27%2C %27attention_mask%27%5D%2C%0A        num_rows%3A 10843%0A    %7D%29%0A%7D%29" isContainer="True" shape="('train',)" />
<var name="dataset_train" type="Dataset" qualifier="datasets.arrow_dataset" value="Dataset%28%7B%0A    features%3A %5B%27id%27%2C %27text%27%2C %27label%27%2C %27source_data%27%2C %27input_ids%27%2C %27token_type_ids%27%2C %27attention_mask%27%5D%2C%0A    num_rows%3A 9758%0A%7D%29" isContainer="True" shape="(9758, 7)" />
<var name="ft_model" type="BertForSequenceClassification" qualifier="transformers.models.bert.modeling_bert" value="BertForSequenceClassification%28%0A  %28bert%29%3A BertModel%28%0A    %28embeddings%29%3A BertEmbeddings%28%0A      %28word_embeddings%29%3A Embedding%2828996...anh%28%29%0A    %29%0A  %29%0A  %28dropout%29%3A Dropout%28p=0.1%2C inplace=False%29%0A  %28classifier%29%3A Linear%28in_features=768%2C out_features=2%2C bias=True%29%0A%29" isContainer="True" />
<var name="ft_model_checkpoint" type="str" qualifier="builtins" value="test_trainer/checkpoint-7317" />
<var name="label_count" type="int" qualifier="builtins" value="2" />
<var name="model_name" type="str" qualifier="builtins" value="./bert-base-cased" />
<var name="result" type="list" qualifier="builtins" value="%5B%7B%27label%27%3A %27POSITIVE%27%2C %27score%27%3A 0.748120903968811%7D%5D" isContainer="True" shape="1" />
<var name="sample_out" type="SequenceClassifierOutput" qualifier="transformers.modeling_outputs" value="SequenceClassifierOutput%28loss=None%2C logits=tensor%28%5B%5B 1.0615%2C -2.0900%5D%5D%2C grad_fn=%3CAddmmBackward0&gt;%29%2C hidden_states=None%2C attentions=None%29" isContainer="True" shape="1" />
<var name="sample_text" type="str" qualifier="builtins" value="" />
<var name="sample_tokens" type="BatchEncoding" qualifier="transformers.tokenization_utils_base" value="%7B%27input_ids%27%3A tensor%28%5B%5B101%2C 102%2C   0%2C   0%2C   0%2C   0%2C   0%2C   0%2C   0%2C   0%2C   0%2C   0%2C   0%2C   0%2C%0A           0%2C   0%2C   0%2C   0%2C   0%2C...%2C 0%2C 0%2C 0%2C%0A         0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C%0A         0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%5D%5D%29%7D" isContainer="True" shape="3" />
<var name="scores" type="ndarray" qualifier="numpy" value="%5B0.95896745 0.04103252%5D" isContainer="True" shape="(2,)" />
<var name="shuffle" type="Dataset" qualifier="datasets.arrow_dataset" value="Dataset%28%7B%0A    features%3A %5B%27id%27%2C %27text%27%2C %27label%27%2C %27source_data%27%2C %27input_ids%27%2C %27token_type_ids%27%2C %27attention_mask%27%5D%2C%0A    num_rows%3A 10843%0A%7D%29" isContainer="True" shape="(10843, 7)" />
<var name="tokenizer" type="BertTokenizerFast" qualifier="transformers.models.bert.tokenization_bert_fast" value="BertTokenizerFast%28name_or_path=%27./bert-base-cased%27%2C vocab_size=28996%2C model_max_length=1000000000000000019884624838656%2C is_fas...se%2C special=True%29%2C%0A%09103%3A AddedToken%28%22%5BMASK%5D%22%2C rstrip=False%2C lstrip=False%2C single_word=False%2C normalized=False%2C special=True%29%2C%0A%7D" isContainer="True" shape="28996" />
<var name="train_count" type="int" qualifier="builtins" value="9758" />
<var name="trainer" type="Trainer" qualifier="transformers.trainer" value="%3Ctransformers.trainer.Trainer object at 0x0000027DAAA33190&gt;" isContainer="True" />
<var name="training_args" type="TrainingArguments" qualifier="transformers.training_args" value="TrainingArguments%28%0A_n_gpu=1%2C%0Aadafactor=False%2C%0Aadam_beta1=0.9%2C%0Aadam_beta2=0.999%2C%0Aadam_epsilon=1e-08%2C%0Aauto_find_batch_size=False...use_ipex=False%2C%0Ause_legacy_prediction_loop=False%2C%0Ause_mps_device=False%2C%0Awarmup_ratio=0.0%2C%0Awarmup_steps=100%2C%0Aweight_decay=0.0%2C%0A%29" isContainer="True" />
</xml>
[{'label': 'NEGATIVE', 'score': 0.9960359930992126}]
depressive score: 0.987523 neutral score: 0.012476991
<xml><var name="_dummy_ipython_val"  />
<var name="_dummy_special_var"  />
<var name="acc_metric" type="Accuracy" qualifier="evaluate_modules.metrics.accuracy.f887c0aab52c2d38e1f8a215681126379eca617f96c447638f751434e8e65b14.accuracy" value="EvaluationModule%28name%3A %22accuracy%22%2C module_type%3A %22metric%22%2C features%3A %7B%27predictions%27%3A Value%28dtype=%27int32%27%2C id=None%29%2C %27references...weight=%5B0.5%2C 2%2C 0.7%2C 0.5%2C 9%2C 0.4%5D%29%0A        &gt;&gt;&gt; print%28results%29%0A        %7B%27accuracy%27%3A 0.8778625954198473%7D%0A%22%22%22%2C stored examples%3A 0%29" isContainer="True" shape="0" />
<var name="base_model" type="BertForSequenceClassification" qualifier="transformers.models.bert.modeling_bert" value="BertForSequenceClassification%28%0A  %28bert%29%3A BertModel%28%0A    %28embeddings%29%3A BertEmbeddings%28%0A      %28word_embeddings%29%3A Embedding%2828996...anh%28%29%0A    %29%0A  %29%0A  %28dropout%29%3A Dropout%28p=0.1%2C inplace=False%29%0A  %28classifier%29%3A Linear%28in_features=768%2C out_features=2%2C bias=True%29%0A%29" isContainer="True" />
<var name="classifier" type="TextClassificationPipeline" qualifier="transformers.pipelines.text_classification" value="%3Ctransformers.pipelines.text_classification.TextClassificationPipeline object at 0x0000027DD5E492D0&gt;" isContainer="True" />
<var name="dataset" type="DatasetDict" qualifier="datasets.dataset_dict" value="DatasetDict%28%7B%0A    train%3A Dataset%28%7B%0A        features%3A %5B%27id%27%2C %27text%27%2C %27label%27%2C %27source_data%27%5D%2C%0A        num_rows%3A 10843%0A    %7D%29%0A%7D%29" isContainer="True" shape="('train',)" />
<var name="dataset_eval" type="Dataset" qualifier="datasets.arrow_dataset" value="Dataset%28%7B%0A    features%3A %5B%27id%27%2C %27text%27%2C %27label%27%2C %27source_data%27%2C %27input_ids%27%2C %27token_type_ids%27%2C %27attention_mask%27%5D%2C%0A    num_rows%3A 1085%0A%7D%29" isContainer="True" shape="(1085, 7)" />
<var name="dataset_tokens" type="DatasetDict" qualifier="datasets.dataset_dict" value="DatasetDict%28%7B%0A    train%3A Dataset%28%7B%0A        features%3A %5B%27id%27%2C %27text%27%2C %27label%27%2C %27source_data%27%2C %27input_ids%27%2C %27token_type_ids%27%2C %27attention_mask%27%5D%2C%0A        num_rows%3A 10843%0A    %7D%29%0A%7D%29" isContainer="True" shape="('train',)" />
<var name="dataset_train" type="Dataset" qualifier="datasets.arrow_dataset" value="Dataset%28%7B%0A    features%3A %5B%27id%27%2C %27text%27%2C %27label%27%2C %27source_data%27%2C %27input_ids%27%2C %27token_type_ids%27%2C %27attention_mask%27%5D%2C%0A    num_rows%3A 9758%0A%7D%29" isContainer="True" shape="(9758, 7)" />
<var name="ft_model" type="BertForSequenceClassification" qualifier="transformers.models.bert.modeling_bert" value="BertForSequenceClassification%28%0A  %28bert%29%3A BertModel%28%0A    %28embeddings%29%3A BertEmbeddings%28%0A      %28word_embeddings%29%3A Embedding%2828996...anh%28%29%0A    %29%0A  %29%0A  %28dropout%29%3A Dropout%28p=0.1%2C inplace=False%29%0A  %28classifier%29%3A Linear%28in_features=768%2C out_features=2%2C bias=True%29%0A%29" isContainer="True" />
<var name="ft_model_checkpoint" type="str" qualifier="builtins" value="test_trainer/checkpoint-7317" />
<var name="label_count" type="int" qualifier="builtins" value="2" />
<var name="model_name" type="str" qualifier="builtins" value="./bert-base-cased" />
<var name="result" type="list" qualifier="builtins" value="%5B%7B%27label%27%3A %27NEGATIVE%27%2C %27score%27%3A 0.9960359930992126%7D%5D" isContainer="True" shape="1" />
<var name="sample_out" type="SequenceClassifierOutput" qualifier="transformers.modeling_outputs" value="SequenceClassifierOutput%28loss=None%2C logits=tensor%28%5B%5B-2.4965%2C  1.8748%5D%5D%2C grad_fn=%3CAddmmBackward0&gt;%29%2C hidden_states=None%2C attentions=None%29" isContainer="True" shape="1" />
<var name="sample_text" type="str" qualifier="builtins" value="i hate myself so much for being like that when they re just minding their business sometimes i just see people so casually happy and hugging and being close or just visibly happy in general and i just feel so bitter they don t deserve me being so shitty ov" />
<var name="sample_tokens" type="BatchEncoding" qualifier="transformers.tokenization_utils_base" value="%7B%27input_ids%27%3A tensor%28%5B%5B  101%2C   178%2C  4819%2C  1991%2C  1177%2C  1277%2C  1111%2C  1217%2C  1176%2C  1115%2C%0A          1165%2C  1152%2C  1231%2C  11...%2C 0%2C 0%2C 0%2C%0A         0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C%0A         0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%5D%5D%29%7D" isContainer="True" shape="3" />
<var name="scores" type="ndarray" qualifier="numpy" value="%5B0.01247699 0.987523  %5D" isContainer="True" shape="(2,)" />
<var name="shuffle" type="Dataset" qualifier="datasets.arrow_dataset" value="Dataset%28%7B%0A    features%3A %5B%27id%27%2C %27text%27%2C %27label%27%2C %27source_data%27%2C %27input_ids%27%2C %27token_type_ids%27%2C %27attention_mask%27%5D%2C%0A    num_rows%3A 10843%0A%7D%29" isContainer="True" shape="(10843, 7)" />
<var name="tokenizer" type="BertTokenizerFast" qualifier="transformers.models.bert.tokenization_bert_fast" value="BertTokenizerFast%28name_or_path=%27./bert-base-cased%27%2C vocab_size=28996%2C model_max_length=1000000000000000019884624838656%2C is_fas...se%2C special=True%29%2C%0A%09103%3A AddedToken%28%22%5BMASK%5D%22%2C rstrip=False%2C lstrip=False%2C single_word=False%2C normalized=False%2C special=True%29%2C%0A%7D" isContainer="True" shape="28996" />
<var name="train_count" type="int" qualifier="builtins" value="9758" />
<var name="trainer" type="Trainer" qualifier="transformers.trainer" value="%3Ctransformers.trainer.Trainer object at 0x0000027DAAA33190&gt;" isContainer="True" />
<var name="training_args" type="TrainingArguments" qualifier="transformers.training_args" value="TrainingArguments%28%0A_n_gpu=1%2C%0Aadafactor=False%2C%0Aadam_beta1=0.9%2C%0Aadam_beta2=0.999%2C%0Aadam_epsilon=1e-08%2C%0Aauto_find_batch_size=False...use_ipex=False%2C%0Ause_legacy_prediction_loop=False%2C%0Ause_mps_device=False%2C%0Awarmup_ratio=0.0%2C%0Awarmup_steps=100%2C%0Aweight_decay=0.0%2C%0A%29" isContainer="True" />
</xml>
[{'label': 'NEGATIVE', 'score': 0.9997101426124573}]
depressive score: 0.00040043588 neutral score: 0.99959964
<xml><var name="_dummy_ipython_val"  />
<var name="_dummy_special_var"  />
<var name="acc_metric" type="Accuracy" qualifier="evaluate_modules.metrics.accuracy.f887c0aab52c2d38e1f8a215681126379eca617f96c447638f751434e8e65b14.accuracy" value="EvaluationModule%28name%3A %22accuracy%22%2C module_type%3A %22metric%22%2C features%3A %7B%27predictions%27%3A Value%28dtype=%27int32%27%2C id=None%29%2C %27references...weight=%5B0.5%2C 2%2C 0.7%2C 0.5%2C 9%2C 0.4%5D%29%0A        &gt;&gt;&gt; print%28results%29%0A        %7B%27accuracy%27%3A 0.8778625954198473%7D%0A%22%22%22%2C stored examples%3A 0%29" isContainer="True" shape="0" />
<var name="base_model" type="BertForSequenceClassification" qualifier="transformers.models.bert.modeling_bert" value="BertForSequenceClassification%28%0A  %28bert%29%3A BertModel%28%0A    %28embeddings%29%3A BertEmbeddings%28%0A      %28word_embeddings%29%3A Embedding%2828996...anh%28%29%0A    %29%0A  %29%0A  %28dropout%29%3A Dropout%28p=0.1%2C inplace=False%29%0A  %28classifier%29%3A Linear%28in_features=768%2C out_features=2%2C bias=True%29%0A%29" isContainer="True" />
<var name="classifier" type="TextClassificationPipeline" qualifier="transformers.pipelines.text_classification" value="%3Ctransformers.pipelines.text_classification.TextClassificationPipeline object at 0x0000027DF5F25C10&gt;" isContainer="True" />
<var name="dataset" type="DatasetDict" qualifier="datasets.dataset_dict" value="DatasetDict%28%7B%0A    train%3A Dataset%28%7B%0A        features%3A %5B%27id%27%2C %27text%27%2C %27label%27%2C %27source_data%27%5D%2C%0A        num_rows%3A 10843%0A    %7D%29%0A%7D%29" isContainer="True" shape="('train',)" />
<var name="dataset_eval" type="Dataset" qualifier="datasets.arrow_dataset" value="Dataset%28%7B%0A    features%3A %5B%27id%27%2C %27text%27%2C %27label%27%2C %27source_data%27%2C %27input_ids%27%2C %27token_type_ids%27%2C %27attention_mask%27%5D%2C%0A    num_rows%3A 1085%0A%7D%29" isContainer="True" shape="(1085, 7)" />
<var name="dataset_tokens" type="DatasetDict" qualifier="datasets.dataset_dict" value="DatasetDict%28%7B%0A    train%3A Dataset%28%7B%0A        features%3A %5B%27id%27%2C %27text%27%2C %27label%27%2C %27source_data%27%2C %27input_ids%27%2C %27token_type_ids%27%2C %27attention_mask%27%5D%2C%0A        num_rows%3A 10843%0A    %7D%29%0A%7D%29" isContainer="True" shape="('train',)" />
<var name="dataset_train" type="Dataset" qualifier="datasets.arrow_dataset" value="Dataset%28%7B%0A    features%3A %5B%27id%27%2C %27text%27%2C %27label%27%2C %27source_data%27%2C %27input_ids%27%2C %27token_type_ids%27%2C %27attention_mask%27%5D%2C%0A    num_rows%3A 9758%0A%7D%29" isContainer="True" shape="(9758, 7)" />
<var name="ft_model" type="BertForSequenceClassification" qualifier="transformers.models.bert.modeling_bert" value="BertForSequenceClassification%28%0A  %28bert%29%3A BertModel%28%0A    %28embeddings%29%3A BertEmbeddings%28%0A      %28word_embeddings%29%3A Embedding%2828996...anh%28%29%0A    %29%0A  %29%0A  %28dropout%29%3A Dropout%28p=0.1%2C inplace=False%29%0A  %28classifier%29%3A Linear%28in_features=768%2C out_features=2%2C bias=True%29%0A%29" isContainer="True" />
<var name="ft_model_checkpoint" type="str" qualifier="builtins" value="test_trainer/checkpoint-7317" />
<var name="label_count" type="int" qualifier="builtins" value="2" />
<var name="model_name" type="str" qualifier="builtins" value="./bert-base-cased" />
<var name="result" type="list" qualifier="builtins" value="%5B%7B%27label%27%3A %27NEGATIVE%27%2C %27score%27%3A 0.9997101426124573%7D%5D" isContainer="True" shape="1" />
<var name="sample_out" type="SequenceClassifierOutput" qualifier="transformers.modeling_outputs" value="SequenceClassifierOutput%28loss=None%2C logits=tensor%28%5B%5B 3.8474%2C -3.9752%5D%5D%2C grad_fn=%3CAddmmBackward0&gt;%29%2C hidden_states=None%2C attentions=None%29" isContainer="True" shape="1" />
<var name="sample_text" type="str" qualifier="builtins" value="i feel soooo bad for my doglet she is not understanding why her mouth is so sore poor little thing" />
<var name="sample_tokens" type="BatchEncoding" qualifier="transformers.tokenization_utils_base" value="%7B%27input_ids%27%3A tensor%28%5B%5B  101%2C   178%2C  1631%2C  1177%2C  5658%2C  1186%2C  2213%2C  1111%2C  1139%2C  3676%2C%0A          5765%2C  1131%2C  1110%2C  11...%2C 0%2C 0%2C 0%2C%0A         0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C%0A         0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%5D%5D%29%7D" isContainer="True" shape="3" />
<var name="scores" type="ndarray" qualifier="numpy" value="%5B9.9959964e-01 4.0043588e-04%5D" isContainer="True" shape="(2,)" />
<var name="shuffle" type="Dataset" qualifier="datasets.arrow_dataset" value="Dataset%28%7B%0A    features%3A %5B%27id%27%2C %27text%27%2C %27label%27%2C %27source_data%27%2C %27input_ids%27%2C %27token_type_ids%27%2C %27attention_mask%27%5D%2C%0A    num_rows%3A 10843%0A%7D%29" isContainer="True" shape="(10843, 7)" />
<var name="tokenizer" type="BertTokenizerFast" qualifier="transformers.models.bert.tokenization_bert_fast" value="BertTokenizerFast%28name_or_path=%27./bert-base-cased%27%2C vocab_size=28996%2C model_max_length=1000000000000000019884624838656%2C is_fas...se%2C special=True%29%2C%0A%09103%3A AddedToken%28%22%5BMASK%5D%22%2C rstrip=False%2C lstrip=False%2C single_word=False%2C normalized=False%2C special=True%29%2C%0A%7D" isContainer="True" shape="28996" />
<var name="train_count" type="int" qualifier="builtins" value="9758" />
<var name="trainer" type="Trainer" qualifier="transformers.trainer" value="%3Ctransformers.trainer.Trainer object at 0x0000027DAAA33190&gt;" isContainer="True" />
<var name="training_args" type="TrainingArguments" qualifier="transformers.training_args" value="TrainingArguments%28%0A_n_gpu=1%2C%0Aadafactor=False%2C%0Aadam_beta1=0.9%2C%0Aadam_beta2=0.999%2C%0Aadam_epsilon=1e-08%2C%0Aauto_find_batch_size=False...use_ipex=False%2C%0Ause_legacy_prediction_loop=False%2C%0Ause_mps_device=False%2C%0Awarmup_ratio=0.0%2C%0Awarmup_steps=100%2C%0Aweight_decay=0.0%2C%0A%29" isContainer="True" />
</xml>
depressive score: 0.0004528191 neutral score: 0.9995472
<xml><var name="_dummy_ipython_val"  />
<var name="_dummy_special_var"  />
<var name="acc_metric" type="Accuracy" qualifier="evaluate_modules.metrics.accuracy.f887c0aab52c2d38e1f8a215681126379eca617f96c447638f751434e8e65b14.accuracy" value="EvaluationModule%28name%3A %22accuracy%22%2C module_type%3A %22metric%22%2C features%3A %7B%27predictions%27%3A Value%28dtype=%27int32%27%2C id=None%29%2C %27references...weight=%5B0.5%2C 2%2C 0.7%2C 0.5%2C 9%2C 0.4%5D%29%0A        &gt;&gt;&gt; print%28results%29%0A        %7B%27accuracy%27%3A 0.8778625954198473%7D%0A%22%22%22%2C stored examples%3A 0%29" isContainer="True" shape="0" />
<var name="base_model" type="BertForSequenceClassification" qualifier="transformers.models.bert.modeling_bert" value="BertForSequenceClassification%28%0A  %28bert%29%3A BertModel%28%0A    %28embeddings%29%3A BertEmbeddings%28%0A      %28word_embeddings%29%3A Embedding%2828996...anh%28%29%0A    %29%0A  %29%0A  %28dropout%29%3A Dropout%28p=0.1%2C inplace=False%29%0A  %28classifier%29%3A Linear%28in_features=768%2C out_features=2%2C bias=True%29%0A%29" isContainer="True" />
<var name="classifier" type="TextClassificationPipeline" qualifier="transformers.pipelines.text_classification" value="%3Ctransformers.pipelines.text_classification.TextClassificationPipeline object at 0x0000027DF5F25C10&gt;" isContainer="True" />
<var name="dataset" type="DatasetDict" qualifier="datasets.dataset_dict" value="DatasetDict%28%7B%0A    train%3A Dataset%28%7B%0A        features%3A %5B%27id%27%2C %27text%27%2C %27label%27%2C %27source_data%27%5D%2C%0A        num_rows%3A 10843%0A    %7D%29%0A%7D%29" isContainer="True" shape="('train',)" />
<var name="dataset_eval" type="Dataset" qualifier="datasets.arrow_dataset" value="Dataset%28%7B%0A    features%3A %5B%27id%27%2C %27text%27%2C %27label%27%2C %27source_data%27%2C %27input_ids%27%2C %27token_type_ids%27%2C %27attention_mask%27%5D%2C%0A    num_rows%3A 1085%0A%7D%29" isContainer="True" shape="(1085, 7)" />
<var name="dataset_tokens" type="DatasetDict" qualifier="datasets.dataset_dict" value="DatasetDict%28%7B%0A    train%3A Dataset%28%7B%0A        features%3A %5B%27id%27%2C %27text%27%2C %27label%27%2C %27source_data%27%2C %27input_ids%27%2C %27token_type_ids%27%2C %27attention_mask%27%5D%2C%0A        num_rows%3A 10843%0A    %7D%29%0A%7D%29" isContainer="True" shape="('train',)" />
<var name="dataset_train" type="Dataset" qualifier="datasets.arrow_dataset" value="Dataset%28%7B%0A    features%3A %5B%27id%27%2C %27text%27%2C %27label%27%2C %27source_data%27%2C %27input_ids%27%2C %27token_type_ids%27%2C %27attention_mask%27%5D%2C%0A    num_rows%3A 9758%0A%7D%29" isContainer="True" shape="(9758, 7)" />
<var name="ft_model" type="BertForSequenceClassification" qualifier="transformers.models.bert.modeling_bert" value="BertForSequenceClassification%28%0A  %28bert%29%3A BertModel%28%0A    %28embeddings%29%3A BertEmbeddings%28%0A      %28word_embeddings%29%3A Embedding%2828996...anh%28%29%0A    %29%0A  %29%0A  %28dropout%29%3A Dropout%28p=0.1%2C inplace=False%29%0A  %28classifier%29%3A Linear%28in_features=768%2C out_features=2%2C bias=True%29%0A%29" isContainer="True" />
<var name="ft_model_checkpoint" type="str" qualifier="builtins" value="test_trainer/checkpoint-7317" />
<var name="label_count" type="int" qualifier="builtins" value="2" />
<var name="model_name" type="str" qualifier="builtins" value="./bert-base-cased" />
<var name="result" type="list" qualifier="builtins" value="%5B%7B%27label%27%3A %27NEGATIVE%27%2C %27score%27%3A 0.9997101426124573%7D%5D" isContainer="True" shape="1" />
<var name="sample_out" type="SequenceClassifierOutput" qualifier="transformers.modeling_outputs" value="SequenceClassifierOutput%28loss=None%2C logits=tensor%28%5B%5B 3.8116%2C -3.8880%5D%5D%2C grad_fn=%3CAddmmBackward0&gt;%29%2C hidden_states=None%2C attentions=None%29" isContainer="True" shape="1" />
<var name="sample_text" type="str" qualifier="builtins" value="i wish i had someone to talk to i m so upset no one like me anyway" />
<var name="sample_tokens" type="BatchEncoding" qualifier="transformers.tokenization_utils_base" value="%7B%27input_ids%27%3A tensor%28%5B%5B 101%2C  178%2C 3683%2C  178%2C 1125%2C 1800%2C 1106%2C 2037%2C 1106%2C  178%2C  182%2C 1177%2C%0A         5737%2C 1185%2C 1141%2C 1176...%2C 0%2C 0%2C 0%2C%0A         0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C%0A         0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%5D%5D%29%7D" isContainer="True" shape="3" />
<var name="scores" type="ndarray" qualifier="numpy" value="%5B9.995472e-01 4.528191e-04%5D" isContainer="True" shape="(2,)" />
<var name="shuffle" type="Dataset" qualifier="datasets.arrow_dataset" value="Dataset%28%7B%0A    features%3A %5B%27id%27%2C %27text%27%2C %27label%27%2C %27source_data%27%2C %27input_ids%27%2C %27token_type_ids%27%2C %27attention_mask%27%5D%2C%0A    num_rows%3A 10843%0A%7D%29" isContainer="True" shape="(10843, 7)" />
<var name="tokenizer" type="BertTokenizerFast" qualifier="transformers.models.bert.tokenization_bert_fast" value="BertTokenizerFast%28name_or_path=%27./bert-base-cased%27%2C vocab_size=28996%2C model_max_length=1000000000000000019884624838656%2C is_fas...se%2C special=True%29%2C%0A%09103%3A AddedToken%28%22%5BMASK%5D%22%2C rstrip=False%2C lstrip=False%2C single_word=False%2C normalized=False%2C special=True%29%2C%0A%7D" isContainer="True" shape="28996" />
<var name="train_count" type="int" qualifier="builtins" value="9758" />
<var name="trainer" type="Trainer" qualifier="transformers.trainer" value="%3Ctransformers.trainer.Trainer object at 0x0000027DAAA33190&gt;" isContainer="True" />
<var name="training_args" type="TrainingArguments" qualifier="transformers.training_args" value="TrainingArguments%28%0A_n_gpu=1%2C%0Aadafactor=False%2C%0Aadam_beta1=0.9%2C%0Aadam_beta2=0.999%2C%0Aadam_epsilon=1e-08%2C%0Aauto_find_batch_size=False...use_ipex=False%2C%0Ause_legacy_prediction_loop=False%2C%0Ause_mps_device=False%2C%0Awarmup_ratio=0.0%2C%0Awarmup_steps=100%2C%0Aweight_decay=0.0%2C%0A%29" isContainer="True" />
</xml>
depressive score: 0.9993007 neutral score: 0.00069925387
<xml><var name="_dummy_ipython_val"  />
<var name="_dummy_special_var"  />
<var name="acc_metric" type="Accuracy" qualifier="evaluate_modules.metrics.accuracy.f887c0aab52c2d38e1f8a215681126379eca617f96c447638f751434e8e65b14.accuracy" value="EvaluationModule%28name%3A %22accuracy%22%2C module_type%3A %22metric%22%2C features%3A %7B%27predictions%27%3A Value%28dtype=%27int32%27%2C id=None%29%2C %27references...weight=%5B0.5%2C 2%2C 0.7%2C 0.5%2C 9%2C 0.4%5D%29%0A        &gt;&gt;&gt; print%28results%29%0A        %7B%27accuracy%27%3A 0.8778625954198473%7D%0A%22%22%22%2C stored examples%3A 0%29" isContainer="True" shape="0" />
<var name="base_model" type="BertForSequenceClassification" qualifier="transformers.models.bert.modeling_bert" value="BertForSequenceClassification%28%0A  %28bert%29%3A BertModel%28%0A    %28embeddings%29%3A BertEmbeddings%28%0A      %28word_embeddings%29%3A Embedding%2828996...anh%28%29%0A    %29%0A  %29%0A  %28dropout%29%3A Dropout%28p=0.1%2C inplace=False%29%0A  %28classifier%29%3A Linear%28in_features=768%2C out_features=2%2C bias=True%29%0A%29" isContainer="True" />
<var name="classifier" type="TextClassificationPipeline" qualifier="transformers.pipelines.text_classification" value="%3Ctransformers.pipelines.text_classification.TextClassificationPipeline object at 0x0000027DF5F25C10&gt;" isContainer="True" />
<var name="dataset" type="DatasetDict" qualifier="datasets.dataset_dict" value="DatasetDict%28%7B%0A    train%3A Dataset%28%7B%0A        features%3A %5B%27id%27%2C %27text%27%2C %27label%27%2C %27source_data%27%5D%2C%0A        num_rows%3A 10843%0A    %7D%29%0A%7D%29" isContainer="True" shape="('train',)" />
<var name="dataset_eval" type="Dataset" qualifier="datasets.arrow_dataset" value="Dataset%28%7B%0A    features%3A %5B%27id%27%2C %27text%27%2C %27label%27%2C %27source_data%27%2C %27input_ids%27%2C %27token_type_ids%27%2C %27attention_mask%27%5D%2C%0A    num_rows%3A 1085%0A%7D%29" isContainer="True" shape="(1085, 7)" />
<var name="dataset_tokens" type="DatasetDict" qualifier="datasets.dataset_dict" value="DatasetDict%28%7B%0A    train%3A Dataset%28%7B%0A        features%3A %5B%27id%27%2C %27text%27%2C %27label%27%2C %27source_data%27%2C %27input_ids%27%2C %27token_type_ids%27%2C %27attention_mask%27%5D%2C%0A        num_rows%3A 10843%0A    %7D%29%0A%7D%29" isContainer="True" shape="('train',)" />
<var name="dataset_train" type="Dataset" qualifier="datasets.arrow_dataset" value="Dataset%28%7B%0A    features%3A %5B%27id%27%2C %27text%27%2C %27label%27%2C %27source_data%27%2C %27input_ids%27%2C %27token_type_ids%27%2C %27attention_mask%27%5D%2C%0A    num_rows%3A 9758%0A%7D%29" isContainer="True" shape="(9758, 7)" />
<var name="ft_model" type="BertForSequenceClassification" qualifier="transformers.models.bert.modeling_bert" value="BertForSequenceClassification%28%0A  %28bert%29%3A BertModel%28%0A    %28embeddings%29%3A BertEmbeddings%28%0A      %28word_embeddings%29%3A Embedding%2828996...anh%28%29%0A    %29%0A  %29%0A  %28dropout%29%3A Dropout%28p=0.1%2C inplace=False%29%0A  %28classifier%29%3A Linear%28in_features=768%2C out_features=2%2C bias=True%29%0A%29" isContainer="True" />
<var name="ft_model_checkpoint" type="str" qualifier="builtins" value="test_trainer/checkpoint-7317" />
<var name="label_count" type="int" qualifier="builtins" value="2" />
<var name="model_name" type="str" qualifier="builtins" value="./bert-base-cased" />
<var name="result" type="list" qualifier="builtins" value="%5B%7B%27label%27%3A %27NEGATIVE%27%2C %27score%27%3A 0.9997101426124573%7D%5D" isContainer="True" shape="1" />
<var name="sample_out" type="SequenceClassifierOutput" qualifier="transformers.modeling_outputs" value="SequenceClassifierOutput%28loss=None%2C logits=tensor%28%5B%5B-3.8574%2C  3.4074%5D%5D%2C grad_fn=%3CAddmmBackward0&gt;%29%2C hidden_states=None%2C attentions=None%29" isContainer="True" shape="1" />
<var name="sample_text" type="str" qualifier="builtins" value="i havent slept a wink severe insomnia arghhhh why" />
<var name="sample_tokens" type="BatchEncoding" qualifier="transformers.tokenization_utils_base" value="%7B%27input_ids%27%3A tensor%28%5B%5B  101%2C   178%2C  3983%2C  1204%2C  7362%2C   170%2C 19887%2C  5199%2C 22233%2C  4165%2C%0A          5813%2C   170%2C 10805%2C 238...%2C 0%2C 0%2C 0%2C%0A         0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C%0A         0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%5D%5D%29%7D" isContainer="True" shape="3" />
<var name="scores" type="ndarray" qualifier="numpy" value="%5B6.9925387e-04 9.9930072e-01%5D" isContainer="True" shape="(2,)" />
<var name="shuffle" type="Dataset" qualifier="datasets.arrow_dataset" value="Dataset%28%7B%0A    features%3A %5B%27id%27%2C %27text%27%2C %27label%27%2C %27source_data%27%2C %27input_ids%27%2C %27token_type_ids%27%2C %27attention_mask%27%5D%2C%0A    num_rows%3A 10843%0A%7D%29" isContainer="True" shape="(10843, 7)" />
<var name="tokenizer" type="BertTokenizerFast" qualifier="transformers.models.bert.tokenization_bert_fast" value="BertTokenizerFast%28name_or_path=%27./bert-base-cased%27%2C vocab_size=28996%2C model_max_length=1000000000000000019884624838656%2C is_fas...se%2C special=True%29%2C%0A%09103%3A AddedToken%28%22%5BMASK%5D%22%2C rstrip=False%2C lstrip=False%2C single_word=False%2C normalized=False%2C special=True%29%2C%0A%7D" isContainer="True" shape="28996" />
<var name="train_count" type="int" qualifier="builtins" value="9758" />
<var name="trainer" type="Trainer" qualifier="transformers.trainer" value="%3Ctransformers.trainer.Trainer object at 0x0000027DAAA33190&gt;" isContainer="True" />
<var name="training_args" type="TrainingArguments" qualifier="transformers.training_args" value="TrainingArguments%28%0A_n_gpu=1%2C%0Aadafactor=False%2C%0Aadam_beta1=0.9%2C%0Aadam_beta2=0.999%2C%0Aadam_epsilon=1e-08%2C%0Aauto_find_batch_size=False...use_ipex=False%2C%0Ause_legacy_prediction_loop=False%2C%0Ause_mps_device=False%2C%0Awarmup_ratio=0.0%2C%0Awarmup_steps=100%2C%0Aweight_decay=0.0%2C%0A%29" isContainer="True" />
</xml>
depressive score: 0.00011102436 neutral score: 0.999889
<xml><var name="_dummy_ipython_val"  />
<var name="_dummy_special_var"  />
<var name="acc_metric" type="Accuracy" qualifier="evaluate_modules.metrics.accuracy.f887c0aab52c2d38e1f8a215681126379eca617f96c447638f751434e8e65b14.accuracy" value="EvaluationModule%28name%3A %22accuracy%22%2C module_type%3A %22metric%22%2C features%3A %7B%27predictions%27%3A Value%28dtype=%27int32%27%2C id=None%29%2C %27references...weight=%5B0.5%2C 2%2C 0.7%2C 0.5%2C 9%2C 0.4%5D%29%0A        &gt;&gt;&gt; print%28results%29%0A        %7B%27accuracy%27%3A 0.8778625954198473%7D%0A%22%22%22%2C stored examples%3A 0%29" isContainer="True" shape="0" />
<var name="base_model" type="BertForSequenceClassification" qualifier="transformers.models.bert.modeling_bert" value="BertForSequenceClassification%28%0A  %28bert%29%3A BertModel%28%0A    %28embeddings%29%3A BertEmbeddings%28%0A      %28word_embeddings%29%3A Embedding%2828996...anh%28%29%0A    %29%0A  %29%0A  %28dropout%29%3A Dropout%28p=0.1%2C inplace=False%29%0A  %28classifier%29%3A Linear%28in_features=768%2C out_features=2%2C bias=True%29%0A%29" isContainer="True" />
<var name="classifier" type="TextClassificationPipeline" qualifier="transformers.pipelines.text_classification" value="%3Ctransformers.pipelines.text_classification.TextClassificationPipeline object at 0x0000027DF5F25C10&gt;" isContainer="True" />
<var name="dataset" type="DatasetDict" qualifier="datasets.dataset_dict" value="DatasetDict%28%7B%0A    train%3A Dataset%28%7B%0A        features%3A %5B%27id%27%2C %27text%27%2C %27label%27%2C %27source_data%27%5D%2C%0A        num_rows%3A 10843%0A    %7D%29%0A%7D%29" isContainer="True" shape="('train',)" />
<var name="dataset_eval" type="Dataset" qualifier="datasets.arrow_dataset" value="Dataset%28%7B%0A    features%3A %5B%27id%27%2C %27text%27%2C %27label%27%2C %27source_data%27%2C %27input_ids%27%2C %27token_type_ids%27%2C %27attention_mask%27%5D%2C%0A    num_rows%3A 1085%0A%7D%29" isContainer="True" shape="(1085, 7)" />
<var name="dataset_tokens" type="DatasetDict" qualifier="datasets.dataset_dict" value="DatasetDict%28%7B%0A    train%3A Dataset%28%7B%0A        features%3A %5B%27id%27%2C %27text%27%2C %27label%27%2C %27source_data%27%2C %27input_ids%27%2C %27token_type_ids%27%2C %27attention_mask%27%5D%2C%0A        num_rows%3A 10843%0A    %7D%29%0A%7D%29" isContainer="True" shape="('train',)" />
<var name="dataset_train" type="Dataset" qualifier="datasets.arrow_dataset" value="Dataset%28%7B%0A    features%3A %5B%27id%27%2C %27text%27%2C %27label%27%2C %27source_data%27%2C %27input_ids%27%2C %27token_type_ids%27%2C %27attention_mask%27%5D%2C%0A    num_rows%3A 9758%0A%7D%29" isContainer="True" shape="(9758, 7)" />
<var name="ft_model" type="BertForSequenceClassification" qualifier="transformers.models.bert.modeling_bert" value="BertForSequenceClassification%28%0A  %28bert%29%3A BertModel%28%0A    %28embeddings%29%3A BertEmbeddings%28%0A      %28word_embeddings%29%3A Embedding%2828996...anh%28%29%0A    %29%0A  %29%0A  %28dropout%29%3A Dropout%28p=0.1%2C inplace=False%29%0A  %28classifier%29%3A Linear%28in_features=768%2C out_features=2%2C bias=True%29%0A%29" isContainer="True" />
<var name="ft_model_checkpoint" type="str" qualifier="builtins" value="test_trainer/checkpoint-7317" />
<var name="label_count" type="int" qualifier="builtins" value="2" />
<var name="model_name" type="str" qualifier="builtins" value="./bert-base-cased" />
<var name="result" type="list" qualifier="builtins" value="%5B%7B%27label%27%3A %27NEGATIVE%27%2C %27score%27%3A 0.9997101426124573%7D%5D" isContainer="True" shape="1" />
<var name="sample_out" type="SequenceClassifierOutput" qualifier="transformers.modeling_outputs" value="SequenceClassifierOutput%28loss=None%2C logits=tensor%28%5B%5B 4.6930%2C -4.4127%5D%5D%2C grad_fn=%3CAddmmBackward0&gt;%29%2C hidden_states=None%2C attentions=None%29" isContainer="True" shape="1" />
<var name="sample_text" type="str" qualifier="builtins" value="ill make fresh start i promise xtra sad puppy face" />
<var name="sample_tokens" type="BatchEncoding" qualifier="transformers.tokenization_utils_base" value="%7B%27input_ids%27%3A tensor%28%5B%5B  101%2C  5178%2C  1294%2C  4489%2C  1838%2C   178%2C  4437%2C   193%2C  4487%2C  6782%2C%0A         21566%2C  1339%2C   102%2C    ...%2C 0%2C 0%2C 0%2C%0A         0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C%0A         0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%5D%5D%29%7D" isContainer="True" shape="3" />
<var name="scores" type="ndarray" qualifier="numpy" value="%5B9.9988902e-01 1.1102436e-04%5D" isContainer="True" shape="(2,)" />
<var name="shuffle" type="Dataset" qualifier="datasets.arrow_dataset" value="Dataset%28%7B%0A    features%3A %5B%27id%27%2C %27text%27%2C %27label%27%2C %27source_data%27%2C %27input_ids%27%2C %27token_type_ids%27%2C %27attention_mask%27%5D%2C%0A    num_rows%3A 10843%0A%7D%29" isContainer="True" shape="(10843, 7)" />
<var name="tokenizer" type="BertTokenizerFast" qualifier="transformers.models.bert.tokenization_bert_fast" value="BertTokenizerFast%28name_or_path=%27./bert-base-cased%27%2C vocab_size=28996%2C model_max_length=1000000000000000019884624838656%2C is_fas...se%2C special=True%29%2C%0A%09103%3A AddedToken%28%22%5BMASK%5D%22%2C rstrip=False%2C lstrip=False%2C single_word=False%2C normalized=False%2C special=True%29%2C%0A%7D" isContainer="True" shape="28996" />
<var name="train_count" type="int" qualifier="builtins" value="9758" />
<var name="trainer" type="Trainer" qualifier="transformers.trainer" value="%3Ctransformers.trainer.Trainer object at 0x0000027DAAA33190&gt;" isContainer="True" />
<var name="training_args" type="TrainingArguments" qualifier="transformers.training_args" value="TrainingArguments%28%0A_n_gpu=1%2C%0Aadafactor=False%2C%0Aadam_beta1=0.9%2C%0Aadam_beta2=0.999%2C%0Aadam_epsilon=1e-08%2C%0Aauto_find_batch_size=False...use_ipex=False%2C%0Ause_legacy_prediction_loop=False%2C%0Ause_mps_device=False%2C%0Awarmup_ratio=0.0%2C%0Awarmup_steps=100%2C%0Aweight_decay=0.0%2C%0A%29" isContainer="True" />
</xml>
depressive score: 0.0021486273 neutral score: 0.9978514
<xml><var name="_dummy_ipython_val"  />
<var name="_dummy_special_var"  />
<var name="acc_metric" type="Accuracy" qualifier="evaluate_modules.metrics.accuracy.f887c0aab52c2d38e1f8a215681126379eca617f96c447638f751434e8e65b14.accuracy" value="EvaluationModule%28name%3A %22accuracy%22%2C module_type%3A %22metric%22%2C features%3A %7B%27predictions%27%3A Value%28dtype=%27int32%27%2C id=None%29%2C %27references...weight=%5B0.5%2C 2%2C 0.7%2C 0.5%2C 9%2C 0.4%5D%29%0A        &gt;&gt;&gt; print%28results%29%0A        %7B%27accuracy%27%3A 0.8778625954198473%7D%0A%22%22%22%2C stored examples%3A 0%29" isContainer="True" shape="0" />
<var name="base_model" type="BertForSequenceClassification" qualifier="transformers.models.bert.modeling_bert" value="BertForSequenceClassification%28%0A  %28bert%29%3A BertModel%28%0A    %28embeddings%29%3A BertEmbeddings%28%0A      %28word_embeddings%29%3A Embedding%2828996...anh%28%29%0A    %29%0A  %29%0A  %28dropout%29%3A Dropout%28p=0.1%2C inplace=False%29%0A  %28classifier%29%3A Linear%28in_features=768%2C out_features=2%2C bias=True%29%0A%29" isContainer="True" />
<var name="classifier" type="TextClassificationPipeline" qualifier="transformers.pipelines.text_classification" value="%3Ctransformers.pipelines.text_classification.TextClassificationPipeline object at 0x0000027DF5F25C10&gt;" isContainer="True" />
<var name="dataset" type="DatasetDict" qualifier="datasets.dataset_dict" value="DatasetDict%28%7B%0A    train%3A Dataset%28%7B%0A        features%3A %5B%27id%27%2C %27text%27%2C %27label%27%2C %27source_data%27%5D%2C%0A        num_rows%3A 10843%0A    %7D%29%0A%7D%29" isContainer="True" shape="('train',)" />
<var name="dataset_eval" type="Dataset" qualifier="datasets.arrow_dataset" value="Dataset%28%7B%0A    features%3A %5B%27id%27%2C %27text%27%2C %27label%27%2C %27source_data%27%2C %27input_ids%27%2C %27token_type_ids%27%2C %27attention_mask%27%5D%2C%0A    num_rows%3A 1085%0A%7D%29" isContainer="True" shape="(1085, 7)" />
<var name="dataset_tokens" type="DatasetDict" qualifier="datasets.dataset_dict" value="DatasetDict%28%7B%0A    train%3A Dataset%28%7B%0A        features%3A %5B%27id%27%2C %27text%27%2C %27label%27%2C %27source_data%27%2C %27input_ids%27%2C %27token_type_ids%27%2C %27attention_mask%27%5D%2C%0A        num_rows%3A 10843%0A    %7D%29%0A%7D%29" isContainer="True" shape="('train',)" />
<var name="dataset_train" type="Dataset" qualifier="datasets.arrow_dataset" value="Dataset%28%7B%0A    features%3A %5B%27id%27%2C %27text%27%2C %27label%27%2C %27source_data%27%2C %27input_ids%27%2C %27token_type_ids%27%2C %27attention_mask%27%5D%2C%0A    num_rows%3A 9758%0A%7D%29" isContainer="True" shape="(9758, 7)" />
<var name="ft_model" type="BertForSequenceClassification" qualifier="transformers.models.bert.modeling_bert" value="BertForSequenceClassification%28%0A  %28bert%29%3A BertModel%28%0A    %28embeddings%29%3A BertEmbeddings%28%0A      %28word_embeddings%29%3A Embedding%2828996...anh%28%29%0A    %29%0A  %29%0A  %28dropout%29%3A Dropout%28p=0.1%2C inplace=False%29%0A  %28classifier%29%3A Linear%28in_features=768%2C out_features=2%2C bias=True%29%0A%29" isContainer="True" />
<var name="ft_model_checkpoint" type="str" qualifier="builtins" value="test_trainer/checkpoint-7317" />
<var name="label_count" type="int" qualifier="builtins" value="2" />
<var name="model_name" type="str" qualifier="builtins" value="./bert-base-cased" />
<var name="result" type="list" qualifier="builtins" value="%5B%7B%27label%27%3A %27NEGATIVE%27%2C %27score%27%3A 0.9997101426124573%7D%5D" isContainer="True" shape="1" />
<var name="sample_out" type="SequenceClassifierOutput" qualifier="transformers.modeling_outputs" value="SequenceClassifierOutput%28loss=None%2C logits=tensor%28%5B%5B 2.9234%2C -3.2174%5D%5D%2C grad_fn=%3CAddmmBackward0&gt;%29%2C hidden_states=None%2C attentions=None%29" isContainer="True" shape="1" />
<var name="sample_text" type="str" qualifier="builtins" value="to me it seems like an empty meaningless phrase people use like cool but it s not going to help the fact that i m broke can t get out of bed some day and struggling through live now" />
<var name="sample_tokens" type="BatchEncoding" qualifier="transformers.tokenization_utils_base" value="%7B%27input_ids%27%3A tensor%28%5B%5B 101%2C 1106%2C 1143%2C 1122%2C 3093%2C 1176%2C 1126%2C 3427%2C 2764%2C 2008%2C 7224%2C 1234%2C%0A         1329%2C 1176%2C 4348%2C 1133...%2C 0%2C 0%2C 0%2C%0A         0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C%0A         0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%5D%5D%29%7D" isContainer="True" shape="3" />
<var name="scores" type="ndarray" qualifier="numpy" value="%5B0.9978514  0.00214863%5D" isContainer="True" shape="(2,)" />
<var name="shuffle" type="Dataset" qualifier="datasets.arrow_dataset" value="Dataset%28%7B%0A    features%3A %5B%27id%27%2C %27text%27%2C %27label%27%2C %27source_data%27%2C %27input_ids%27%2C %27token_type_ids%27%2C %27attention_mask%27%5D%2C%0A    num_rows%3A 10843%0A%7D%29" isContainer="True" shape="(10843, 7)" />
<var name="tokenizer" type="BertTokenizerFast" qualifier="transformers.models.bert.tokenization_bert_fast" value="BertTokenizerFast%28name_or_path=%27./bert-base-cased%27%2C vocab_size=28996%2C model_max_length=1000000000000000019884624838656%2C is_fas...se%2C special=True%29%2C%0A%09103%3A AddedToken%28%22%5BMASK%5D%22%2C rstrip=False%2C lstrip=False%2C single_word=False%2C normalized=False%2C special=True%29%2C%0A%7D" isContainer="True" shape="28996" />
<var name="train_count" type="int" qualifier="builtins" value="9758" />
<var name="trainer" type="Trainer" qualifier="transformers.trainer" value="%3Ctransformers.trainer.Trainer object at 0x0000027DAAA33190&gt;" isContainer="True" />
<var name="training_args" type="TrainingArguments" qualifier="transformers.training_args" value="TrainingArguments%28%0A_n_gpu=1%2C%0Aadafactor=False%2C%0Aadam_beta1=0.9%2C%0Aadam_beta2=0.999%2C%0Aadam_epsilon=1e-08%2C%0Aauto_find_batch_size=False...use_ipex=False%2C%0Ause_legacy_prediction_loop=False%2C%0Ause_mps_device=False%2C%0Awarmup_ratio=0.0%2C%0Awarmup_steps=100%2C%0Aweight_decay=0.0%2C%0A%29" isContainer="True" />
</xml>
depressive score: 0.9993555 neutral score: 0.0006445518
<xml><var name="_dummy_ipython_val"  />
<var name="_dummy_special_var"  />
<var name="acc_metric" type="Accuracy" qualifier="evaluate_modules.metrics.accuracy.f887c0aab52c2d38e1f8a215681126379eca617f96c447638f751434e8e65b14.accuracy" value="EvaluationModule%28name%3A %22accuracy%22%2C module_type%3A %22metric%22%2C features%3A %7B%27predictions%27%3A Value%28dtype=%27int32%27%2C id=None%29%2C %27references...weight=%5B0.5%2C 2%2C 0.7%2C 0.5%2C 9%2C 0.4%5D%29%0A        &gt;&gt;&gt; print%28results%29%0A        %7B%27accuracy%27%3A 0.8778625954198473%7D%0A%22%22%22%2C stored examples%3A 0%29" isContainer="True" shape="0" />
<var name="base_model" type="BertForSequenceClassification" qualifier="transformers.models.bert.modeling_bert" value="BertForSequenceClassification%28%0A  %28bert%29%3A BertModel%28%0A    %28embeddings%29%3A BertEmbeddings%28%0A      %28word_embeddings%29%3A Embedding%2828996...anh%28%29%0A    %29%0A  %29%0A  %28dropout%29%3A Dropout%28p=0.1%2C inplace=False%29%0A  %28classifier%29%3A Linear%28in_features=768%2C out_features=2%2C bias=True%29%0A%29" isContainer="True" />
<var name="classifier" type="TextClassificationPipeline" qualifier="transformers.pipelines.text_classification" value="%3Ctransformers.pipelines.text_classification.TextClassificationPipeline object at 0x0000027DF5F25C10&gt;" isContainer="True" />
<var name="dataset" type="DatasetDict" qualifier="datasets.dataset_dict" value="DatasetDict%28%7B%0A    train%3A Dataset%28%7B%0A        features%3A %5B%27id%27%2C %27text%27%2C %27label%27%2C %27source_data%27%5D%2C%0A        num_rows%3A 10843%0A    %7D%29%0A%7D%29" isContainer="True" shape="('train',)" />
<var name="dataset_eval" type="Dataset" qualifier="datasets.arrow_dataset" value="Dataset%28%7B%0A    features%3A %5B%27id%27%2C %27text%27%2C %27label%27%2C %27source_data%27%2C %27input_ids%27%2C %27token_type_ids%27%2C %27attention_mask%27%5D%2C%0A    num_rows%3A 1085%0A%7D%29" isContainer="True" shape="(1085, 7)" />
<var name="dataset_tokens" type="DatasetDict" qualifier="datasets.dataset_dict" value="DatasetDict%28%7B%0A    train%3A Dataset%28%7B%0A        features%3A %5B%27id%27%2C %27text%27%2C %27label%27%2C %27source_data%27%2C %27input_ids%27%2C %27token_type_ids%27%2C %27attention_mask%27%5D%2C%0A        num_rows%3A 10843%0A    %7D%29%0A%7D%29" isContainer="True" shape="('train',)" />
<var name="dataset_train" type="Dataset" qualifier="datasets.arrow_dataset" value="Dataset%28%7B%0A    features%3A %5B%27id%27%2C %27text%27%2C %27label%27%2C %27source_data%27%2C %27input_ids%27%2C %27token_type_ids%27%2C %27attention_mask%27%5D%2C%0A    num_rows%3A 9758%0A%7D%29" isContainer="True" shape="(9758, 7)" />
<var name="ft_model" type="BertForSequenceClassification" qualifier="transformers.models.bert.modeling_bert" value="BertForSequenceClassification%28%0A  %28bert%29%3A BertModel%28%0A    %28embeddings%29%3A BertEmbeddings%28%0A      %28word_embeddings%29%3A Embedding%2828996...anh%28%29%0A    %29%0A  %29%0A  %28dropout%29%3A Dropout%28p=0.1%2C inplace=False%29%0A  %28classifier%29%3A Linear%28in_features=768%2C out_features=2%2C bias=True%29%0A%29" isContainer="True" />
<var name="ft_model_checkpoint" type="str" qualifier="builtins" value="test_trainer/checkpoint-7317" />
<var name="label_count" type="int" qualifier="builtins" value="2" />
<var name="model_name" type="str" qualifier="builtins" value="./bert-base-cased" />
<var name="result" type="list" qualifier="builtins" value="%5B%7B%27label%27%3A %27NEGATIVE%27%2C %27score%27%3A 0.9997101426124573%7D%5D" isContainer="True" shape="1" />
<var name="sample_out" type="SequenceClassifierOutput" qualifier="transformers.modeling_outputs" value="SequenceClassifierOutput%28loss=None%2C logits=tensor%28%5B%5B-3.9263%2C  3.4200%5D%5D%2C grad_fn=%3CAddmmBackward0&gt;%29%2C hidden_states=None%2C attentions=None%29" isContainer="True" shape="1" />
<var name="sample_text" type="str" qualifier="builtins" value="i dont bother doing anything all day and im failing college yet im still tired and im constantly thinking about suicide" />
<var name="sample_tokens" type="BatchEncoding" qualifier="transformers.tokenization_utils_base" value="%7B%27input_ids%27%3A tensor%28%5B%5B  101%2C   178%2C  1274%2C  1204%2C  8255%2C  1833%2C  1625%2C  1155%2C  1285%2C  1105%2C%0A         13280%2C  7793%2C  2134%2C  18...%2C 0%2C 0%2C 0%2C%0A         0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C%0A         0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%5D%5D%29%7D" isContainer="True" shape="3" />
<var name="scores" type="ndarray" qualifier="numpy" value="%5B6.445518e-04 9.993555e-01%5D" isContainer="True" shape="(2,)" />
<var name="shuffle" type="Dataset" qualifier="datasets.arrow_dataset" value="Dataset%28%7B%0A    features%3A %5B%27id%27%2C %27text%27%2C %27label%27%2C %27source_data%27%2C %27input_ids%27%2C %27token_type_ids%27%2C %27attention_mask%27%5D%2C%0A    num_rows%3A 10843%0A%7D%29" isContainer="True" shape="(10843, 7)" />
<var name="tokenizer" type="BertTokenizerFast" qualifier="transformers.models.bert.tokenization_bert_fast" value="BertTokenizerFast%28name_or_path=%27./bert-base-cased%27%2C vocab_size=28996%2C model_max_length=1000000000000000019884624838656%2C is_fas...se%2C special=True%29%2C%0A%09103%3A AddedToken%28%22%5BMASK%5D%22%2C rstrip=False%2C lstrip=False%2C single_word=False%2C normalized=False%2C special=True%29%2C%0A%7D" isContainer="True" shape="28996" />
<var name="train_count" type="int" qualifier="builtins" value="9758" />
<var name="trainer" type="Trainer" qualifier="transformers.trainer" value="%3Ctransformers.trainer.Trainer object at 0x0000027DAAA33190&gt;" isContainer="True" />
<var name="training_args" type="TrainingArguments" qualifier="transformers.training_args" value="TrainingArguments%28%0A_n_gpu=1%2C%0Aadafactor=False%2C%0Aadam_beta1=0.9%2C%0Aadam_beta2=0.999%2C%0Aadam_epsilon=1e-08%2C%0Aauto_find_batch_size=False...use_ipex=False%2C%0Ause_legacy_prediction_loop=False%2C%0Ause_mps_device=False%2C%0Awarmup_ratio=0.0%2C%0Awarmup_steps=100%2C%0Aweight_decay=0.0%2C%0A%29" isContainer="True" />
</xml>
depressive score: 0.00016904059 neutral score: 0.99983096
<xml><var name="_dummy_ipython_val"  />
<var name="_dummy_special_var"  />
<var name="acc_metric" type="Accuracy" qualifier="evaluate_modules.metrics.accuracy.f887c0aab52c2d38e1f8a215681126379eca617f96c447638f751434e8e65b14.accuracy" value="EvaluationModule%28name%3A %22accuracy%22%2C module_type%3A %22metric%22%2C features%3A %7B%27predictions%27%3A Value%28dtype=%27int32%27%2C id=None%29%2C %27references...weight=%5B0.5%2C 2%2C 0.7%2C 0.5%2C 9%2C 0.4%5D%29%0A        &gt;&gt;&gt; print%28results%29%0A        %7B%27accuracy%27%3A 0.8778625954198473%7D%0A%22%22%22%2C stored examples%3A 0%29" isContainer="True" shape="0" />
<var name="base_model" type="BertForSequenceClassification" qualifier="transformers.models.bert.modeling_bert" value="BertForSequenceClassification%28%0A  %28bert%29%3A BertModel%28%0A    %28embeddings%29%3A BertEmbeddings%28%0A      %28word_embeddings%29%3A Embedding%2828996...anh%28%29%0A    %29%0A  %29%0A  %28dropout%29%3A Dropout%28p=0.1%2C inplace=False%29%0A  %28classifier%29%3A Linear%28in_features=768%2C out_features=2%2C bias=True%29%0A%29" isContainer="True" />
<var name="classifier" type="TextClassificationPipeline" qualifier="transformers.pipelines.text_classification" value="%3Ctransformers.pipelines.text_classification.TextClassificationPipeline object at 0x0000027DF5F25C10&gt;" isContainer="True" />
<var name="dataset" type="DatasetDict" qualifier="datasets.dataset_dict" value="DatasetDict%28%7B%0A    train%3A Dataset%28%7B%0A        features%3A %5B%27id%27%2C %27text%27%2C %27label%27%2C %27source_data%27%5D%2C%0A        num_rows%3A 10843%0A    %7D%29%0A%7D%29" isContainer="True" shape="('train',)" />
<var name="dataset_eval" type="Dataset" qualifier="datasets.arrow_dataset" value="Dataset%28%7B%0A    features%3A %5B%27id%27%2C %27text%27%2C %27label%27%2C %27source_data%27%2C %27input_ids%27%2C %27token_type_ids%27%2C %27attention_mask%27%5D%2C%0A    num_rows%3A 1085%0A%7D%29" isContainer="True" shape="(1085, 7)" />
<var name="dataset_tokens" type="DatasetDict" qualifier="datasets.dataset_dict" value="DatasetDict%28%7B%0A    train%3A Dataset%28%7B%0A        features%3A %5B%27id%27%2C %27text%27%2C %27label%27%2C %27source_data%27%2C %27input_ids%27%2C %27token_type_ids%27%2C %27attention_mask%27%5D%2C%0A        num_rows%3A 10843%0A    %7D%29%0A%7D%29" isContainer="True" shape="('train',)" />
<var name="dataset_train" type="Dataset" qualifier="datasets.arrow_dataset" value="Dataset%28%7B%0A    features%3A %5B%27id%27%2C %27text%27%2C %27label%27%2C %27source_data%27%2C %27input_ids%27%2C %27token_type_ids%27%2C %27attention_mask%27%5D%2C%0A    num_rows%3A 9758%0A%7D%29" isContainer="True" shape="(9758, 7)" />
<var name="ft_model" type="BertForSequenceClassification" qualifier="transformers.models.bert.modeling_bert" value="BertForSequenceClassification%28%0A  %28bert%29%3A BertModel%28%0A    %28embeddings%29%3A BertEmbeddings%28%0A      %28word_embeddings%29%3A Embedding%2828996...anh%28%29%0A    %29%0A  %29%0A  %28dropout%29%3A Dropout%28p=0.1%2C inplace=False%29%0A  %28classifier%29%3A Linear%28in_features=768%2C out_features=2%2C bias=True%29%0A%29" isContainer="True" />
<var name="ft_model_checkpoint" type="str" qualifier="builtins" value="test_trainer/checkpoint-7317" />
<var name="label_count" type="int" qualifier="builtins" value="2" />
<var name="model_name" type="str" qualifier="builtins" value="./bert-base-cased" />
<var name="result" type="list" qualifier="builtins" value="%5B%7B%27label%27%3A %27NEGATIVE%27%2C %27score%27%3A 0.9997101426124573%7D%5D" isContainer="True" shape="1" />
<var name="sample_out" type="SequenceClassifierOutput" qualifier="transformers.modeling_outputs" value="SequenceClassifierOutput%28loss=None%2C logits=tensor%28%5B%5B 4.4679%2C -4.2173%5D%5D%2C grad_fn=%3CAddmmBackward0&gt;%29%2C hidden_states=None%2C attentions=None%29" isContainer="True" shape="1" />
<var name="sample_text" type="str" qualifier="builtins" value="like a battery in a remote s back that keep it working i wish i could also remove the battery and just turn off for a while" />
<var name="sample_tokens" type="BatchEncoding" qualifier="transformers.tokenization_utils_base" value="%7B%27input_ids%27%3A tensor%28%5B%5B 101%2C 1176%2C  170%2C 7105%2C 1107%2C  170%2C 6456%2C  188%2C 1171%2C 1115%2C 1712%2C 1122%2C%0A         1684%2C  178%2C 3683%2C  178...%2C 0%2C 0%2C 0%2C%0A         0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C%0A         0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%5D%5D%29%7D" isContainer="True" shape="3" />
<var name="scores" type="ndarray" qualifier="numpy" value="%5B9.9983096e-01 1.6904059e-04%5D" isContainer="True" shape="(2,)" />
<var name="shuffle" type="Dataset" qualifier="datasets.arrow_dataset" value="Dataset%28%7B%0A    features%3A %5B%27id%27%2C %27text%27%2C %27label%27%2C %27source_data%27%2C %27input_ids%27%2C %27token_type_ids%27%2C %27attention_mask%27%5D%2C%0A    num_rows%3A 10843%0A%7D%29" isContainer="True" shape="(10843, 7)" />
<var name="tokenizer" type="BertTokenizerFast" qualifier="transformers.models.bert.tokenization_bert_fast" value="BertTokenizerFast%28name_or_path=%27./bert-base-cased%27%2C vocab_size=28996%2C model_max_length=1000000000000000019884624838656%2C is_fas...se%2C special=True%29%2C%0A%09103%3A AddedToken%28%22%5BMASK%5D%22%2C rstrip=False%2C lstrip=False%2C single_word=False%2C normalized=False%2C special=True%29%2C%0A%7D" isContainer="True" shape="28996" />
<var name="train_count" type="int" qualifier="builtins" value="9758" />
<var name="trainer" type="Trainer" qualifier="transformers.trainer" value="%3Ctransformers.trainer.Trainer object at 0x0000027DAAA33190&gt;" isContainer="True" />
<var name="training_args" type="TrainingArguments" qualifier="transformers.training_args" value="TrainingArguments%28%0A_n_gpu=1%2C%0Aadafactor=False%2C%0Aadam_beta1=0.9%2C%0Aadam_beta2=0.999%2C%0Aadam_epsilon=1e-08%2C%0Aauto_find_batch_size=False...use_ipex=False%2C%0Ause_legacy_prediction_loop=False%2C%0Ause_mps_device=False%2C%0Awarmup_ratio=0.0%2C%0Awarmup_steps=100%2C%0Aweight_decay=0.0%2C%0A%29" isContainer="True" />
</xml>
depressive score: 0.00041366983 neutral score: 0.9995863
<xml><var name="_dummy_ipython_val"  />
<var name="_dummy_special_var"  />
<var name="acc_metric" type="Accuracy" qualifier="evaluate_modules.metrics.accuracy.f887c0aab52c2d38e1f8a215681126379eca617f96c447638f751434e8e65b14.accuracy" value="EvaluationModule%28name%3A %22accuracy%22%2C module_type%3A %22metric%22%2C features%3A %7B%27predictions%27%3A Value%28dtype=%27int32%27%2C id=None%29%2C %27references...weight=%5B0.5%2C 2%2C 0.7%2C 0.5%2C 9%2C 0.4%5D%29%0A        &gt;&gt;&gt; print%28results%29%0A        %7B%27accuracy%27%3A 0.8778625954198473%7D%0A%22%22%22%2C stored examples%3A 0%29" isContainer="True" shape="0" />
<var name="base_model" type="BertForSequenceClassification" qualifier="transformers.models.bert.modeling_bert" value="BertForSequenceClassification%28%0A  %28bert%29%3A BertModel%28%0A    %28embeddings%29%3A BertEmbeddings%28%0A      %28word_embeddings%29%3A Embedding%2828996...anh%28%29%0A    %29%0A  %29%0A  %28dropout%29%3A Dropout%28p=0.1%2C inplace=False%29%0A  %28classifier%29%3A Linear%28in_features=768%2C out_features=2%2C bias=True%29%0A%29" isContainer="True" />
<var name="classifier" type="TextClassificationPipeline" qualifier="transformers.pipelines.text_classification" value="%3Ctransformers.pipelines.text_classification.TextClassificationPipeline object at 0x0000027DF5F25C10&gt;" isContainer="True" />
<var name="dataset" type="DatasetDict" qualifier="datasets.dataset_dict" value="DatasetDict%28%7B%0A    train%3A Dataset%28%7B%0A        features%3A %5B%27id%27%2C %27text%27%2C %27label%27%2C %27source_data%27%5D%2C%0A        num_rows%3A 10843%0A    %7D%29%0A%7D%29" isContainer="True" shape="('train',)" />
<var name="dataset_eval" type="Dataset" qualifier="datasets.arrow_dataset" value="Dataset%28%7B%0A    features%3A %5B%27id%27%2C %27text%27%2C %27label%27%2C %27source_data%27%2C %27input_ids%27%2C %27token_type_ids%27%2C %27attention_mask%27%5D%2C%0A    num_rows%3A 1085%0A%7D%29" isContainer="True" shape="(1085, 7)" />
<var name="dataset_tokens" type="DatasetDict" qualifier="datasets.dataset_dict" value="DatasetDict%28%7B%0A    train%3A Dataset%28%7B%0A        features%3A %5B%27id%27%2C %27text%27%2C %27label%27%2C %27source_data%27%2C %27input_ids%27%2C %27token_type_ids%27%2C %27attention_mask%27%5D%2C%0A        num_rows%3A 10843%0A    %7D%29%0A%7D%29" isContainer="True" shape="('train',)" />
<var name="dataset_train" type="Dataset" qualifier="datasets.arrow_dataset" value="Dataset%28%7B%0A    features%3A %5B%27id%27%2C %27text%27%2C %27label%27%2C %27source_data%27%2C %27input_ids%27%2C %27token_type_ids%27%2C %27attention_mask%27%5D%2C%0A    num_rows%3A 9758%0A%7D%29" isContainer="True" shape="(9758, 7)" />
<var name="ft_model" type="BertForSequenceClassification" qualifier="transformers.models.bert.modeling_bert" value="BertForSequenceClassification%28%0A  %28bert%29%3A BertModel%28%0A    %28embeddings%29%3A BertEmbeddings%28%0A      %28word_embeddings%29%3A Embedding%2828996...anh%28%29%0A    %29%0A  %29%0A  %28dropout%29%3A Dropout%28p=0.1%2C inplace=False%29%0A  %28classifier%29%3A Linear%28in_features=768%2C out_features=2%2C bias=True%29%0A%29" isContainer="True" />
<var name="ft_model_checkpoint" type="str" qualifier="builtins" value="test_trainer/checkpoint-7317" />
<var name="label_count" type="int" qualifier="builtins" value="2" />
<var name="model_name" type="str" qualifier="builtins" value="./bert-base-cased" />
<var name="result" type="list" qualifier="builtins" value="%5B%7B%27label%27%3A %27NEGATIVE%27%2C %27score%27%3A 0.9997101426124573%7D%5D" isContainer="True" shape="1" />
<var name="sample_out" type="SequenceClassifierOutput" qualifier="transformers.modeling_outputs" value="SequenceClassifierOutput%28loss=None%2C logits=tensor%28%5B%5B 3.8304%2C -3.9597%5D%5D%2C grad_fn=%3CAddmmBackward0&gt;%29%2C hidden_states=None%2C attentions=None%29" isContainer="True" shape="1" />
<var name="sample_text" type="str" qualifier="builtins" value="it s all rainy and cloudy and stuff today for me but even if it wasn t i d still feel this way" />
<var name="sample_tokens" type="BatchEncoding" qualifier="transformers.tokenization_utils_base" value="%7B%27input_ids%27%3A tensor%28%5B%5B  101%2C  1122%2C   188%2C  1155%2C 21098%2C  1105%2C  7180%2C  1183%2C  1105%2C  4333%2C%0A          2052%2C  1111%2C  1143%2C  11...%2C 0%2C 0%2C 0%2C%0A         0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C%0A         0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%5D%5D%29%7D" isContainer="True" shape="3" />
<var name="scores" type="ndarray" qualifier="numpy" value="%5B9.9958628e-01 4.1366983e-04%5D" isContainer="True" shape="(2,)" />
<var name="shuffle" type="Dataset" qualifier="datasets.arrow_dataset" value="Dataset%28%7B%0A    features%3A %5B%27id%27%2C %27text%27%2C %27label%27%2C %27source_data%27%2C %27input_ids%27%2C %27token_type_ids%27%2C %27attention_mask%27%5D%2C%0A    num_rows%3A 10843%0A%7D%29" isContainer="True" shape="(10843, 7)" />
<var name="tokenizer" type="BertTokenizerFast" qualifier="transformers.models.bert.tokenization_bert_fast" value="BertTokenizerFast%28name_or_path=%27./bert-base-cased%27%2C vocab_size=28996%2C model_max_length=1000000000000000019884624838656%2C is_fas...se%2C special=True%29%2C%0A%09103%3A AddedToken%28%22%5BMASK%5D%22%2C rstrip=False%2C lstrip=False%2C single_word=False%2C normalized=False%2C special=True%29%2C%0A%7D" isContainer="True" shape="28996" />
<var name="train_count" type="int" qualifier="builtins" value="9758" />
<var name="trainer" type="Trainer" qualifier="transformers.trainer" value="%3Ctransformers.trainer.Trainer object at 0x0000027DAAA33190&gt;" isContainer="True" />
<var name="training_args" type="TrainingArguments" qualifier="transformers.training_args" value="TrainingArguments%28%0A_n_gpu=1%2C%0Aadafactor=False%2C%0Aadam_beta1=0.9%2C%0Aadam_beta2=0.999%2C%0Aadam_epsilon=1e-08%2C%0Aauto_find_batch_size=False...use_ipex=False%2C%0Ause_legacy_prediction_loop=False%2C%0Ause_mps_device=False%2C%0Awarmup_ratio=0.0%2C%0Awarmup_steps=100%2C%0Aweight_decay=0.0%2C%0A%29" isContainer="True" />
</xml>
depressive score: 0.0001355973 neutral score: 0.99986434
<xml><var name="_dummy_ipython_val"  />
<var name="_dummy_special_var"  />
<var name="acc_metric" type="Accuracy" qualifier="evaluate_modules.metrics.accuracy.f887c0aab52c2d38e1f8a215681126379eca617f96c447638f751434e8e65b14.accuracy" value="EvaluationModule%28name%3A %22accuracy%22%2C module_type%3A %22metric%22%2C features%3A %7B%27predictions%27%3A Value%28dtype=%27int32%27%2C id=None%29%2C %27references...weight=%5B0.5%2C 2%2C 0.7%2C 0.5%2C 9%2C 0.4%5D%29%0A        &gt;&gt;&gt; print%28results%29%0A        %7B%27accuracy%27%3A 0.8778625954198473%7D%0A%22%22%22%2C stored examples%3A 0%29" isContainer="True" shape="0" />
<var name="base_model" type="BertForSequenceClassification" qualifier="transformers.models.bert.modeling_bert" value="BertForSequenceClassification%28%0A  %28bert%29%3A BertModel%28%0A    %28embeddings%29%3A BertEmbeddings%28%0A      %28word_embeddings%29%3A Embedding%2828996...anh%28%29%0A    %29%0A  %29%0A  %28dropout%29%3A Dropout%28p=0.1%2C inplace=False%29%0A  %28classifier%29%3A Linear%28in_features=768%2C out_features=2%2C bias=True%29%0A%29" isContainer="True" />
<var name="classifier" type="TextClassificationPipeline" qualifier="transformers.pipelines.text_classification" value="%3Ctransformers.pipelines.text_classification.TextClassificationPipeline object at 0x0000027DF5F25C10&gt;" isContainer="True" />
<var name="dataset" type="DatasetDict" qualifier="datasets.dataset_dict" value="DatasetDict%28%7B%0A    train%3A Dataset%28%7B%0A        features%3A %5B%27id%27%2C %27text%27%2C %27label%27%2C %27source_data%27%5D%2C%0A        num_rows%3A 10843%0A    %7D%29%0A%7D%29" isContainer="True" shape="('train',)" />
<var name="dataset_eval" type="Dataset" qualifier="datasets.arrow_dataset" value="Dataset%28%7B%0A    features%3A %5B%27id%27%2C %27text%27%2C %27label%27%2C %27source_data%27%2C %27input_ids%27%2C %27token_type_ids%27%2C %27attention_mask%27%5D%2C%0A    num_rows%3A 1085%0A%7D%29" isContainer="True" shape="(1085, 7)" />
<var name="dataset_tokens" type="DatasetDict" qualifier="datasets.dataset_dict" value="DatasetDict%28%7B%0A    train%3A Dataset%28%7B%0A        features%3A %5B%27id%27%2C %27text%27%2C %27label%27%2C %27source_data%27%2C %27input_ids%27%2C %27token_type_ids%27%2C %27attention_mask%27%5D%2C%0A        num_rows%3A 10843%0A    %7D%29%0A%7D%29" isContainer="True" shape="('train',)" />
<var name="dataset_train" type="Dataset" qualifier="datasets.arrow_dataset" value="Dataset%28%7B%0A    features%3A %5B%27id%27%2C %27text%27%2C %27label%27%2C %27source_data%27%2C %27input_ids%27%2C %27token_type_ids%27%2C %27attention_mask%27%5D%2C%0A    num_rows%3A 9758%0A%7D%29" isContainer="True" shape="(9758, 7)" />
<var name="ft_model" type="BertForSequenceClassification" qualifier="transformers.models.bert.modeling_bert" value="BertForSequenceClassification%28%0A  %28bert%29%3A BertModel%28%0A    %28embeddings%29%3A BertEmbeddings%28%0A      %28word_embeddings%29%3A Embedding%2828996...anh%28%29%0A    %29%0A  %29%0A  %28dropout%29%3A Dropout%28p=0.1%2C inplace=False%29%0A  %28classifier%29%3A Linear%28in_features=768%2C out_features=2%2C bias=True%29%0A%29" isContainer="True" />
<var name="ft_model_checkpoint" type="str" qualifier="builtins" value="test_trainer/checkpoint-7317" />
<var name="label_count" type="int" qualifier="builtins" value="2" />
<var name="model_name" type="str" qualifier="builtins" value="./bert-base-cased" />
<var name="result" type="list" qualifier="builtins" value="%5B%7B%27label%27%3A %27NEGATIVE%27%2C %27score%27%3A 0.9997101426124573%7D%5D" isContainer="True" shape="1" />
<var name="sample_out" type="SequenceClassifierOutput" qualifier="transformers.modeling_outputs" value="SequenceClassifierOutput%28loss=None%2C logits=tensor%28%5B%5B 4.6040%2C -4.3017%5D%5D%2C grad_fn=%3CAddmmBackward0&gt;%29%2C hidden_states=None%2C attentions=None%29" isContainer="True" shape="1" />
<var name="sample_text" type="str" qualifier="builtins" value="i never had illusion of grandeur growing up i had a pretty low bar for what itd take to make me happy" />
<var name="sample_tokens" type="BatchEncoding" qualifier="transformers.tokenization_utils_base" value="%7B%27input_ids%27%3A tensor%28%5B%5B  101%2C   178%2C  1309%2C  1125%2C 14488%2C  1104%2C  5372%2C  8816%2C  2898%2C  1146%2C%0A           178%2C  1125%2C   170%2C  27...%2C 0%2C 0%2C 0%2C%0A         0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C%0A         0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%5D%5D%29%7D" isContainer="True" shape="3" />
<var name="scores" type="ndarray" qualifier="numpy" value="%5B9.9986434e-01 1.3559731e-04%5D" isContainer="True" shape="(2,)" />
<var name="shuffle" type="Dataset" qualifier="datasets.arrow_dataset" value="Dataset%28%7B%0A    features%3A %5B%27id%27%2C %27text%27%2C %27label%27%2C %27source_data%27%2C %27input_ids%27%2C %27token_type_ids%27%2C %27attention_mask%27%5D%2C%0A    num_rows%3A 10843%0A%7D%29" isContainer="True" shape="(10843, 7)" />
<var name="tokenizer" type="BertTokenizerFast" qualifier="transformers.models.bert.tokenization_bert_fast" value="BertTokenizerFast%28name_or_path=%27./bert-base-cased%27%2C vocab_size=28996%2C model_max_length=1000000000000000019884624838656%2C is_fas...se%2C special=True%29%2C%0A%09103%3A AddedToken%28%22%5BMASK%5D%22%2C rstrip=False%2C lstrip=False%2C single_word=False%2C normalized=False%2C special=True%29%2C%0A%7D" isContainer="True" shape="28996" />
<var name="train_count" type="int" qualifier="builtins" value="9758" />
<var name="trainer" type="Trainer" qualifier="transformers.trainer" value="%3Ctransformers.trainer.Trainer object at 0x0000027DAAA33190&gt;" isContainer="True" />
<var name="training_args" type="TrainingArguments" qualifier="transformers.training_args" value="TrainingArguments%28%0A_n_gpu=1%2C%0Aadafactor=False%2C%0Aadam_beta1=0.9%2C%0Aadam_beta2=0.999%2C%0Aadam_epsilon=1e-08%2C%0Aauto_find_batch_size=False...use_ipex=False%2C%0Ause_legacy_prediction_loop=False%2C%0Ause_mps_device=False%2C%0Awarmup_ratio=0.0%2C%0Awarmup_steps=100%2C%0Aweight_decay=0.0%2C%0A%29" isContainer="True" />
</xml>
depressive score: 0.9985948 neutral score: 0.0014051461
<xml><var name="_dummy_ipython_val"  />
<var name="_dummy_special_var"  />
<var name="acc_metric" type="Accuracy" qualifier="evaluate_modules.metrics.accuracy.f887c0aab52c2d38e1f8a215681126379eca617f96c447638f751434e8e65b14.accuracy" value="EvaluationModule%28name%3A %22accuracy%22%2C module_type%3A %22metric%22%2C features%3A %7B%27predictions%27%3A Value%28dtype=%27int32%27%2C id=None%29%2C %27references...weight=%5B0.5%2C 2%2C 0.7%2C 0.5%2C 9%2C 0.4%5D%29%0A        &gt;&gt;&gt; print%28results%29%0A        %7B%27accuracy%27%3A 0.8778625954198473%7D%0A%22%22%22%2C stored examples%3A 0%29" isContainer="True" shape="0" />
<var name="base_model" type="BertForSequenceClassification" qualifier="transformers.models.bert.modeling_bert" value="BertForSequenceClassification%28%0A  %28bert%29%3A BertModel%28%0A    %28embeddings%29%3A BertEmbeddings%28%0A      %28word_embeddings%29%3A Embedding%2828996...anh%28%29%0A    %29%0A  %29%0A  %28dropout%29%3A Dropout%28p=0.1%2C inplace=False%29%0A  %28classifier%29%3A Linear%28in_features=768%2C out_features=2%2C bias=True%29%0A%29" isContainer="True" />
<var name="classifier" type="TextClassificationPipeline" qualifier="transformers.pipelines.text_classification" value="%3Ctransformers.pipelines.text_classification.TextClassificationPipeline object at 0x0000027DF5F25C10&gt;" isContainer="True" />
<var name="dataset" type="DatasetDict" qualifier="datasets.dataset_dict" value="DatasetDict%28%7B%0A    train%3A Dataset%28%7B%0A        features%3A %5B%27id%27%2C %27text%27%2C %27label%27%2C %27source_data%27%5D%2C%0A        num_rows%3A 10843%0A    %7D%29%0A%7D%29" isContainer="True" shape="('train',)" />
<var name="dataset_eval" type="Dataset" qualifier="datasets.arrow_dataset" value="Dataset%28%7B%0A    features%3A %5B%27id%27%2C %27text%27%2C %27label%27%2C %27source_data%27%2C %27input_ids%27%2C %27token_type_ids%27%2C %27attention_mask%27%5D%2C%0A    num_rows%3A 1085%0A%7D%29" isContainer="True" shape="(1085, 7)" />
<var name="dataset_tokens" type="DatasetDict" qualifier="datasets.dataset_dict" value="DatasetDict%28%7B%0A    train%3A Dataset%28%7B%0A        features%3A %5B%27id%27%2C %27text%27%2C %27label%27%2C %27source_data%27%2C %27input_ids%27%2C %27token_type_ids%27%2C %27attention_mask%27%5D%2C%0A        num_rows%3A 10843%0A    %7D%29%0A%7D%29" isContainer="True" shape="('train',)" />
<var name="dataset_train" type="Dataset" qualifier="datasets.arrow_dataset" value="Dataset%28%7B%0A    features%3A %5B%27id%27%2C %27text%27%2C %27label%27%2C %27source_data%27%2C %27input_ids%27%2C %27token_type_ids%27%2C %27attention_mask%27%5D%2C%0A    num_rows%3A 9758%0A%7D%29" isContainer="True" shape="(9758, 7)" />
<var name="ft_model" type="BertForSequenceClassification" qualifier="transformers.models.bert.modeling_bert" value="BertForSequenceClassification%28%0A  %28bert%29%3A BertModel%28%0A    %28embeddings%29%3A BertEmbeddings%28%0A      %28word_embeddings%29%3A Embedding%2828996...anh%28%29%0A    %29%0A  %29%0A  %28dropout%29%3A Dropout%28p=0.1%2C inplace=False%29%0A  %28classifier%29%3A Linear%28in_features=768%2C out_features=2%2C bias=True%29%0A%29" isContainer="True" />
<var name="ft_model_checkpoint" type="str" qualifier="builtins" value="test_trainer/checkpoint-7317" />
<var name="label_count" type="int" qualifier="builtins" value="2" />
<var name="model_name" type="str" qualifier="builtins" value="./bert-base-cased" />
<var name="result" type="list" qualifier="builtins" value="%5B%7B%27label%27%3A %27NEGATIVE%27%2C %27score%27%3A 0.9997101426124573%7D%5D" isContainer="True" shape="1" />
<var name="sample_out" type="SequenceClassifierOutput" qualifier="transformers.modeling_outputs" value="SequenceClassifierOutput%28loss=None%2C logits=tensor%28%5B%5B-3.5057%2C  3.0605%5D%5D%2C grad_fn=%3CAddmmBackward0&gt;%29%2C hidden_states=None%2C attentions=None%29" isContainer="True" shape="1" />
<var name="sample_text" type="str" qualifier="builtins" value="i feel completely exhausted my life isn t going anywhere and i ve got nobody to turn to" />
<var name="sample_tokens" type="BatchEncoding" qualifier="transformers.tokenization_utils_base" value="%7B%27input_ids%27%3A tensor%28%5B%5B 101%2C  178%2C 1631%2C 2423%2C 8984%2C 1139%2C 1297%2C 2762%2C  189%2C 1280%2C 5456%2C 1105%2C%0A          178%2C 1396%2C 1400%2C 8582...%2C 0%2C 0%2C 0%2C%0A         0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C%0A         0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%5D%5D%29%7D" isContainer="True" shape="3" />
<var name="scores" type="ndarray" qualifier="numpy" value="%5B0.00140515 0.9985948 %5D" isContainer="True" shape="(2,)" />
<var name="shuffle" type="Dataset" qualifier="datasets.arrow_dataset" value="Dataset%28%7B%0A    features%3A %5B%27id%27%2C %27text%27%2C %27label%27%2C %27source_data%27%2C %27input_ids%27%2C %27token_type_ids%27%2C %27attention_mask%27%5D%2C%0A    num_rows%3A 10843%0A%7D%29" isContainer="True" shape="(10843, 7)" />
<var name="tokenizer" type="BertTokenizerFast" qualifier="transformers.models.bert.tokenization_bert_fast" value="BertTokenizerFast%28name_or_path=%27./bert-base-cased%27%2C vocab_size=28996%2C model_max_length=1000000000000000019884624838656%2C is_fas...se%2C special=True%29%2C%0A%09103%3A AddedToken%28%22%5BMASK%5D%22%2C rstrip=False%2C lstrip=False%2C single_word=False%2C normalized=False%2C special=True%29%2C%0A%7D" isContainer="True" shape="28996" />
<var name="train_count" type="int" qualifier="builtins" value="9758" />
<var name="trainer" type="Trainer" qualifier="transformers.trainer" value="%3Ctransformers.trainer.Trainer object at 0x0000027DAAA33190&gt;" isContainer="True" />
<var name="training_args" type="TrainingArguments" qualifier="transformers.training_args" value="TrainingArguments%28%0A_n_gpu=1%2C%0Aadafactor=False%2C%0Aadam_beta1=0.9%2C%0Aadam_beta2=0.999%2C%0Aadam_epsilon=1e-08%2C%0Aauto_find_batch_size=False...use_ipex=False%2C%0Ause_legacy_prediction_loop=False%2C%0Ause_mps_device=False%2C%0Awarmup_ratio=0.0%2C%0Awarmup_steps=100%2C%0Aweight_decay=0.0%2C%0A%29" isContainer="True" />
</xml>
depressive score: 0.00012317205 neutral score: 0.99987686
<xml><var name="_dummy_ipython_val"  />
<var name="_dummy_special_var"  />
<var name="acc_metric" type="Accuracy" qualifier="evaluate_modules.metrics.accuracy.f887c0aab52c2d38e1f8a215681126379eca617f96c447638f751434e8e65b14.accuracy" value="EvaluationModule%28name%3A %22accuracy%22%2C module_type%3A %22metric%22%2C features%3A %7B%27predictions%27%3A Value%28dtype=%27int32%27%2C id=None%29%2C %27references...weight=%5B0.5%2C 2%2C 0.7%2C 0.5%2C 9%2C 0.4%5D%29%0A        &gt;&gt;&gt; print%28results%29%0A        %7B%27accuracy%27%3A 0.8778625954198473%7D%0A%22%22%22%2C stored examples%3A 0%29" isContainer="True" shape="0" />
<var name="base_model" type="BertForSequenceClassification" qualifier="transformers.models.bert.modeling_bert" value="BertForSequenceClassification%28%0A  %28bert%29%3A BertModel%28%0A    %28embeddings%29%3A BertEmbeddings%28%0A      %28word_embeddings%29%3A Embedding%2828996...anh%28%29%0A    %29%0A  %29%0A  %28dropout%29%3A Dropout%28p=0.1%2C inplace=False%29%0A  %28classifier%29%3A Linear%28in_features=768%2C out_features=2%2C bias=True%29%0A%29" isContainer="True" />
<var name="classifier" type="TextClassificationPipeline" qualifier="transformers.pipelines.text_classification" value="%3Ctransformers.pipelines.text_classification.TextClassificationPipeline object at 0x0000027DF5F25C10&gt;" isContainer="True" />
<var name="dataset" type="DatasetDict" qualifier="datasets.dataset_dict" value="DatasetDict%28%7B%0A    train%3A Dataset%28%7B%0A        features%3A %5B%27id%27%2C %27text%27%2C %27label%27%2C %27source_data%27%5D%2C%0A        num_rows%3A 10843%0A    %7D%29%0A%7D%29" isContainer="True" shape="('train',)" />
<var name="dataset_eval" type="Dataset" qualifier="datasets.arrow_dataset" value="Dataset%28%7B%0A    features%3A %5B%27id%27%2C %27text%27%2C %27label%27%2C %27source_data%27%2C %27input_ids%27%2C %27token_type_ids%27%2C %27attention_mask%27%5D%2C%0A    num_rows%3A 1085%0A%7D%29" isContainer="True" shape="(1085, 7)" />
<var name="dataset_tokens" type="DatasetDict" qualifier="datasets.dataset_dict" value="DatasetDict%28%7B%0A    train%3A Dataset%28%7B%0A        features%3A %5B%27id%27%2C %27text%27%2C %27label%27%2C %27source_data%27%2C %27input_ids%27%2C %27token_type_ids%27%2C %27attention_mask%27%5D%2C%0A        num_rows%3A 10843%0A    %7D%29%0A%7D%29" isContainer="True" shape="('train',)" />
<var name="dataset_train" type="Dataset" qualifier="datasets.arrow_dataset" value="Dataset%28%7B%0A    features%3A %5B%27id%27%2C %27text%27%2C %27label%27%2C %27source_data%27%2C %27input_ids%27%2C %27token_type_ids%27%2C %27attention_mask%27%5D%2C%0A    num_rows%3A 9758%0A%7D%29" isContainer="True" shape="(9758, 7)" />
<var name="ft_model" type="BertForSequenceClassification" qualifier="transformers.models.bert.modeling_bert" value="BertForSequenceClassification%28%0A  %28bert%29%3A BertModel%28%0A    %28embeddings%29%3A BertEmbeddings%28%0A      %28word_embeddings%29%3A Embedding%2828996...anh%28%29%0A    %29%0A  %29%0A  %28dropout%29%3A Dropout%28p=0.1%2C inplace=False%29%0A  %28classifier%29%3A Linear%28in_features=768%2C out_features=2%2C bias=True%29%0A%29" isContainer="True" />
<var name="ft_model_checkpoint" type="str" qualifier="builtins" value="test_trainer/checkpoint-7317" />
<var name="label_count" type="int" qualifier="builtins" value="2" />
<var name="model_name" type="str" qualifier="builtins" value="./bert-base-cased" />
<var name="result" type="list" qualifier="builtins" value="%5B%7B%27label%27%3A %27NEGATIVE%27%2C %27score%27%3A 0.9997101426124573%7D%5D" isContainer="True" shape="1" />
<var name="sample_out" type="SequenceClassifierOutput" qualifier="transformers.modeling_outputs" value="SequenceClassifierOutput%28loss=None%2C logits=tensor%28%5B%5B 4.6405%2C -4.3613%5D%5D%2C grad_fn=%3CAddmmBackward0&gt;%29%2C hidden_states=None%2C attentions=None%29" isContainer="True" shape="1" />
<var name="sample_text" type="str" qualifier="builtins" value="i%27ll make fresh start i promise xtra sad puppy face" />
<var name="sample_tokens" type="BatchEncoding" qualifier="transformers.tokenization_utils_base" value="%7B%27input_ids%27%3A tensor%28%5B%5B  101%2C   178%2C   112%2C  1325%2C  1294%2C  4489%2C  1838%2C   178%2C  4437%2C   193%2C%0A          4487%2C  6782%2C 21566%2C  13...%2C 0%2C 0%2C 0%2C%0A         0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C%0A         0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%5D%5D%29%7D" isContainer="True" shape="3" />
<var name="scores" type="ndarray" qualifier="numpy" value="%5B9.9987686e-01 1.2317205e-04%5D" isContainer="True" shape="(2,)" />
<var name="shuffle" type="Dataset" qualifier="datasets.arrow_dataset" value="Dataset%28%7B%0A    features%3A %5B%27id%27%2C %27text%27%2C %27label%27%2C %27source_data%27%2C %27input_ids%27%2C %27token_type_ids%27%2C %27attention_mask%27%5D%2C%0A    num_rows%3A 10843%0A%7D%29" isContainer="True" shape="(10843, 7)" />
<var name="tokenizer" type="BertTokenizerFast" qualifier="transformers.models.bert.tokenization_bert_fast" value="BertTokenizerFast%28name_or_path=%27./bert-base-cased%27%2C vocab_size=28996%2C model_max_length=1000000000000000019884624838656%2C is_fas...se%2C special=True%29%2C%0A%09103%3A AddedToken%28%22%5BMASK%5D%22%2C rstrip=False%2C lstrip=False%2C single_word=False%2C normalized=False%2C special=True%29%2C%0A%7D" isContainer="True" shape="28996" />
<var name="train_count" type="int" qualifier="builtins" value="9758" />
<var name="trainer" type="Trainer" qualifier="transformers.trainer" value="%3Ctransformers.trainer.Trainer object at 0x0000027DAAA33190&gt;" isContainer="True" />
<var name="training_args" type="TrainingArguments" qualifier="transformers.training_args" value="TrainingArguments%28%0A_n_gpu=1%2C%0Aadafactor=False%2C%0Aadam_beta1=0.9%2C%0Aadam_beta2=0.999%2C%0Aadam_epsilon=1e-08%2C%0Aauto_find_batch_size=False...use_ipex=False%2C%0Ause_legacy_prediction_loop=False%2C%0Ause_mps_device=False%2C%0Awarmup_ratio=0.0%2C%0Awarmup_steps=100%2C%0Aweight_decay=0.0%2C%0A%29" isContainer="True" />
</xml>
depressive score: 0.9985948 neutral score: 0.0014051461
<xml><var name="_dummy_ipython_val"  />
<var name="_dummy_special_var"  />
<var name="acc_metric" type="Accuracy" qualifier="evaluate_modules.metrics.accuracy.f887c0aab52c2d38e1f8a215681126379eca617f96c447638f751434e8e65b14.accuracy" value="EvaluationModule%28name%3A %22accuracy%22%2C module_type%3A %22metric%22%2C features%3A %7B%27predictions%27%3A Value%28dtype=%27int32%27%2C id=None%29%2C %27references...weight=%5B0.5%2C 2%2C 0.7%2C 0.5%2C 9%2C 0.4%5D%29%0A        &gt;&gt;&gt; print%28results%29%0A        %7B%27accuracy%27%3A 0.8778625954198473%7D%0A%22%22%22%2C stored examples%3A 0%29" isContainer="True" shape="0" />
<var name="base_model" type="BertForSequenceClassification" qualifier="transformers.models.bert.modeling_bert" value="BertForSequenceClassification%28%0A  %28bert%29%3A BertModel%28%0A    %28embeddings%29%3A BertEmbeddings%28%0A      %28word_embeddings%29%3A Embedding%2828996...anh%28%29%0A    %29%0A  %29%0A  %28dropout%29%3A Dropout%28p=0.1%2C inplace=False%29%0A  %28classifier%29%3A Linear%28in_features=768%2C out_features=2%2C bias=True%29%0A%29" isContainer="True" />
<var name="classifier" type="TextClassificationPipeline" qualifier="transformers.pipelines.text_classification" value="%3Ctransformers.pipelines.text_classification.TextClassificationPipeline object at 0x0000027DF5F25C10&gt;" isContainer="True" />
<var name="dataset" type="DatasetDict" qualifier="datasets.dataset_dict" value="DatasetDict%28%7B%0A    train%3A Dataset%28%7B%0A        features%3A %5B%27id%27%2C %27text%27%2C %27label%27%2C %27source_data%27%5D%2C%0A        num_rows%3A 10843%0A    %7D%29%0A%7D%29" isContainer="True" shape="('train',)" />
<var name="dataset_eval" type="Dataset" qualifier="datasets.arrow_dataset" value="Dataset%28%7B%0A    features%3A %5B%27id%27%2C %27text%27%2C %27label%27%2C %27source_data%27%2C %27input_ids%27%2C %27token_type_ids%27%2C %27attention_mask%27%5D%2C%0A    num_rows%3A 1085%0A%7D%29" isContainer="True" shape="(1085, 7)" />
<var name="dataset_tokens" type="DatasetDict" qualifier="datasets.dataset_dict" value="DatasetDict%28%7B%0A    train%3A Dataset%28%7B%0A        features%3A %5B%27id%27%2C %27text%27%2C %27label%27%2C %27source_data%27%2C %27input_ids%27%2C %27token_type_ids%27%2C %27attention_mask%27%5D%2C%0A        num_rows%3A 10843%0A    %7D%29%0A%7D%29" isContainer="True" shape="('train',)" />
<var name="dataset_train" type="Dataset" qualifier="datasets.arrow_dataset" value="Dataset%28%7B%0A    features%3A %5B%27id%27%2C %27text%27%2C %27label%27%2C %27source_data%27%2C %27input_ids%27%2C %27token_type_ids%27%2C %27attention_mask%27%5D%2C%0A    num_rows%3A 9758%0A%7D%29" isContainer="True" shape="(9758, 7)" />
<var name="ft_model" type="BertForSequenceClassification" qualifier="transformers.models.bert.modeling_bert" value="BertForSequenceClassification%28%0A  %28bert%29%3A BertModel%28%0A    %28embeddings%29%3A BertEmbeddings%28%0A      %28word_embeddings%29%3A Embedding%2828996...anh%28%29%0A    %29%0A  %29%0A  %28dropout%29%3A Dropout%28p=0.1%2C inplace=False%29%0A  %28classifier%29%3A Linear%28in_features=768%2C out_features=2%2C bias=True%29%0A%29" isContainer="True" />
<var name="ft_model_checkpoint" type="str" qualifier="builtins" value="test_trainer/checkpoint-7317" />
<var name="label_count" type="int" qualifier="builtins" value="2" />
<var name="model_name" type="str" qualifier="builtins" value="./bert-base-cased" />
<var name="result" type="list" qualifier="builtins" value="%5B%7B%27label%27%3A %27NEGATIVE%27%2C %27score%27%3A 0.9997101426124573%7D%5D" isContainer="True" shape="1" />
<var name="sample_out" type="SequenceClassifierOutput" qualifier="transformers.modeling_outputs" value="SequenceClassifierOutput%28loss=None%2C logits=tensor%28%5B%5B-3.5057%2C  3.0605%5D%5D%2C grad_fn=%3CAddmmBackward0&gt;%29%2C hidden_states=None%2C attentions=None%29" isContainer="True" shape="1" />
<var name="sample_text" type="str" qualifier="builtins" value="i feel completely exhausted my life isn t going anywhere and i ve got nobody to turn to" />
<var name="sample_tokens" type="BatchEncoding" qualifier="transformers.tokenization_utils_base" value="%7B%27input_ids%27%3A tensor%28%5B%5B 101%2C  178%2C 1631%2C 2423%2C 8984%2C 1139%2C 1297%2C 2762%2C  189%2C 1280%2C 5456%2C 1105%2C%0A          178%2C 1396%2C 1400%2C 8582...%2C 0%2C 0%2C 0%2C%0A         0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C%0A         0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%5D%5D%29%7D" isContainer="True" shape="3" />
<var name="scores" type="ndarray" qualifier="numpy" value="%5B0.00140515 0.9985948 %5D" isContainer="True" shape="(2,)" />
<var name="shuffle" type="Dataset" qualifier="datasets.arrow_dataset" value="Dataset%28%7B%0A    features%3A %5B%27id%27%2C %27text%27%2C %27label%27%2C %27source_data%27%2C %27input_ids%27%2C %27token_type_ids%27%2C %27attention_mask%27%5D%2C%0A    num_rows%3A 10843%0A%7D%29" isContainer="True" shape="(10843, 7)" />
<var name="tokenizer" type="BertTokenizerFast" qualifier="transformers.models.bert.tokenization_bert_fast" value="BertTokenizerFast%28name_or_path=%27./bert-base-cased%27%2C vocab_size=28996%2C model_max_length=1000000000000000019884624838656%2C is_fas...se%2C special=True%29%2C%0A%09103%3A AddedToken%28%22%5BMASK%5D%22%2C rstrip=False%2C lstrip=False%2C single_word=False%2C normalized=False%2C special=True%29%2C%0A%7D" isContainer="True" shape="28996" />
<var name="train_count" type="int" qualifier="builtins" value="9758" />
<var name="trainer" type="Trainer" qualifier="transformers.trainer" value="%3Ctransformers.trainer.Trainer object at 0x0000027DAAA33190&gt;" isContainer="True" />
<var name="training_args" type="TrainingArguments" qualifier="transformers.training_args" value="TrainingArguments%28%0A_n_gpu=1%2C%0Aadafactor=False%2C%0Aadam_beta1=0.9%2C%0Aadam_beta2=0.999%2C%0Aadam_epsilon=1e-08%2C%0Aauto_find_batch_size=False...use_ipex=False%2C%0Ause_legacy_prediction_loop=False%2C%0Ause_mps_device=False%2C%0Awarmup_ratio=0.0%2C%0Awarmup_steps=100%2C%0Aweight_decay=0.0%2C%0A%29" isContainer="True" />
</xml>
depressive score: 0.9985948 neutral score: 0.0014051461
<xml><var name="_dummy_ipython_val"  />
<var name="_dummy_special_var"  />
<var name="acc_metric" type="Accuracy" qualifier="evaluate_modules.metrics.accuracy.f887c0aab52c2d38e1f8a215681126379eca617f96c447638f751434e8e65b14.accuracy" value="EvaluationModule%28name%3A %22accuracy%22%2C module_type%3A %22metric%22%2C features%3A %7B%27predictions%27%3A Value%28dtype=%27int32%27%2C id=None%29%2C %27references...weight=%5B0.5%2C 2%2C 0.7%2C 0.5%2C 9%2C 0.4%5D%29%0A        &gt;&gt;&gt; print%28results%29%0A        %7B%27accuracy%27%3A 0.8778625954198473%7D%0A%22%22%22%2C stored examples%3A 0%29" isContainer="True" shape="0" />
<var name="base_model" type="BertForSequenceClassification" qualifier="transformers.models.bert.modeling_bert" value="BertForSequenceClassification%28%0A  %28bert%29%3A BertModel%28%0A    %28embeddings%29%3A BertEmbeddings%28%0A      %28word_embeddings%29%3A Embedding%2828996...anh%28%29%0A    %29%0A  %29%0A  %28dropout%29%3A Dropout%28p=0.1%2C inplace=False%29%0A  %28classifier%29%3A Linear%28in_features=768%2C out_features=2%2C bias=True%29%0A%29" isContainer="True" />
<var name="classifier" type="TextClassificationPipeline" qualifier="transformers.pipelines.text_classification" value="%3Ctransformers.pipelines.text_classification.TextClassificationPipeline object at 0x0000027DF5F25C10&gt;" isContainer="True" />
<var name="dataset" type="DatasetDict" qualifier="datasets.dataset_dict" value="DatasetDict%28%7B%0A    train%3A Dataset%28%7B%0A        features%3A %5B%27id%27%2C %27text%27%2C %27label%27%2C %27source_data%27%5D%2C%0A        num_rows%3A 10843%0A    %7D%29%0A%7D%29" isContainer="True" shape="('train',)" />
<var name="dataset_eval" type="Dataset" qualifier="datasets.arrow_dataset" value="Dataset%28%7B%0A    features%3A %5B%27id%27%2C %27text%27%2C %27label%27%2C %27source_data%27%2C %27input_ids%27%2C %27token_type_ids%27%2C %27attention_mask%27%5D%2C%0A    num_rows%3A 1085%0A%7D%29" isContainer="True" shape="(1085, 7)" />
<var name="dataset_tokens" type="DatasetDict" qualifier="datasets.dataset_dict" value="DatasetDict%28%7B%0A    train%3A Dataset%28%7B%0A        features%3A %5B%27id%27%2C %27text%27%2C %27label%27%2C %27source_data%27%2C %27input_ids%27%2C %27token_type_ids%27%2C %27attention_mask%27%5D%2C%0A        num_rows%3A 10843%0A    %7D%29%0A%7D%29" isContainer="True" shape="('train',)" />
<var name="dataset_train" type="Dataset" qualifier="datasets.arrow_dataset" value="Dataset%28%7B%0A    features%3A %5B%27id%27%2C %27text%27%2C %27label%27%2C %27source_data%27%2C %27input_ids%27%2C %27token_type_ids%27%2C %27attention_mask%27%5D%2C%0A    num_rows%3A 9758%0A%7D%29" isContainer="True" shape="(9758, 7)" />
<var name="ft_model" type="BertForSequenceClassification" qualifier="transformers.models.bert.modeling_bert" value="BertForSequenceClassification%28%0A  %28bert%29%3A BertModel%28%0A    %28embeddings%29%3A BertEmbeddings%28%0A      %28word_embeddings%29%3A Embedding%2828996...anh%28%29%0A    %29%0A  %29%0A  %28dropout%29%3A Dropout%28p=0.1%2C inplace=False%29%0A  %28classifier%29%3A Linear%28in_features=768%2C out_features=2%2C bias=True%29%0A%29" isContainer="True" />
<var name="ft_model_checkpoint" type="str" qualifier="builtins" value="test_trainer/checkpoint-7317" />
<var name="label_count" type="int" qualifier="builtins" value="2" />
<var name="model_name" type="str" qualifier="builtins" value="./bert-base-cased" />
<var name="result" type="list" qualifier="builtins" value="%5B%7B%27label%27%3A %27NEGATIVE%27%2C %27score%27%3A 0.9997101426124573%7D%5D" isContainer="True" shape="1" />
<var name="sample_out" type="SequenceClassifierOutput" qualifier="transformers.modeling_outputs" value="SequenceClassifierOutput%28loss=None%2C logits=tensor%28%5B%5B-3.5057%2C  3.0605%5D%5D%2C grad_fn=%3CAddmmBackward0&gt;%29%2C hidden_states=None%2C attentions=None%29" isContainer="True" shape="1" />
<var name="sample_text" type="str" qualifier="builtins" value="i feel completely exhausted my life isn t going anywhere and i ve got nobody to turn to" />
<var name="sample_tokens" type="BatchEncoding" qualifier="transformers.tokenization_utils_base" value="%7B%27input_ids%27%3A tensor%28%5B%5B 101%2C  178%2C 1631%2C 2423%2C 8984%2C 1139%2C 1297%2C 2762%2C  189%2C 1280%2C 5456%2C 1105%2C%0A          178%2C 1396%2C 1400%2C 8582...%2C 0%2C 0%2C 0%2C%0A         0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C%0A         0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%5D%5D%29%7D" isContainer="True" shape="3" />
<var name="scores" type="ndarray" qualifier="numpy" value="%5B0.00140515 0.9985948 %5D" isContainer="True" shape="(2,)" />
<var name="shuffle" type="Dataset" qualifier="datasets.arrow_dataset" value="Dataset%28%7B%0A    features%3A %5B%27id%27%2C %27text%27%2C %27label%27%2C %27source_data%27%2C %27input_ids%27%2C %27token_type_ids%27%2C %27attention_mask%27%5D%2C%0A    num_rows%3A 10843%0A%7D%29" isContainer="True" shape="(10843, 7)" />
<var name="tokenizer" type="BertTokenizerFast" qualifier="transformers.models.bert.tokenization_bert_fast" value="BertTokenizerFast%28name_or_path=%27./bert-base-cased%27%2C vocab_size=28996%2C model_max_length=1000000000000000019884624838656%2C is_fas...se%2C special=True%29%2C%0A%09103%3A AddedToken%28%22%5BMASK%5D%22%2C rstrip=False%2C lstrip=False%2C single_word=False%2C normalized=False%2C special=True%29%2C%0A%7D" isContainer="True" shape="28996" />
<var name="train_count" type="int" qualifier="builtins" value="9758" />
<var name="trainer" type="Trainer" qualifier="transformers.trainer" value="%3Ctransformers.trainer.Trainer object at 0x0000027DAAA33190&gt;" isContainer="True" />
<var name="training_args" type="TrainingArguments" qualifier="transformers.training_args" value="TrainingArguments%28%0A_n_gpu=1%2C%0Aadafactor=False%2C%0Aadam_beta1=0.9%2C%0Aadam_beta2=0.999%2C%0Aadam_epsilon=1e-08%2C%0Aauto_find_batch_size=False...use_ipex=False%2C%0Ause_legacy_prediction_loop=False%2C%0Ause_mps_device=False%2C%0Awarmup_ratio=0.0%2C%0Awarmup_steps=100%2C%0Aweight_decay=0.0%2C%0A%29" isContainer="True" />
</xml>
depressive score: 0.00012317205 neutral score: 0.99987686
<xml><var name="_dummy_ipython_val"  />
<var name="_dummy_special_var"  />
<var name="acc_metric" type="Accuracy" qualifier="evaluate_modules.metrics.accuracy.f887c0aab52c2d38e1f8a215681126379eca617f96c447638f751434e8e65b14.accuracy" value="EvaluationModule%28name%3A %22accuracy%22%2C module_type%3A %22metric%22%2C features%3A %7B%27predictions%27%3A Value%28dtype=%27int32%27%2C id=None%29%2C %27references...weight=%5B0.5%2C 2%2C 0.7%2C 0.5%2C 9%2C 0.4%5D%29%0A        &gt;&gt;&gt; print%28results%29%0A        %7B%27accuracy%27%3A 0.8778625954198473%7D%0A%22%22%22%2C stored examples%3A 0%29" isContainer="True" shape="0" />
<var name="base_model" type="BertForSequenceClassification" qualifier="transformers.models.bert.modeling_bert" value="BertForSequenceClassification%28%0A  %28bert%29%3A BertModel%28%0A    %28embeddings%29%3A BertEmbeddings%28%0A      %28word_embeddings%29%3A Embedding%2828996...anh%28%29%0A    %29%0A  %29%0A  %28dropout%29%3A Dropout%28p=0.1%2C inplace=False%29%0A  %28classifier%29%3A Linear%28in_features=768%2C out_features=2%2C bias=True%29%0A%29" isContainer="True" />
<var name="classifier" type="TextClassificationPipeline" qualifier="transformers.pipelines.text_classification" value="%3Ctransformers.pipelines.text_classification.TextClassificationPipeline object at 0x0000027DF5F25C10&gt;" isContainer="True" />
<var name="dataset" type="DatasetDict" qualifier="datasets.dataset_dict" value="DatasetDict%28%7B%0A    train%3A Dataset%28%7B%0A        features%3A %5B%27id%27%2C %27text%27%2C %27label%27%2C %27source_data%27%5D%2C%0A        num_rows%3A 10843%0A    %7D%29%0A%7D%29" isContainer="True" shape="('train',)" />
<var name="dataset_eval" type="Dataset" qualifier="datasets.arrow_dataset" value="Dataset%28%7B%0A    features%3A %5B%27id%27%2C %27text%27%2C %27label%27%2C %27source_data%27%2C %27input_ids%27%2C %27token_type_ids%27%2C %27attention_mask%27%5D%2C%0A    num_rows%3A 1085%0A%7D%29" isContainer="True" shape="(1085, 7)" />
<var name="dataset_tokens" type="DatasetDict" qualifier="datasets.dataset_dict" value="DatasetDict%28%7B%0A    train%3A Dataset%28%7B%0A        features%3A %5B%27id%27%2C %27text%27%2C %27label%27%2C %27source_data%27%2C %27input_ids%27%2C %27token_type_ids%27%2C %27attention_mask%27%5D%2C%0A        num_rows%3A 10843%0A    %7D%29%0A%7D%29" isContainer="True" shape="('train',)" />
<var name="dataset_train" type="Dataset" qualifier="datasets.arrow_dataset" value="Dataset%28%7B%0A    features%3A %5B%27id%27%2C %27text%27%2C %27label%27%2C %27source_data%27%2C %27input_ids%27%2C %27token_type_ids%27%2C %27attention_mask%27%5D%2C%0A    num_rows%3A 9758%0A%7D%29" isContainer="True" shape="(9758, 7)" />
<var name="ft_model" type="BertForSequenceClassification" qualifier="transformers.models.bert.modeling_bert" value="BertForSequenceClassification%28%0A  %28bert%29%3A BertModel%28%0A    %28embeddings%29%3A BertEmbeddings%28%0A      %28word_embeddings%29%3A Embedding%2828996...anh%28%29%0A    %29%0A  %29%0A  %28dropout%29%3A Dropout%28p=0.1%2C inplace=False%29%0A  %28classifier%29%3A Linear%28in_features=768%2C out_features=2%2C bias=True%29%0A%29" isContainer="True" />
<var name="ft_model_checkpoint" type="str" qualifier="builtins" value="test_trainer/checkpoint-7317" />
<var name="label_count" type="int" qualifier="builtins" value="2" />
<var name="model_name" type="str" qualifier="builtins" value="./bert-base-cased" />
<var name="result" type="list" qualifier="builtins" value="%5B%7B%27label%27%3A %27NEGATIVE%27%2C %27score%27%3A 0.9997101426124573%7D%5D" isContainer="True" shape="1" />
<var name="sample_out" type="SequenceClassifierOutput" qualifier="transformers.modeling_outputs" value="SequenceClassifierOutput%28loss=None%2C logits=tensor%28%5B%5B 4.6405%2C -4.3613%5D%5D%2C grad_fn=%3CAddmmBackward0&gt;%29%2C hidden_states=None%2C attentions=None%29" isContainer="True" shape="1" />
<var name="sample_text" type="str" qualifier="builtins" value="i%27ll make fresh start i promise xtra sad puppy face" />
<var name="sample_tokens" type="BatchEncoding" qualifier="transformers.tokenization_utils_base" value="%7B%27input_ids%27%3A tensor%28%5B%5B  101%2C   178%2C   112%2C  1325%2C  1294%2C  4489%2C  1838%2C   178%2C  4437%2C   193%2C%0A          4487%2C  6782%2C 21566%2C  13...%2C 0%2C 0%2C 0%2C%0A         0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C%0A         0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%5D%5D%29%7D" isContainer="True" shape="3" />
<var name="scores" type="ndarray" qualifier="numpy" value="%5B9.9987686e-01 1.2317205e-04%5D" isContainer="True" shape="(2,)" />
<var name="shuffle" type="Dataset" qualifier="datasets.arrow_dataset" value="Dataset%28%7B%0A    features%3A %5B%27id%27%2C %27text%27%2C %27label%27%2C %27source_data%27%2C %27input_ids%27%2C %27token_type_ids%27%2C %27attention_mask%27%5D%2C%0A    num_rows%3A 10843%0A%7D%29" isContainer="True" shape="(10843, 7)" />
<var name="tokenizer" type="BertTokenizerFast" qualifier="transformers.models.bert.tokenization_bert_fast" value="BertTokenizerFast%28name_or_path=%27./bert-base-cased%27%2C vocab_size=28996%2C model_max_length=1000000000000000019884624838656%2C is_fas...se%2C special=True%29%2C%0A%09103%3A AddedToken%28%22%5BMASK%5D%22%2C rstrip=False%2C lstrip=False%2C single_word=False%2C normalized=False%2C special=True%29%2C%0A%7D" isContainer="True" shape="28996" />
<var name="train_count" type="int" qualifier="builtins" value="9758" />
<var name="trainer" type="Trainer" qualifier="transformers.trainer" value="%3Ctransformers.trainer.Trainer object at 0x0000027DAAA33190&gt;" isContainer="True" />
<var name="training_args" type="TrainingArguments" qualifier="transformers.training_args" value="TrainingArguments%28%0A_n_gpu=1%2C%0Aadafactor=False%2C%0Aadam_beta1=0.9%2C%0Aadam_beta2=0.999%2C%0Aadam_epsilon=1e-08%2C%0Aauto_find_batch_size=False...use_ipex=False%2C%0Ause_legacy_prediction_loop=False%2C%0Ause_mps_device=False%2C%0Awarmup_ratio=0.0%2C%0Awarmup_steps=100%2C%0Aweight_decay=0.0%2C%0A%29" isContainer="True" />
</xml>
depressive score: 0.9985948 neutral score: 0.0014051461
<xml><var name="_dummy_ipython_val"  />
<var name="_dummy_special_var"  />
<var name="acc_metric" type="Accuracy" qualifier="evaluate_modules.metrics.accuracy.f887c0aab52c2d38e1f8a215681126379eca617f96c447638f751434e8e65b14.accuracy" value="EvaluationModule%28name%3A %22accuracy%22%2C module_type%3A %22metric%22%2C features%3A %7B%27predictions%27%3A Value%28dtype=%27int32%27%2C id=None%29%2C %27references...weight=%5B0.5%2C 2%2C 0.7%2C 0.5%2C 9%2C 0.4%5D%29%0A        &gt;&gt;&gt; print%28results%29%0A        %7B%27accuracy%27%3A 0.8778625954198473%7D%0A%22%22%22%2C stored examples%3A 0%29" isContainer="True" shape="0" />
<var name="base_model" type="BertForSequenceClassification" qualifier="transformers.models.bert.modeling_bert" value="BertForSequenceClassification%28%0A  %28bert%29%3A BertModel%28%0A    %28embeddings%29%3A BertEmbeddings%28%0A      %28word_embeddings%29%3A Embedding%2828996...anh%28%29%0A    %29%0A  %29%0A  %28dropout%29%3A Dropout%28p=0.1%2C inplace=False%29%0A  %28classifier%29%3A Linear%28in_features=768%2C out_features=2%2C bias=True%29%0A%29" isContainer="True" />
<var name="classifier" type="TextClassificationPipeline" qualifier="transformers.pipelines.text_classification" value="%3Ctransformers.pipelines.text_classification.TextClassificationPipeline object at 0x0000027DF5F25C10&gt;" isContainer="True" />
<var name="dataset" type="DatasetDict" qualifier="datasets.dataset_dict" value="DatasetDict%28%7B%0A    train%3A Dataset%28%7B%0A        features%3A %5B%27id%27%2C %27text%27%2C %27label%27%2C %27source_data%27%5D%2C%0A        num_rows%3A 10843%0A    %7D%29%0A%7D%29" isContainer="True" shape="('train',)" />
<var name="dataset_eval" type="Dataset" qualifier="datasets.arrow_dataset" value="Dataset%28%7B%0A    features%3A %5B%27id%27%2C %27text%27%2C %27label%27%2C %27source_data%27%2C %27input_ids%27%2C %27token_type_ids%27%2C %27attention_mask%27%5D%2C%0A    num_rows%3A 1085%0A%7D%29" isContainer="True" shape="(1085, 7)" />
<var name="dataset_tokens" type="DatasetDict" qualifier="datasets.dataset_dict" value="DatasetDict%28%7B%0A    train%3A Dataset%28%7B%0A        features%3A %5B%27id%27%2C %27text%27%2C %27label%27%2C %27source_data%27%2C %27input_ids%27%2C %27token_type_ids%27%2C %27attention_mask%27%5D%2C%0A        num_rows%3A 10843%0A    %7D%29%0A%7D%29" isContainer="True" shape="('train',)" />
<var name="dataset_train" type="Dataset" qualifier="datasets.arrow_dataset" value="Dataset%28%7B%0A    features%3A %5B%27id%27%2C %27text%27%2C %27label%27%2C %27source_data%27%2C %27input_ids%27%2C %27token_type_ids%27%2C %27attention_mask%27%5D%2C%0A    num_rows%3A 9758%0A%7D%29" isContainer="True" shape="(9758, 7)" />
<var name="ft_model" type="BertForSequenceClassification" qualifier="transformers.models.bert.modeling_bert" value="BertForSequenceClassification%28%0A  %28bert%29%3A BertModel%28%0A    %28embeddings%29%3A BertEmbeddings%28%0A      %28word_embeddings%29%3A Embedding%2828996...anh%28%29%0A    %29%0A  %29%0A  %28dropout%29%3A Dropout%28p=0.1%2C inplace=False%29%0A  %28classifier%29%3A Linear%28in_features=768%2C out_features=2%2C bias=True%29%0A%29" isContainer="True" />
<var name="ft_model_checkpoint" type="str" qualifier="builtins" value="test_trainer/checkpoint-7317" />
<var name="label_count" type="int" qualifier="builtins" value="2" />
<var name="model_name" type="str" qualifier="builtins" value="./bert-base-cased" />
<var name="result" type="list" qualifier="builtins" value="%5B%7B%27label%27%3A %27NEGATIVE%27%2C %27score%27%3A 0.9997101426124573%7D%5D" isContainer="True" shape="1" />
<var name="sample_out" type="SequenceClassifierOutput" qualifier="transformers.modeling_outputs" value="SequenceClassifierOutput%28loss=None%2C logits=tensor%28%5B%5B-3.5057%2C  3.0605%5D%5D%2C grad_fn=%3CAddmmBackward0&gt;%29%2C hidden_states=None%2C attentions=None%29" isContainer="True" shape="1" />
<var name="sample_text" type="str" qualifier="builtins" value="i feel completely exhausted my life isn t going anywhere and i ve got nobody to turn to" />
<var name="sample_tokens" type="BatchEncoding" qualifier="transformers.tokenization_utils_base" value="%7B%27input_ids%27%3A tensor%28%5B%5B 101%2C  178%2C 1631%2C 2423%2C 8984%2C 1139%2C 1297%2C 2762%2C  189%2C 1280%2C 5456%2C 1105%2C%0A          178%2C 1396%2C 1400%2C 8582...%2C 0%2C 0%2C 0%2C%0A         0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C%0A         0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%5D%5D%29%7D" isContainer="True" shape="3" />
<var name="scores" type="ndarray" qualifier="numpy" value="%5B0.00140515 0.9985948 %5D" isContainer="True" shape="(2,)" />
<var name="shuffle" type="Dataset" qualifier="datasets.arrow_dataset" value="Dataset%28%7B%0A    features%3A %5B%27id%27%2C %27text%27%2C %27label%27%2C %27source_data%27%2C %27input_ids%27%2C %27token_type_ids%27%2C %27attention_mask%27%5D%2C%0A    num_rows%3A 10843%0A%7D%29" isContainer="True" shape="(10843, 7)" />
<var name="tokenizer" type="BertTokenizerFast" qualifier="transformers.models.bert.tokenization_bert_fast" value="BertTokenizerFast%28name_or_path=%27./bert-base-cased%27%2C vocab_size=28996%2C model_max_length=1000000000000000019884624838656%2C is_fas...se%2C special=True%29%2C%0A%09103%3A AddedToken%28%22%5BMASK%5D%22%2C rstrip=False%2C lstrip=False%2C single_word=False%2C normalized=False%2C special=True%29%2C%0A%7D" isContainer="True" shape="28996" />
<var name="train_count" type="int" qualifier="builtins" value="9758" />
<var name="trainer" type="Trainer" qualifier="transformers.trainer" value="%3Ctransformers.trainer.Trainer object at 0x0000027DAAA33190&gt;" isContainer="True" />
<var name="training_args" type="TrainingArguments" qualifier="transformers.training_args" value="TrainingArguments%28%0A_n_gpu=1%2C%0Aadafactor=False%2C%0Aadam_beta1=0.9%2C%0Aadam_beta2=0.999%2C%0Aadam_epsilon=1e-08%2C%0Aauto_find_batch_size=False...use_ipex=False%2C%0Ause_legacy_prediction_loop=False%2C%0Ause_mps_device=False%2C%0Awarmup_ratio=0.0%2C%0Awarmup_steps=100%2C%0Aweight_decay=0.0%2C%0A%29" isContainer="True" />
</xml>
depressive score: 0.00012317205 neutral score: 0.99987686
<xml><var name="_dummy_ipython_val"  />
<var name="_dummy_special_var"  />
<var name="acc_metric" type="Accuracy" qualifier="evaluate_modules.metrics.accuracy.f887c0aab52c2d38e1f8a215681126379eca617f96c447638f751434e8e65b14.accuracy" value="EvaluationModule%28name%3A %22accuracy%22%2C module_type%3A %22metric%22%2C features%3A %7B%27predictions%27%3A Value%28dtype=%27int32%27%2C id=None%29%2C %27references...weight=%5B0.5%2C 2%2C 0.7%2C 0.5%2C 9%2C 0.4%5D%29%0A        &gt;&gt;&gt; print%28results%29%0A        %7B%27accuracy%27%3A 0.8778625954198473%7D%0A%22%22%22%2C stored examples%3A 0%29" isContainer="True" shape="0" />
<var name="base_model" type="BertForSequenceClassification" qualifier="transformers.models.bert.modeling_bert" value="BertForSequenceClassification%28%0A  %28bert%29%3A BertModel%28%0A    %28embeddings%29%3A BertEmbeddings%28%0A      %28word_embeddings%29%3A Embedding%2828996...anh%28%29%0A    %29%0A  %29%0A  %28dropout%29%3A Dropout%28p=0.1%2C inplace=False%29%0A  %28classifier%29%3A Linear%28in_features=768%2C out_features=2%2C bias=True%29%0A%29" isContainer="True" />
<var name="classifier" type="TextClassificationPipeline" qualifier="transformers.pipelines.text_classification" value="%3Ctransformers.pipelines.text_classification.TextClassificationPipeline object at 0x0000027DF5F25C10&gt;" isContainer="True" />
<var name="dataset" type="DatasetDict" qualifier="datasets.dataset_dict" value="DatasetDict%28%7B%0A    train%3A Dataset%28%7B%0A        features%3A %5B%27id%27%2C %27text%27%2C %27label%27%2C %27source_data%27%5D%2C%0A        num_rows%3A 10843%0A    %7D%29%0A%7D%29" isContainer="True" shape="('train',)" />
<var name="dataset_eval" type="Dataset" qualifier="datasets.arrow_dataset" value="Dataset%28%7B%0A    features%3A %5B%27id%27%2C %27text%27%2C %27label%27%2C %27source_data%27%2C %27input_ids%27%2C %27token_type_ids%27%2C %27attention_mask%27%5D%2C%0A    num_rows%3A 1085%0A%7D%29" isContainer="True" shape="(1085, 7)" />
<var name="dataset_tokens" type="DatasetDict" qualifier="datasets.dataset_dict" value="DatasetDict%28%7B%0A    train%3A Dataset%28%7B%0A        features%3A %5B%27id%27%2C %27text%27%2C %27label%27%2C %27source_data%27%2C %27input_ids%27%2C %27token_type_ids%27%2C %27attention_mask%27%5D%2C%0A        num_rows%3A 10843%0A    %7D%29%0A%7D%29" isContainer="True" shape="('train',)" />
<var name="dataset_train" type="Dataset" qualifier="datasets.arrow_dataset" value="Dataset%28%7B%0A    features%3A %5B%27id%27%2C %27text%27%2C %27label%27%2C %27source_data%27%2C %27input_ids%27%2C %27token_type_ids%27%2C %27attention_mask%27%5D%2C%0A    num_rows%3A 9758%0A%7D%29" isContainer="True" shape="(9758, 7)" />
<var name="ft_model" type="BertForSequenceClassification" qualifier="transformers.models.bert.modeling_bert" value="BertForSequenceClassification%28%0A  %28bert%29%3A BertModel%28%0A    %28embeddings%29%3A BertEmbeddings%28%0A      %28word_embeddings%29%3A Embedding%2828996...anh%28%29%0A    %29%0A  %29%0A  %28dropout%29%3A Dropout%28p=0.1%2C inplace=False%29%0A  %28classifier%29%3A Linear%28in_features=768%2C out_features=2%2C bias=True%29%0A%29" isContainer="True" />
<var name="ft_model_checkpoint" type="str" qualifier="builtins" value="test_trainer/checkpoint-7317" />
<var name="label_count" type="int" qualifier="builtins" value="2" />
<var name="model_name" type="str" qualifier="builtins" value="./bert-base-cased" />
<var name="result" type="list" qualifier="builtins" value="%5B%7B%27label%27%3A %27NEGATIVE%27%2C %27score%27%3A 0.9997101426124573%7D%5D" isContainer="True" shape="1" />
<var name="sample_out" type="SequenceClassifierOutput" qualifier="transformers.modeling_outputs" value="SequenceClassifierOutput%28loss=None%2C logits=tensor%28%5B%5B 4.6405%2C -4.3613%5D%5D%2C grad_fn=%3CAddmmBackward0&gt;%29%2C hidden_states=None%2C attentions=None%29" isContainer="True" shape="1" />
<var name="sample_text" type="str" qualifier="builtins" value="i%27ll make fresh start i promise xtra sad puppy face" />
<var name="sample_tokens" type="BatchEncoding" qualifier="transformers.tokenization_utils_base" value="%7B%27input_ids%27%3A tensor%28%5B%5B  101%2C   178%2C   112%2C  1325%2C  1294%2C  4489%2C  1838%2C   178%2C  4437%2C   193%2C%0A          4487%2C  6782%2C 21566%2C  13...%2C 0%2C 0%2C 0%2C%0A         0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C%0A         0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%2C 0%5D%5D%29%7D" isContainer="True" shape="3" />
<var name="scores" type="ndarray" qualifier="numpy" value="%5B9.9987686e-01 1.2317205e-04%5D" isContainer="True" shape="(2,)" />
<var name="shuffle" type="Dataset" qualifier="datasets.arrow_dataset" value="Dataset%28%7B%0A    features%3A %5B%27id%27%2C %27text%27%2C %27label%27%2C %27source_data%27%2C %27input_ids%27%2C %27token_type_ids%27%2C %27attention_mask%27%5D%2C%0A    num_rows%3A 10843%0A%7D%29" isContainer="True" shape="(10843, 7)" />
<var name="tokenizer" type="BertTokenizerFast" qualifier="transformers.models.bert.tokenization_bert_fast" value="BertTokenizerFast%28name_or_path=%27./bert-base-cased%27%2C vocab_size=28996%2C model_max_length=1000000000000000019884624838656%2C is_fas...se%2C special=True%29%2C%0A%09103%3A AddedToken%28%22%5BMASK%5D%22%2C rstrip=False%2C lstrip=False%2C single_word=False%2C normalized=False%2C special=True%29%2C%0A%7D" isContainer="True" shape="28996" />
<var name="train_count" type="int" qualifier="builtins" value="9758" />
<var name="trainer" type="Trainer" qualifier="transformers.trainer" value="%3Ctransformers.trainer.Trainer object at 0x0000027DAAA33190&gt;" isContainer="True" />
<var name="training_args" type="TrainingArguments" qualifier="transformers.training_args" value="TrainingArguments%28%0A_n_gpu=1%2C%0Aadafactor=False%2C%0Aadam_beta1=0.9%2C%0Aadam_beta2=0.999%2C%0Aadam_epsilon=1e-08%2C%0Aauto_find_batch_size=False...use_ipex=False%2C%0Ause_legacy_prediction_loop=False%2C%0Ause_mps_device=False%2C%0Awarmup_ratio=0.0%2C%0Awarmup_steps=100%2C%0Aweight_decay=0.0%2C%0A%29" isContainer="True" />
