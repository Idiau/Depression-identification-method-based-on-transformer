{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "import numpy as np \n",
    "import evaluate\n",
    "import os \n",
    "from scipy.special import softmax"
   ],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-02T02:50:18.450291100Z",
     "start_time": "2024-03-02T02:50:01.576021800Z"
    }
   },
   "id": "6d4251e0-07df-4304-b75a-1d0035c6afad"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "os.environ[\"WANDB_API_KEY\"] = 'ca91f3fe76b1db407047964b611a44bd349c4a73'\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-29T10:58:26.974399200Z",
     "start_time": "2024-02-29T10:58:26.965880400Z"
    }
   },
   "id": "91abb5fc8f4045cb"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "Dataset({\n    features: ['text', 'label'],\n    num_rows: 27977\n})"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load depressive speech dataset and store it\n",
    "dataset = load_dataset('./data/depressive_speech')\n",
    "#dataset\n",
    "dataset['train']"
   ],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-29T10:58:29.521490Z",
     "start_time": "2024-02-29T10:58:26.970402100Z"
    }
   },
   "id": "bd7948d0-d9b5-4ac1-b7c9-86d8bbad0c44"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "# set the base model to a bert-base-cased\n",
    "model_name = \"./bert-base-cased\""
   ],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-29T10:58:29.522490900Z",
     "start_time": "2024-02-29T10:58:29.515974500Z"
    }
   },
   "id": "9a177124-405d-4027-92c6-176fee3f2c05"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "# get the tokenizer from the model and store it\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-29T10:58:29.826444500Z",
     "start_time": "2024-02-29T10:58:29.521490Z"
    }
   },
   "id": "94653e91-a798-465d-87b1-fccf7c085be8"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "# define the tokenize function that the tokenizer will be used for\n",
    "def tokenize(samples):\n",
    "    return tokenizer(samples['text'], padding=\"max_length\", truncation=True,max_length=512)"
   ],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-29T10:58:29.870796600Z",
     "start_time": "2024-02-29T10:58:29.869793400Z"
    }
   },
   "id": "90f19ae1-8ff5-42bd-b415-3ab83e0c6146"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "2"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#tokenize the data and store it as a new variable, then determine the number of unique labels that will be used to classify the data during training and evaluation\n",
    "dataset_tokens = dataset.map(tokenize, batched=True)\n",
    "label_count = np.unique(np.array(dataset_tokens['train']['label'])).size\n",
    "label_count"
   ],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-29T10:58:29.971775400Z",
     "start_time": "2024-02-29T10:58:29.869793400Z"
    }
   },
   "id": "311f7c4d-0ac3-4cd5-a34d-bfab091313a5"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval: Dataset({\n",
      "    features: ['text', 'label', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
      "    num_rows: 2798\n",
      "}) \n",
      "Train: Dataset({\n",
      "    features: ['text', 'label', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
      "    num_rows: 25179\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "# randomize the tokenized data, then split it up into a training set and an evaluation set\n",
    "shuffle = dataset_tokens['train'].shuffle(seed=42)\n",
    "\n",
    "train_count = int(shuffle.num_rows * 0.9) \n",
    "\n",
    "dataset_train = shuffle.select(range(0, train_count))\n",
    "dataset_eval = shuffle.select(range(train_count, shuffle.num_rows))\n",
    "print(\"Eval:\", dataset_eval, \"\\nTrain:\", dataset_train)"
   ],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-29T10:58:30.005497300Z",
     "start_time": "2024-02-29T10:58:29.966777400Z"
    }
   },
   "id": "0780ec4f-0843-4cdc-9e1a-e8509823e87c"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at ./bert-base-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# create an instance of the base model that will be trained\n",
    "base_model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=label_count)"
   ],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-29T10:58:35.028299100Z",
     "start_time": "2024-02-29T10:58:29.991490400Z"
    }
   },
   "id": "43264197-c63e-4e29-9b1a-16a9c5ab227e"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "# set the characteristics of how the model will be trained (ex: the similarity of the output to the ground truth will be evaluated every epoch)\n",
    "#training_args = TrainingArguments(output_dir=\"test_trainer\", evaluation_strategy=\"epoch\")\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='test_trainer',  # 保存模型和日志的目录\n",
    "    num_train_epochs=1,  # 训练轮数\n",
    "    per_device_train_batch_size=2,  # 训练时每个 GPU 上的 batch size\n",
    "    per_device_eval_batch_size=2,  # 验证时每个 GPU 上的 batch size\n",
    "    warmup_steps=100,  # 学习率 warmup 步数\n",
    "    learning_rate=3e-5,  # 初始学习率\n",
    "    logging_dir='./logs',  # 日志保存目录\n",
    "    logging_steps=100,  # 每隔多少步打印一次训练日志\n",
    "    evaluation_strategy='epoch',  # 在哪些时间步骤上评估性能：'no', 'steps', 'epoch'\n",
    "    save_total_limit=3,  # 保存的模型数量上限\n",
    "    save_strategy='epoch', # 模型保存策略，'steps':每隔多少步保存一次，'epoch':每个epoch保存一次\n",
    "    gradient_accumulation_steps=2,  # 每多少个 batch 合并为一个，等于期望的 batch size / \n",
    ")"
   ],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-29T10:58:35.064441200Z",
     "start_time": "2024-02-29T10:58:35.026299100Z"
    }
   },
   "id": "54e1952c-8a64-41bd-9373-ee8c2e49b210"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "# load the accuracy metric\n",
    "metrics = evaluate.combine([\"./metrics/accuracy\", \"./metrics/f1\", \"./metrics/precision\", \"./metrics/recall\"])"
   ],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-29T10:58:35.292287200Z",
     "start_time": "2024-02-29T10:58:35.048357Z"
    }
   },
   "id": "3a0f7b40-284c-4dd0-a36a-53b4e6df3338"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "# define a fuction that will evaluate the accuracy of the model's output\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return metrics.compute(predictions=predictions, references=labels)"
   ],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-29T10:58:35.302807300Z",
     "start_time": "2024-02-29T10:58:35.295800500Z"
    }
   },
   "id": "da3110df-17b6-473c-b3ba-6610f4bdbf69"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "# create an instance of the trainer class\n",
    "trainer = Trainer(\n",
    "    model=base_model,\n",
    "    args=training_args,\n",
    "    train_dataset=dataset_train,\n",
    "    eval_dataset=dataset_eval,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-29T10:58:39.323860Z",
     "start_time": "2024-02-29T10:58:35.299809800Z"
    }
   },
   "id": "81f0fad9-a196-46c2-b1ca-96a8fcbcb085"
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d44fb22c-8453-407d-92e6-c73ba08568c8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-29T12:17:23.038721100Z",
     "start_time": "2024-02-29T10:58:39.327862200Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mwandb\u001B[0m: Currently logged in as: \u001B[33midiau\u001B[0m. Use \u001B[1m`wandb login --relogin`\u001B[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011111111111111112, max=1.0…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "53dcd7a1b7f24a2297ca172eeb0c35bd"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Tracking run with wandb version 0.16.2"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Run data is saved locally in <code>D:\\Paper\\red-flag-text-detection-main\\wandb\\run-20240229_185853-jrjqz719</code>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Syncing run <strong><a href='https://wandb.ai/idiau/huggingface/runs/jrjqz719' target=\"_blank\">young-planet-16</a></strong> to <a href='https://wandb.ai/idiau/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": " View project at <a href='https://wandb.ai/idiau/huggingface' target=\"_blank\">https://wandb.ai/idiau/huggingface</a>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": " View run at <a href='https://wandb.ai/idiau/huggingface/runs/jrjqz719' target=\"_blank\">https://wandb.ai/idiau/huggingface/runs/jrjqz719</a>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n    <div>\n      \n      <progress value='2' max='6295' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [   2/6295 : < :, Epoch 0.00/1]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table><p>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checkpoint destination directory test_trainer\\checkpoint-6295 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n    <div>\n      \n      <progress value='1' max='1399' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [   1/1399 : < :]\n    </div>\n    "
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.20620355010032654, 'eval_accuracy': 0.952108649035025, 'eval_f1': 0.9522111269614836, 'eval_precision': 0.9474804826117814, 'eval_recall': 0.956989247311828, 'eval_runtime': 164.4518, 'eval_samples_per_second': 17.014, 'eval_steps_per_second': 8.507, 'epoch': 1.0}\n"
     ]
    }
   ],
   "source": [
    "# train the model!\n",
    "trainer.train()\n",
    "print(trainer.evaluate())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "data": {
      "text/plain": "('depression-bert-base-cased\\\\tokenizer_config.json',\n 'depression-bert-base-cased\\\\special_tokens_map.json',\n 'depression-bert-base-cased\\\\vocab.txt',\n 'depression-bert-base-cased\\\\added_tokens.json',\n 'depression-bert-base-cased\\\\tokenizer.json')"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 保存微调后的模型和分词器\n",
    "model_path = \"depression-bert-base-cased\"\n",
    "base_model.save_pretrained(model_path)\n",
    "tokenizer.save_pretrained(model_path)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-29T12:31:29.209739100Z",
     "start_time": "2024-02-29T12:31:24.494466300Z"
    }
   },
   "id": "971ff72788897a74"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "model_path = \"depression-bert-base-cased\"\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_path, num_labels=2)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)"
   ],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-02T02:50:53.347225200Z",
     "start_time": "2024-03-02T02:50:53.061237200Z"
    }
   },
   "id": "bde48b07-1cde-454c-9b33-7c07b807cd69"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9d23240b-58d8-4e18-bbb8-2fe1a20c5c86",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-02T02:51:12.373225400Z",
     "start_time": "2024-03-02T02:51:10.747368400Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[ 101,  178, 1631, 2423, 8984, 1139, 1297, 2762,  189, 1280, 5456, 1105,\n",
      "          178, 1396, 1400, 8582, 1106, 1885, 1106,  102,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0]])}\n",
      "depressive score: 0.96090585 neutral score: 0.03909418\n"
     ]
    }
   ],
   "source": [
    "sample_text = \"i feel completely exhausted my life isn t going anywhere and i ve got nobody to turn to\"\n",
    "#sample_text=\"i'll make fresh start i promise xtra sad puppy face\"\n",
    "sample_tokens = tokenizer(sample_text, return_tensors=\"pt\", padding=\"max_length\", truncation=True,max_length=512)\n",
    "sample_out = model(**sample_tokens)\n",
    "scores = sample_out[0][0].detach().numpy()\n",
    "scores = softmax(scores)\n",
    "print(\"depressive score:\",scores[1], \"neutral score:\", scores[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-29T12:17:26.796898800Z",
     "start_time": "2024-02-29T12:17:26.791898800Z"
    }
   },
   "id": "9422ca7904827488"
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
